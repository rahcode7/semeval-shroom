{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing dependencies. You might need to tweak the CMAKE_ARGS for the `llama-cpp-python` pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CKL68Itp9Bm-",
    "outputId": "dd33c010-aa3e-4f6a-c763-e30047591c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python>=0.1.79\n",
      "  Downloading llama_cpp_python-0.2.24.tar.gz (8.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python>=0.1.79)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python>=0.1.79)\n",
      "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python>=0.1.79)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for llama-cpp-python \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[37 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1m\u001b[92mscikit-build-core 0.7.0\u001b[0m using \u001b[94mCMake 3.22.1\u001b[0m \u001b[91m(wheel)\u001b[0m\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mConfiguring CMake...\u001b[0m\n",
      "  \u001b[31m   \u001b[0m loading initial cache file /tmp/tmpmgsfdp15/build/CMakeInit.txt\n",
      "  \u001b[31m   \u001b[0m -- The C compiler identification is GNU 11.4.0\n",
      "  \u001b[31m   \u001b[0m -- The CXX compiler identification is GNU 11.4.0\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working C compiler: /usr/bin/cc - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
      "  \u001b[31m   \u001b[0m -- Looking for pthread.h\n",
      "  \u001b[31m   \u001b[0m -- Looking for pthread.h - found\n",
      "  \u001b[31m   \u001b[0m -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  \u001b[31m   \u001b[0m -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "  \u001b[31m   \u001b[0m -- Found Threads: TRUE\n",
      "  \u001b[31m   \u001b[0m -- Found CUDAToolkit: /usr/local/cuda/include (found version \"12.0.140\")\n",
      "  \u001b[31m   \u001b[0m -- cuBLAS found\n",
      "  \u001b[31m   \u001b[0m -- The CUDA compiler identification is unknown\n",
      "  \u001b[31m   \u001b[0m \u001b[31mCMake Error at vendor/llama.cpp/CMakeLists.txt:267 (enable_language):\n",
      "  \u001b[31m   \u001b[0m   No CMAKE_CUDA_COMPILER could be found.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m   Tell CMake where to find the compiler by setting either the environment\n",
      "  \u001b[31m   \u001b[0m   variable \"CUDACXX\" or the CMake cache entry CMAKE_CUDA_COMPILER to the full\n",
      "  \u001b[31m   \u001b[0m   path to the compiler, or to the compiler name if it is in the PATH.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[0m\n",
      "  \u001b[31m   \u001b[0m -- Configuring incomplete, errors occurred!\n",
      "  \u001b[31m   \u001b[0m See also \"/tmp/tmpmgsfdp15/build/CMakeFiles/CMakeOutput.log\".\n",
      "  \u001b[31m   \u001b[0m See also \"/tmp/tmpmgsfdp15/build/CMakeFiles/CMakeError.log\".\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[91m\u001b[1m*** CMake configuration failed\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for llama-cpp-python\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build llama-cpp-python\n",
      "\u001b[31mERROR: Could not build wheels for llama-cpp-python, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: huggingface_hub in /home/mickus/shroom/.venv/lib/python3.10/site-packages (0.19.4)\n",
      "Requirement already satisfied: filelock in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.11.17)\n",
      "Requirement already satisfied: datasets in /home/mickus/shroom/.venv/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: filelock in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/mickus/shroom/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# GPU llama-cpp-python; Starting from version llama-cpp-python==0.1.79, it supports GGUF\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on \" pip install 'llama-cpp-python>=0.1.79' --force-reinstall --upgrade --no-cache-dir\n",
    "# For download the models\n",
    "!pip install huggingface_hub\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by downloading an instruction-finetuned Mistral model, which we will ask to classify model outputs for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106,
     "referenced_widgets": [
      "2ae89d1a8a074a249b750d138587e44d",
      "eb30e73c1e824fa8942f0c58104d696f",
      "df0a135d8a5b43d5ab94bef15b2db5aa",
      "a5e99c0d3739407799fde2f29a301d05",
      "fa5555299e2e47ae9d2cc7a7e58415f4",
      "c96a1b051a7b4fbfbd873be07cf44cf0",
      "fa37a3f2205749468f31309b6061ffef",
      "a0ceffacff7f492d87084da291061006",
      "af87959da48a436e842f58ac691717df",
      "e35a5293e19748679095d1222f1a31e5",
      "2abefc6082af406ab1c955a880a2b419"
     ]
    },
    "id": "uDMqQmBfAhYO",
    "outputId": "eacd2078-6e5a-4451-84b4-69c6789cb4d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
      "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3080 Laptop GPU, compute capability 8.6\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /home/mickus/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/mistral-7b-instruct-v0.2.Q6_K.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:              blk.0.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:              blk.0.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:              blk.0.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:         blk.0.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:            blk.0.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:              blk.1.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:              blk.1.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:              blk.1.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:         blk.1.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:            blk.1.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:              blk.2.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:              blk.2.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:              blk.2.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:         blk.2.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:            blk.2.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:              blk.3.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:            blk.3.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:            blk.3.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:              blk.4.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:              blk.4.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:              blk.4.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:         blk.4.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:            blk.4.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:              blk.5.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:              blk.5.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:              blk.5.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:         blk.5.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:            blk.5.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:              blk.6.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:              blk.6.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:              blk.6.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:         blk.6.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:            blk.6.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:              blk.7.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:              blk.7.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:              blk.7.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:         blk.7.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.7.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.8.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:         blk.8.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.8.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.8.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.8.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.9.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.9.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:              blk.9.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:         blk.9.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.9.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.9.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.9.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.10.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:             blk.10.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.10.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:        blk.10.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.10.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.10.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:           blk.10.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.11.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:             blk.11.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:             blk.11.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:        blk.11.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:           blk.11.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:             blk.11.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.11.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:             blk.12.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:             blk.12.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:             blk.12.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:        blk.12.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:           blk.12.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:             blk.12.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:           blk.12.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:             blk.13.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:             blk.13.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:             blk.13.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:        blk.13.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:           blk.13.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:             blk.14.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:             blk.14.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:             blk.14.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:        blk.14.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:           blk.14.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:             blk.15.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:             blk.15.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:             blk.15.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:        blk.15.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:             blk.16.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:             blk.16.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:             blk.16.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:        blk.16.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:           blk.16.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:             blk.17.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:        blk.17.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:             blk.18.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:             blk.18.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:             blk.18.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:        blk.18.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:           blk.18.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:             blk.19.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:             blk.19.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:             blk.19.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:        blk.19.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:           blk.19.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:             blk.20.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:             blk.20.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:             blk.20.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:        blk.20.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:           blk.20.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:             blk.21.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:           blk.21.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:             blk.22.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:             blk.22.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:             blk.22.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:        blk.22.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:           blk.22.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:             blk.23.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:             blk.23.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:             blk.23.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:        blk.23.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:           blk.23.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:             blk.24.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:             blk.24.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:             blk.24.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:        blk.24.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:           blk.24.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:             blk.25.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:             blk.25.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:             blk.25.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:        blk.25.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:           blk.25.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:             blk.26.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:        blk.26.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:             blk.27.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:             blk.27.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:             blk.27.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:        blk.27.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:           blk.27.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:             blk.28.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:             blk.28.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:             blk.28.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:        blk.28.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:           blk.28.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:             blk.29.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:             blk.29.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:             blk.29.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:        blk.29.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:           blk.29.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:             blk.30.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:           blk.30.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:           blk.30.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:             blk.31.attn_q.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:             blk.31.attn_k.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:             blk.31.attn_v.weight q6_K     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:        blk.31.attn_output.weight q6_K     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:           blk.31.ffn_gate.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:             blk.31.ffn_up.weight q6_K     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:           blk.31.ffn_down.weight q6_K     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 18\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q6_K:  226 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q6_K\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 5.53 GiB (6.56 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: using CUDA for GPU acceleration\n",
      "llm_load_tensors: mem required  =  205.20 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 32/33 layers to GPU\n",
      "llm_load_tensors: VRAM used: 5461.00 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 8192\n",
      "llama_new_context_with_model: freq_base  = 1000000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 8628.25 MiB\n",
      "llama_new_context_with_model: VRAM scratch buffer: 8625.06 MiB\n",
      "llama_new_context_with_model: total VRAM used: 14086.06 MiB (model: 5461.00 MiB, context: 8625.06 MiB)\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "model_name_or_path = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "model_basename = \"mistral-7b-instruct-v0.2.Q6_K.gguf\"\n",
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "# This config has been tested on an RTX 3080 (VRAM of 16GB).\n",
    "# you might need to tweak with respect to your hardware.\n",
    "from llama_cpp import Llama\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=16, # CPU cores\n",
    "    n_batch=8000, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=32, # Change this value based on your model and your GPU VRAM pool.\n",
    "    n_ctx=8192, # Context window\n",
    "    logits_all=True\n",
    ")\n",
    "\n",
    "run_on_test = False # whether this baseline system is ran on the test splits or the val splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on the model-aware track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKo1-X5OvT4b",
    "outputId": "4eba054f-48c4-4aea-a1de-4c14c9c45fa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64f002577ab4009bd2ee570b4642ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    35 runs   (    0.22 ms per token,  4620.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.47 ms /    51 tokens (    4.03 ms per token,   248.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1714.84 ms /    34 runs   (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:       total time =    2055.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    36 runs   (    0.20 ms per token,  4964.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.39 ms /    42 tokens (    4.72 ms per token,   211.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1363.09 ms /    35 runs   (   38.95 ms per token,    25.68 tokens per second)\n",
      "llama_print_timings:       total time =    1681.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    25 runs   (    0.20 ms per token,  4930.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.56 ms /    47 tokens (    4.16 ms per token,   240.33 tokens per second)\n",
      "llama_print_timings:        eval time =     947.73 ms /    24 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
      "llama_print_timings:       total time =    1256.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    59 runs   (    0.21 ms per token,  4711.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     224.67 ms /    50 tokens (    4.49 ms per token,   222.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2125.15 ms /    58 runs   (   36.64 ms per token,    27.29 tokens per second)\n",
      "llama_print_timings:       total time =    2532.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.07 ms /    29 runs   (    0.21 ms per token,  4776.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.29 ms /    53 tokens (    3.78 ms per token,   264.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1044.84 ms /    28 runs   (   37.32 ms per token,    26.80 tokens per second)\n",
      "llama_print_timings:       total time =    1369.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    37 runs   (    0.21 ms per token,  4792.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.83 ms /    57 tokens (    3.42 ms per token,   292.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.26 ms /    36 runs   (   37.03 ms per token,    27.00 tokens per second)\n",
      "llama_print_timings:       total time =    1672.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    21 runs   (    0.20 ms per token,  5038.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.37 ms /    36 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
      "llama_print_timings:        eval time =     716.24 ms /    20 runs   (   35.81 ms per token,    27.92 tokens per second)\n",
      "llama_print_timings:       total time =     993.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    23 runs   (    0.21 ms per token,  4872.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.03 ms /    46 tokens (    4.13 ms per token,   242.06 tokens per second)\n",
      "llama_print_timings:        eval time =     888.77 ms /    22 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
      "llama_print_timings:       total time =    1182.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    27 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.09 ms /    51 tokens (    3.77 ms per token,   265.51 tokens per second)\n",
      "llama_print_timings:        eval time =     990.66 ms /    26 runs   (   38.10 ms per token,    26.25 tokens per second)\n",
      "llama_print_timings:       total time =    1304.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    32 runs   (    0.20 ms per token,  4938.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     237.36 ms /    43 tokens (    5.52 ms per token,   181.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1816.23 ms /    31 runs   (   58.59 ms per token,    17.07 tokens per second)\n",
      "llama_print_timings:       total time =    2177.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    44 runs   (    0.22 ms per token,  4458.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.75 ms /    48 tokens (    4.29 ms per token,   233.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1614.16 ms /    43 runs   (   37.54 ms per token,    26.64 tokens per second)\n",
      "llama_print_timings:       total time =    1975.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.15 ms /    23 runs   (    0.22 ms per token,  4466.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.52 ms /    55 tokens (    3.59 ms per token,   278.45 tokens per second)\n",
      "llama_print_timings:        eval time =     824.86 ms /    22 runs   (   37.49 ms per token,    26.67 tokens per second)\n",
      "llama_print_timings:       total time =    1149.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    34 runs   (    0.22 ms per token,  4450.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.63 ms /    53 tokens (    3.63 ms per token,   275.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.69 ms /    33 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:       total time =    1672.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    42 runs   (    0.22 ms per token,  4605.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.78 ms /    61 tokens (    3.31 ms per token,   302.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1606.84 ms /    41 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
      "llama_print_timings:       total time =    1969.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.47 ms /    52 runs   (    0.22 ms per token,  4535.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.14 ms /    52 tokens (    3.69 ms per token,   270.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2181.63 ms /    51 runs   (   42.78 ms per token,    23.38 tokens per second)\n",
      "llama_print_timings:       total time =    2552.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    51 runs   (    0.22 ms per token,  4527.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.11 ms /    45 tokens (    4.18 ms per token,   239.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1943.11 ms /    50 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
      "llama_print_timings:       total time =    2301.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    63 runs   (    0.22 ms per token,  4556.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.84 ms /    52 tokens (    3.77 ms per token,   265.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2971.74 ms /    62 runs   (   47.93 ms per token,    20.86 tokens per second)\n",
      "llama_print_timings:       total time =    3369.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    40 runs   (    0.24 ms per token,  4201.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     518.96 ms /   100 tokens (    5.19 ms per token,   192.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2268.09 ms /    39 runs   (   58.16 ms per token,    17.20 tokens per second)\n",
      "llama_print_timings:       total time =    3024.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    28 runs   (    0.22 ms per token,  4477.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.19 ms /    48 tokens (    4.36 ms per token,   229.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1223.82 ms /    27 runs   (   45.33 ms per token,    22.06 tokens per second)\n",
      "llama_print_timings:       total time =    1565.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    53 runs   (    0.23 ms per token,  4264.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.58 ms /    47 tokens (    4.23 ms per token,   236.68 tokens per second)\n",
      "llama_print_timings:        eval time =    2998.86 ms /    52 runs   (   57.67 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:       total time =    3389.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    28 runs   (    0.22 ms per token,  4583.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     225.16 ms /    52 tokens (    4.33 ms per token,   230.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1293.13 ms /    27 runs   (   47.89 ms per token,    20.88 tokens per second)\n",
      "llama_print_timings:       total time =    1649.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    28 runs   (    0.22 ms per token,  4477.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.99 ms /    59 tokens (    3.53 ms per token,   283.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1050.99 ms /    27 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
      "llama_print_timings:       total time =    1392.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.99 ms /    38 runs   (    0.24 ms per token,  4227.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.06 ms /    59 tokens (    3.73 ms per token,   268.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1632.66 ms /    37 runs   (   44.13 ms per token,    22.66 tokens per second)\n",
      "llama_print_timings:       total time =    2014.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    50 runs   (    0.23 ms per token,  4279.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.93 ms /    54 tokens (    3.76 ms per token,   266.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1994.92 ms /    49 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
      "llama_print_timings:       total time =    2380.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    56 runs   (    0.22 ms per token,  4478.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.57 ms /    54 tokens (    3.66 ms per token,   273.32 tokens per second)\n",
      "llama_print_timings:        eval time =    2245.43 ms /    55 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
      "llama_print_timings:       total time =    2627.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    35 runs   (    0.23 ms per token,  4423.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.05 ms /    47 tokens (    4.06 ms per token,   246.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1392.86 ms /    34 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
      "llama_print_timings:       total time =    1718.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.68 ms /    68 runs   (    0.22 ms per token,  4633.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.24 ms /    40 tokens (    4.63 ms per token,   215.93 tokens per second)\n",
      "llama_print_timings:        eval time =    2784.73 ms /    67 runs   (   41.56 ms per token,    24.06 tokens per second)\n",
      "llama_print_timings:       total time =    3160.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.14 ms /    82 runs   (    0.22 ms per token,  4519.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.30 ms /    49 tokens (    4.62 ms per token,   216.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3294.16 ms /    81 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
      "llama_print_timings:       total time =    3753.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    31 runs   (    0.23 ms per token,  4297.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     246.93 ms /    59 tokens (    4.19 ms per token,   238.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1347.81 ms /    30 runs   (   44.93 ms per token,    22.26 tokens per second)\n",
      "llama_print_timings:       total time =    1744.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    21 runs   (    0.22 ms per token,  4467.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.03 ms /    53 tokens (    3.64 ms per token,   274.57 tokens per second)\n",
      "llama_print_timings:        eval time =     775.09 ms /    20 runs   (   38.75 ms per token,    25.80 tokens per second)\n",
      "llama_print_timings:       total time =    1082.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    41 runs   (    0.22 ms per token,  4481.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.38 ms /    61 tokens (    3.33 ms per token,   299.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1626.24 ms /    40 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =    1997.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    28 runs   (    0.21 ms per token,  4797.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.69 ms /    42 tokens (    4.40 ms per token,   227.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1010.32 ms /    27 runs   (   37.42 ms per token,    26.72 tokens per second)\n",
      "llama_print_timings:       total time =    1302.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    28 runs   (    0.21 ms per token,  4703.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.36 ms /    42 tokens (    4.44 ms per token,   225.37 tokens per second)\n",
      "llama_print_timings:        eval time =     957.08 ms /    27 runs   (   35.45 ms per token,    28.21 tokens per second)\n",
      "llama_print_timings:       total time =    1252.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.68 ms /    43 runs   (    0.23 ms per token,  4442.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.22 ms /    48 tokens (    4.09 ms per token,   244.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1695.49 ms /    42 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
      "llama_print_timings:       total time =    2043.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    23 runs   (    0.20 ms per token,  4972.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.50 ms /    34 tokens (    5.37 ms per token,   186.30 tokens per second)\n",
      "llama_print_timings:        eval time =     831.31 ms /    22 runs   (   37.79 ms per token,    26.46 tokens per second)\n",
      "llama_print_timings:       total time =    1103.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    37 runs   (    0.22 ms per token,  4496.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.81 ms /    56 tokens (    3.51 ms per token,   284.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1475.07 ms /    36 runs   (   40.97 ms per token,    24.41 tokens per second)\n",
      "llama_print_timings:       total time =    1827.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    42 runs   (    0.22 ms per token,  4463.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.93 ms /    44 tokens (    4.29 ms per token,   232.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1647.32 ms /    41 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
      "llama_print_timings:       total time =    1983.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    35 runs   (    0.22 ms per token,  4578.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.16 ms /    41 tokens (    4.59 ms per token,   217.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1360.07 ms /    34 runs   (   40.00 ms per token,    25.00 tokens per second)\n",
      "llama_print_timings:       total time =    1677.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    38 runs   (    0.22 ms per token,  4510.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.15 ms /    42 tokens (    4.41 ms per token,   226.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1506.51 ms /    37 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
      "llama_print_timings:       total time =    1824.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.56 ms /    51 runs   (    0.23 ms per token,  4410.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.49 ms /    56 tokens (    3.51 ms per token,   285.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1963.39 ms /    50 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
      "llama_print_timings:       total time =    2339.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    55 runs   (    0.23 ms per token,  4394.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.83 ms /    52 tokens (    3.82 ms per token,   261.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2128.21 ms /    54 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
      "llama_print_timings:       total time =    2507.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.60 ms /    70 runs   (    0.22 ms per token,  4486.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.62 ms /    44 tokens (    4.38 ms per token,   228.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2704.71 ms /    69 runs   (   39.20 ms per token,    25.51 tokens per second)\n",
      "llama_print_timings:       total time =    3100.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    14 runs   (    0.21 ms per token,  4710.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.19 ms /    48 tokens (    4.11 ms per token,   243.43 tokens per second)\n",
      "llama_print_timings:        eval time =     640.34 ms /    13 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:       total time =     937.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.30 ms /    54 runs   (    0.23 ms per token,  4389.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.53 ms /    44 tokens (    4.19 ms per token,   238.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2308.42 ms /    53 runs   (   43.56 ms per token,    22.96 tokens per second)\n",
      "llama_print_timings:       total time =    2668.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.57 ms /    42 runs   (    0.23 ms per token,  4387.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.06 ms /    62 tokens (    3.37 ms per token,   296.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1752.54 ms /    41 runs   (   42.74 ms per token,    23.39 tokens per second)\n",
      "llama_print_timings:       total time =    2131.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.54 ms /    45 runs   (    0.23 ms per token,  4267.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     235.80 ms /    54 tokens (    4.37 ms per token,   229.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1790.42 ms /    44 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =    2196.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    17 runs   (    0.22 ms per token,  4502.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.86 ms /    51 tokens (    3.84 ms per token,   260.39 tokens per second)\n",
      "llama_print_timings:        eval time =     601.50 ms /    16 runs   (   37.59 ms per token,    26.60 tokens per second)\n",
      "llama_print_timings:       total time =     898.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    35 runs   (    0.23 ms per token,  4274.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.87 ms /    45 tokens (    4.60 ms per token,   217.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1369.47 ms /    34 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
      "llama_print_timings:       total time =    1719.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.32 ms /    61 runs   (    0.23 ms per token,  4258.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.27 ms /    48 tokens (    5.48 ms per token,   182.32 tokens per second)\n",
      "llama_print_timings:        eval time =    2498.96 ms /    60 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    2965.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    20 runs   (    0.24 ms per token,  4220.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.88 ms /    63 tokens (    3.22 ms per token,   310.53 tokens per second)\n",
      "llama_print_timings:        eval time =     741.46 ms /    19 runs   (   39.02 ms per token,    25.63 tokens per second)\n",
      "llama_print_timings:       total time =    1083.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      26.37 ms /   112 runs   (    0.24 ms per token,  4248.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.31 ms /    38 tokens (    5.03 ms per token,   198.63 tokens per second)\n",
      "llama_print_timings:        eval time =    5033.74 ms /   111 runs   (   45.35 ms per token,    22.05 tokens per second)\n",
      "llama_print_timings:       total time =    5514.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /    16 runs   (    0.21 ms per token,  4854.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.86 ms /    36 tokens (    5.47 ms per token,   182.87 tokens per second)\n",
      "llama_print_timings:        eval time =     586.02 ms /    15 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
      "llama_print_timings:       total time =     865.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    36 runs   (    0.23 ms per token,  4395.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.71 ms /    45 tokens (    4.22 ms per token,   237.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1732.07 ms /    35 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:       total time =    2060.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    58 runs   (    0.24 ms per token,  4160.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     213.19 ms /    44 tokens (    4.85 ms per token,   206.39 tokens per second)\n",
      "llama_print_timings:        eval time =    2709.96 ms /    57 runs   (   47.54 ms per token,    21.03 tokens per second)\n",
      "llama_print_timings:       total time =    3118.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.85 ms /    61 runs   (    0.24 ms per token,  4108.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.46 ms /    55 tokens (    3.54 ms per token,   282.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2667.53 ms /    60 runs   (   44.46 ms per token,    22.49 tokens per second)\n",
      "llama_print_timings:       total time =    3070.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    30 runs   (    0.21 ms per token,  4660.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.49 ms /    46 tokens (    4.12 ms per token,   242.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1197.76 ms /    29 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
      "llama_print_timings:       total time =    1513.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    34 runs   (    0.23 ms per token,  4387.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.52 ms /    42 tokens (    4.42 ms per token,   226.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1355.99 ms /    33 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:       total time =    1669.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      20.82 ms /    88 runs   (    0.24 ms per token,  4227.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.49 ms /    48 tokens (    3.97 ms per token,   251.98 tokens per second)\n",
      "llama_print_timings:        eval time =    3340.51 ms /    87 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
      "llama_print_timings:       total time =    3777.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.27 ms /    59 runs   (    0.24 ms per token,  4134.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.33 ms /    72 tokens (    3.60 ms per token,   277.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2223.39 ms /    58 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
      "llama_print_timings:       total time =    2708.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.45 ms /    72 runs   (    0.23 ms per token,  4376.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.58 ms /    41 tokens (    4.53 ms per token,   220.93 tokens per second)\n",
      "llama_print_timings:        eval time =    3059.65 ms /    71 runs   (   43.09 ms per token,    23.21 tokens per second)\n",
      "llama_print_timings:       total time =    3461.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    32 runs   (    0.22 ms per token,  4513.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.95 ms /    41 tokens (    5.63 ms per token,   177.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1676.64 ms /    31 runs   (   54.09 ms per token,    18.49 tokens per second)\n",
      "llama_print_timings:       total time =    2037.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    40 runs   (    0.23 ms per token,  4290.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.63 ms /    49 tokens (    4.22 ms per token,   237.14 tokens per second)\n",
      "llama_print_timings:        eval time =    2807.04 ms /    39 runs   (   71.98 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:       total time =    3174.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.72 ms /    17 runs   (    0.22 ms per token,  4569.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.26 ms /    44 tokens (    4.55 ms per token,   219.71 tokens per second)\n",
      "llama_print_timings:        eval time =     897.90 ms /    16 runs   (   56.12 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:       total time =    1204.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    36 runs   (    0.24 ms per token,  4222.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.87 ms /    60 tokens (    3.68 ms per token,   271.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1774.85 ms /    35 runs   (   50.71 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:       total time =    2156.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    32 runs   (    0.22 ms per token,  4508.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.69 ms /    39 tokens (    5.15 ms per token,   194.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1664.56 ms /    31 runs   (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:       total time =    1990.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.44 ms /    43 runs   (    0.24 ms per token,  4117.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.77 ms /    69 tokens (    3.01 ms per token,   332.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1956.31 ms /    42 runs   (   46.58 ms per token,    21.47 tokens per second)\n",
      "llama_print_timings:       total time =    2361.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    25 runs   (    0.21 ms per token,  4782.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     242.96 ms /    35 tokens (    6.94 ms per token,   144.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.90 ms /    24 runs   (   43.75 ms per token,    22.86 tokens per second)\n",
      "llama_print_timings:       total time =    1391.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.96 ms /    56 runs   (    0.23 ms per token,  4321.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.88 ms /    49 tokens (    4.06 ms per token,   246.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2299.80 ms /    55 runs   (   41.81 ms per token,    23.92 tokens per second)\n",
      "llama_print_timings:       total time =    2691.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      24.01 ms /   101 runs   (    0.24 ms per token,  4206.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.87 ms /    49 tokens (    4.06 ms per token,   246.40 tokens per second)\n",
      "llama_print_timings:        eval time =    4126.70 ms /   100 runs   (   41.27 ms per token,    24.23 tokens per second)\n",
      "llama_print_timings:       total time =    4611.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    27 runs   (    0.21 ms per token,  4719.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.57 ms /    43 tokens (    5.85 ms per token,   170.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1077.68 ms /    26 runs   (   41.45 ms per token,    24.13 tokens per second)\n",
      "llama_print_timings:       total time =    1443.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    36 runs   (    0.22 ms per token,  4449.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.89 ms /    40 tokens (    4.65 ms per token,   215.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1545.76 ms /    35 runs   (   44.16 ms per token,    22.64 tokens per second)\n",
      "llama_print_timings:       total time =    1865.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    39 runs   (    0.24 ms per token,  4144.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     222.37 ms /    77 tokens (    2.89 ms per token,   346.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1732.75 ms /    38 runs   (   45.60 ms per token,    21.93 tokens per second)\n",
      "llama_print_timings:       total time =    2141.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    27 runs   (    0.21 ms per token,  4800.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.73 ms /    38 tokens (    5.28 ms per token,   189.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.54 ms /    26 runs   (   41.98 ms per token,    23.82 tokens per second)\n",
      "llama_print_timings:       total time =    1403.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.24 ms /    50 runs   (    0.22 ms per token,  4448.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.15 ms /    54 tokens (    3.60 ms per token,   278.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1931.07 ms /    49 runs   (   39.41 ms per token,    25.37 tokens per second)\n",
      "llama_print_timings:       total time =    2299.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    31 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     235.52 ms /    44 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1762.56 ms /    30 runs   (   58.75 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:       total time =    2131.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    34 runs   (    0.23 ms per token,  4368.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     341.09 ms /    44 tokens (    7.75 ms per token,   129.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2231.56 ms /    33 runs   (   67.62 ms per token,    14.79 tokens per second)\n",
      "llama_print_timings:       total time =    2717.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /    16 runs   (    0.21 ms per token,  4733.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.75 ms /    42 tokens (    4.73 ms per token,   211.32 tokens per second)\n",
      "llama_print_timings:        eval time =     576.50 ms /    15 runs   (   38.43 ms per token,    26.02 tokens per second)\n",
      "llama_print_timings:       total time =     869.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.30 ms /    47 runs   (    0.22 ms per token,  4562.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.93 ms /    37 tokens (    4.97 ms per token,   201.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2138.84 ms /    46 runs   (   46.50 ms per token,    21.51 tokens per second)\n",
      "llama_print_timings:       total time =    2476.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    22 runs   (    0.22 ms per token,  4522.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     246.49 ms /    39 tokens (    6.32 ms per token,   158.22 tokens per second)\n",
      "llama_print_timings:        eval time =     757.32 ms /    21 runs   (   36.06 ms per token,    27.73 tokens per second)\n",
      "llama_print_timings:       total time =    1109.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.59 ms /    51 runs   (    0.23 ms per token,  4399.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.41 ms /    44 tokens (    4.62 ms per token,   216.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2234.05 ms /    50 runs   (   44.68 ms per token,    22.38 tokens per second)\n",
      "llama_print_timings:       total time =    2632.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    27 runs   (    0.23 ms per token,  4312.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.69 ms /    52 tokens (    3.80 ms per token,   263.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1569.13 ms /    26 runs   (   60.35 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:       total time =    1902.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    27 runs   (    0.23 ms per token,  4335.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.69 ms /    43 tokens (    6.18 ms per token,   161.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2059.15 ms /    26 runs   (   79.20 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    2455.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    31 runs   (    0.22 ms per token,  4639.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.32 ms /    38 tokens (    4.85 ms per token,   206.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1849.40 ms /    30 runs   (   61.65 ms per token,    16.22 tokens per second)\n",
      "llama_print_timings:       total time =    2159.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.75 ms /    61 runs   (    0.24 ms per token,  4135.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.91 ms /    54 tokens (    3.55 ms per token,   281.38 tokens per second)\n",
      "llama_print_timings:        eval time =    3314.11 ms /    60 runs   (   55.24 ms per token,    18.10 tokens per second)\n",
      "llama_print_timings:       total time =    3714.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    29 runs   (    0.22 ms per token,  4532.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.50 ms /    36 tokens (    5.24 ms per token,   190.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1391.06 ms /    28 runs   (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:       total time =    1696.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    33 runs   (    0.23 ms per token,  4264.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     297.44 ms /    44 tokens (    6.76 ms per token,   147.93 tokens per second)\n",
      "llama_print_timings:        eval time =    2283.87 ms /    32 runs   (   71.37 ms per token,    14.01 tokens per second)\n",
      "llama_print_timings:       total time =    2731.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    54 runs   (    0.22 ms per token,  4495.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.08 ms /    48 tokens (    4.29 ms per token,   232.92 tokens per second)\n",
      "llama_print_timings:        eval time =    2555.59 ms /    53 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_print_timings:       total time =    2942.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    32 runs   (    0.22 ms per token,  4624.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.06 ms /    49 tokens (    3.94 ms per token,   253.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2078.86 ms /    31 runs   (   67.06 ms per token,    14.91 tokens per second)\n",
      "llama_print_timings:       total time =    2404.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.27 ms /    63 runs   (    0.23 ms per token,  4416.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     341.75 ms /    37 tokens (    9.24 ms per token,   108.27 tokens per second)\n",
      "llama_print_timings:        eval time =    3321.70 ms /    62 runs   (   53.58 ms per token,    18.67 tokens per second)\n",
      "llama_print_timings:       total time =    3853.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    14 runs   (    0.20 ms per token,  5050.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.41 ms /    36 tokens (    5.01 ms per token,   199.54 tokens per second)\n",
      "llama_print_timings:        eval time =     564.23 ms /    13 runs   (   43.40 ms per token,    23.04 tokens per second)\n",
      "llama_print_timings:       total time =     822.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    31 runs   (    0.23 ms per token,  4361.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.40 ms /    42 tokens (    4.34 ms per token,   230.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1391.01 ms /    30 runs   (   46.37 ms per token,    21.57 tokens per second)\n",
      "llama_print_timings:       total time =    1702.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.77 ms /    82 runs   (    0.24 ms per token,  4147.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     307.56 ms /    52 tokens (    5.91 ms per token,   169.07 tokens per second)\n",
      "llama_print_timings:        eval time =    5466.94 ms /    81 runs   (   67.49 ms per token,    14.82 tokens per second)\n",
      "llama_print_timings:       total time =    6035.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    27 runs   (    0.22 ms per token,  4543.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.48 ms /    42 tokens (    4.68 ms per token,   213.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.86 ms /    26 runs   (   41.99 ms per token,    23.81 tokens per second)\n",
      "llama_print_timings:       total time =    1412.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    23 runs   (    0.21 ms per token,  4831.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.65 ms /    33 tokens (    5.50 ms per token,   181.67 tokens per second)\n",
      "llama_print_timings:        eval time =     823.98 ms /    22 runs   (   37.45 ms per token,    26.70 tokens per second)\n",
      "llama_print_timings:       total time =    1092.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.61 ms /    39 runs   (    0.25 ms per token,  4059.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.88 ms /    54 tokens (    3.61 ms per token,   277.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1482.39 ms /    38 runs   (   39.01 ms per token,    25.63 tokens per second)\n",
      "llama_print_timings:       total time =    1834.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.91 ms /    76 runs   (    0.24 ms per token,  4242.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.37 ms /    60 tokens (    3.39 ms per token,   295.03 tokens per second)\n",
      "llama_print_timings:        eval time =    3117.22 ms /    75 runs   (   41.56 ms per token,    24.06 tokens per second)\n",
      "llama_print_timings:       total time =    3576.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    23 runs   (    0.23 ms per token,  4351.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.48 ms /    78 tokens (    2.97 ms per token,   336.97 tokens per second)\n",
      "llama_print_timings:        eval time =     809.15 ms /    22 runs   (   36.78 ms per token,    27.19 tokens per second)\n",
      "llama_print_timings:       total time =    1200.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    33 runs   (    0.22 ms per token,  4448.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     179.60 ms /    38 tokens (    4.73 ms per token,   211.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1206.62 ms /    32 runs   (   37.71 ms per token,    26.52 tokens per second)\n",
      "llama_print_timings:       total time =    1503.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.56 ms /    54 runs   (    0.23 ms per token,  4298.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.72 ms /    42 tokens (    4.40 ms per token,   227.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2021.67 ms /    53 runs   (   38.14 ms per token,    26.22 tokens per second)\n",
      "llama_print_timings:       total time =    2376.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    32 runs   (    0.23 ms per token,  4343.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.68 ms /    46 tokens (    4.04 ms per token,   247.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1910.36 ms /    31 runs   (   61.62 ms per token,    16.23 tokens per second)\n",
      "llama_print_timings:       total time =    2240.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    17 runs   (    0.21 ms per token,  4828.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.19 ms /    39 tokens (    5.16 ms per token,   193.85 tokens per second)\n",
      "llama_print_timings:        eval time =     629.18 ms /    16 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:       total time =     921.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.17 ms /    49 runs   (    0.23 ms per token,  4385.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.09 ms /    50 tokens (    3.78 ms per token,   264.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1887.52 ms /    48 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:       total time =    2244.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    67 runs   (    0.22 ms per token,  4482.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.14 ms /    51 tokens (    3.71 ms per token,   269.64 tokens per second)\n",
      "llama_print_timings:        eval time =    3825.59 ms /    66 runs   (   57.96 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:       total time =    4236.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /    55 runs   (    0.24 ms per token,  4110.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     246.77 ms /    85 tokens (    2.90 ms per token,   344.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2453.23 ms /    54 runs   (   45.43 ms per token,    22.01 tokens per second)\n",
      "llama_print_timings:       total time =    2937.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    26 runs   (    0.22 ms per token,  4535.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.68 ms /    39 tokens (    5.22 ms per token,   191.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.94 ms /    25 runs   (   45.00 ms per token,    22.22 tokens per second)\n",
      "llama_print_timings:       total time =    1441.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    26 runs   (    0.23 ms per token,  4363.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     374.82 ms /    49 tokens (    7.65 ms per token,   130.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1069.62 ms /    25 runs   (   42.78 ms per token,    23.37 tokens per second)\n",
      "llama_print_timings:       total time =    1573.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.76 ms /    46 runs   (    0.23 ms per token,  4276.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.85 ms /    42 tokens (    4.73 ms per token,   211.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1901.03 ms /    45 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
      "llama_print_timings:       total time =    2261.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.69 ms /    49 runs   (    0.24 ms per token,  4191.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.44 ms /    42 tokens (    5.20 ms per token,   192.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2104.67 ms /    48 runs   (   43.85 ms per token,    22.81 tokens per second)\n",
      "llama_print_timings:       total time =    2494.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    46 runs   (    0.24 ms per token,  4234.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.13 ms /    39 tokens (    6.39 ms per token,   156.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2260.16 ms /    45 runs   (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:       total time =    2675.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    46 runs   (    0.24 ms per token,  4199.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.01 ms /    45 tokens (    5.13 ms per token,   194.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2281.52 ms /    45 runs   (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_print_timings:       total time =    2680.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.55 ms /    36 runs   (    0.24 ms per token,  4208.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.26 ms /    53 tokens (    4.16 ms per token,   240.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1698.43 ms /    35 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_print_timings:       total time =    2068.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    36 runs   (    0.24 ms per token,  4239.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     386.13 ms /    52 tokens (    7.43 ms per token,   134.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2008.24 ms /    35 runs   (   57.38 ms per token,    17.43 tokens per second)\n",
      "llama_print_timings:       total time =    2560.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    59 runs   (    0.23 ms per token,  4266.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.33 ms /    55 tokens (    3.77 ms per token,   265.28 tokens per second)\n",
      "llama_print_timings:        eval time =    2879.59 ms /    58 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_print_timings:       total time =    3295.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.59 ms /    62 runs   (    0.24 ms per token,  4249.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     239.68 ms /    70 tokens (    3.42 ms per token,   292.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2689.14 ms /    61 runs   (   44.08 ms per token,    22.68 tokens per second)\n",
      "llama_print_timings:       total time =    3161.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    26 runs   (    0.21 ms per token,  4672.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.98 ms /    40 tokens (    5.17 ms per token,   193.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1222.26 ms /    25 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:       total time =    1550.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    45 runs   (    0.24 ms per token,  4145.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     219.38 ms /    54 tokens (    4.06 ms per token,   246.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2399.04 ms /    44 runs   (   54.52 ms per token,    18.34 tokens per second)\n",
      "llama_print_timings:       total time =    2796.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    50 runs   (    0.22 ms per token,  4591.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.16 ms /    44 tokens (    5.14 ms per token,   194.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2280.76 ms /    49 runs   (   46.55 ms per token,    21.48 tokens per second)\n",
      "llama_print_timings:       total time =    2680.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    37 runs   (    0.23 ms per token,  4393.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     229.47 ms /    39 tokens (    5.88 ms per token,   169.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1658.41 ms /    36 runs   (   46.07 ms per token,    21.71 tokens per second)\n",
      "llama_print_timings:       total time =    2027.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    34 runs   (    0.22 ms per token,  4466.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     367.44 ms /    49 tokens (    7.50 ms per token,   133.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1394.34 ms /    33 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
      "llama_print_timings:       total time =    1906.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.09 ms /    57 runs   (    0.23 ms per token,  4355.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.56 ms /    55 tokens (    4.01 ms per token,   249.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2674.78 ms /    56 runs   (   47.76 ms per token,    20.94 tokens per second)\n",
      "llama_print_timings:       total time =    3102.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    30 runs   (    0.22 ms per token,  4562.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.58 ms /    52 tokens (    4.82 ms per token,   207.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1289.95 ms /    29 runs   (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_print_timings:       total time =    1678.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.19 ms /    48 runs   (    0.23 ms per token,  4289.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     213.20 ms /    49 tokens (    4.35 ms per token,   229.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2549.80 ms /    47 runs   (   54.25 ms per token,    18.43 tokens per second)\n",
      "llama_print_timings:       total time =    2943.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.54 ms /    63 runs   (    0.23 ms per token,  4334.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.52 ms /    43 tokens (    4.78 ms per token,   209.23 tokens per second)\n",
      "llama_print_timings:        eval time =    3308.57 ms /    62 runs   (   53.36 ms per token,    18.74 tokens per second)\n",
      "llama_print_timings:       total time =    3714.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.86 ms /    39 runs   (    0.23 ms per token,  4404.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.92 ms /    44 tokens (    4.68 ms per token,   213.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1797.99 ms /    38 runs   (   47.32 ms per token,    21.13 tokens per second)\n",
      "llama_print_timings:       total time =    2160.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    35 runs   (    0.23 ms per token,  4260.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.87 ms /    48 tokens (    4.52 ms per token,   221.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1601.52 ms /    34 runs   (   47.10 ms per token,    21.23 tokens per second)\n",
      "llama_print_timings:       total time =    1970.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    19 runs   (    0.23 ms per token,  4326.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     222.89 ms /    49 tokens (    4.55 ms per token,   219.84 tokens per second)\n",
      "llama_print_timings:        eval time =     920.85 ms /    18 runs   (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:       total time =    1270.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.14 ms /    27 runs   (    0.23 ms per token,  4400.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.52 ms /    40 tokens (    5.09 ms per token,   196.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1224.98 ms /    26 runs   (   47.11 ms per token,    21.22 tokens per second)\n",
      "llama_print_timings:       total time =    1563.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.59 ms /    49 runs   (    0.24 ms per token,  4229.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     233.88 ms /    45 tokens (    5.20 ms per token,   192.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2320.82 ms /    48 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_print_timings:       total time =    2732.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    13 runs   (    0.20 ms per token,  4935.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.74 ms /    38 tokens (    5.28 ms per token,   189.30 tokens per second)\n",
      "llama_print_timings:        eval time =     727.60 ms /    12 runs   (   60.63 ms per token,    16.49 tokens per second)\n",
      "llama_print_timings:       total time =    1014.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    27 runs   (    0.22 ms per token,  4534.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.33 ms /    39 tokens (    5.21 ms per token,   191.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.70 ms /    26 runs   (   42.26 ms per token,    23.66 tokens per second)\n",
      "llama_print_timings:       total time =    1416.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    30 runs   (    0.23 ms per token,  4413.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.53 ms /    57 tokens (    4.11 ms per token,   243.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1724.09 ms /    29 runs   (   59.45 ms per token,    16.82 tokens per second)\n",
      "llama_print_timings:       total time =    2104.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    37 runs   (    0.22 ms per token,  4458.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.37 ms /    46 tokens (    4.38 ms per token,   228.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2222.98 ms /    36 runs   (   61.75 ms per token,    16.19 tokens per second)\n",
      "llama_print_timings:       total time =    2576.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    37 runs   (    0.24 ms per token,  4150.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     225.54 ms /    56 tokens (    4.03 ms per token,   248.29 tokens per second)\n",
      "llama_print_timings:        eval time =    3110.02 ms /    36 runs   (   86.39 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    3515.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.52 ms /    58 runs   (    0.23 ms per token,  4290.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.10 ms /    47 tokens (    4.60 ms per token,   217.49 tokens per second)\n",
      "llama_print_timings:        eval time =    2261.70 ms /    57 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
      "llama_print_timings:       total time =    2673.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    41 runs   (    0.22 ms per token,  4468.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.97 ms /    32 tokens (    9.03 ms per token,   110.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1758.42 ms /    40 runs   (   43.96 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time =    2173.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.32 ms /    23 runs   (    0.23 ms per token,  4325.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.13 ms /    55 tokens (    3.71 ms per token,   269.44 tokens per second)\n",
      "llama_print_timings:        eval time =     937.94 ms /    22 runs   (   42.63 ms per token,    23.46 tokens per second)\n",
      "llama_print_timings:       total time =    1274.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    22 runs   (    0.21 ms per token,  4669.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.99 ms /    36 tokens (    5.47 ms per token,   182.75 tokens per second)\n",
      "llama_print_timings:        eval time =     854.91 ms /    21 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
      "llama_print_timings:       total time =    1147.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    23 runs   (    0.23 ms per token,  4422.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.52 ms /    51 tokens (    3.85 ms per token,   259.52 tokens per second)\n",
      "llama_print_timings:        eval time =     849.82 ms /    22 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
      "llama_print_timings:       total time =    1159.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    35 runs   (    0.23 ms per token,  4404.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.43 ms /    37 tokens (    4.90 ms per token,   203.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1514.10 ms /    34 runs   (   44.53 ms per token,    22.46 tokens per second)\n",
      "llama_print_timings:       total time =    1831.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    30 runs   (    0.22 ms per token,  4550.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.22 ms /    52 tokens (    3.81 ms per token,   262.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1290.41 ms /    29 runs   (   44.50 ms per token,    22.47 tokens per second)\n",
      "llama_print_timings:       total time =    1624.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.61 ms /    51 runs   (    0.23 ms per token,  4391.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.55 ms /    56 tokens (    3.42 ms per token,   292.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2041.20 ms /    50 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
      "llama_print_timings:       total time =    2418.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    28 runs   (    0.22 ms per token,  4503.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.72 ms /    44 tokens (    4.18 ms per token,   239.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.68 ms /    27 runs   (   41.95 ms per token,    23.84 tokens per second)\n",
      "llama_print_timings:       total time =    1431.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    22 runs   (    0.21 ms per token,  4674.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     176.47 ms /    34 tokens (    5.19 ms per token,   192.66 tokens per second)\n",
      "llama_print_timings:        eval time =     883.48 ms /    21 runs   (   42.07 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time =    1150.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    25 runs   (    0.24 ms per token,  4203.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     363.17 ms /    52 tokens (    6.98 ms per token,   143.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1603.80 ms /    24 runs   (   66.82 ms per token,    14.96 tokens per second)\n",
      "llama_print_timings:       total time =    2114.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    31 runs   (    0.25 ms per token,  4038.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     284.66 ms /    65 tokens (    4.38 ms per token,   228.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1470.81 ms /    30 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_print_timings:       total time =    1924.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    36 runs   (    0.23 ms per token,  4374.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.13 ms /    51 tokens (    4.26 ms per token,   234.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1562.89 ms /    35 runs   (   44.65 ms per token,    22.39 tokens per second)\n",
      "llama_print_timings:       total time =    1948.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    31 runs   (    0.22 ms per token,  4646.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.99 ms /    42 tokens (    4.40 ms per token,   227.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1178.18 ms /    30 runs   (   39.27 ms per token,    25.46 tokens per second)\n",
      "llama_print_timings:       total time =    1506.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /    23 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     305.92 ms /    61 tokens (    5.02 ms per token,   199.40 tokens per second)\n",
      "llama_print_timings:        eval time =     988.35 ms /    22 runs   (   44.93 ms per token,    22.26 tokens per second)\n",
      "llama_print_timings:       total time =    1430.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    36 runs   (    0.23 ms per token,  4276.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.11 ms /    47 tokens (    4.36 ms per token,   229.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2858.72 ms /    35 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    3213.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      20.04 ms /    84 runs   (    0.24 ms per token,  4192.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.69 ms /    50 tokens (    3.85 ms per token,   259.48 tokens per second)\n",
      "llama_print_timings:        eval time =    4519.81 ms /    83 runs   (   54.46 ms per token,    18.36 tokens per second)\n",
      "llama_print_timings:       total time =    4972.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    18 runs   (    0.22 ms per token,  4567.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.66 ms /    39 tokens (    4.89 ms per token,   204.55 tokens per second)\n",
      "llama_print_timings:        eval time =     657.17 ms /    17 runs   (   38.66 ms per token,    25.87 tokens per second)\n",
      "llama_print_timings:       total time =     941.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.53 ms /    44 runs   (    0.24 ms per token,  4177.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.82 ms /    53 tokens (    4.92 ms per token,   203.20 tokens per second)\n",
      "llama_print_timings:        eval time =    2627.39 ms /    43 runs   (   61.10 ms per token,    16.37 tokens per second)\n",
      "llama_print_timings:       total time =    3072.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    54 runs   (    0.23 ms per token,  4349.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.60 ms /    52 tokens (    5.34 ms per token,   187.32 tokens per second)\n",
      "llama_print_timings:        eval time =    2539.77 ms /    53 runs   (   47.92 ms per token,    20.87 tokens per second)\n",
      "llama_print_timings:       total time =    3007.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    30 runs   (    0.22 ms per token,  4500.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.05 ms /    40 tokens (    4.83 ms per token,   207.20 tokens per second)\n",
      "llama_print_timings:        eval time =    2020.18 ms /    29 runs   (   69.66 ms per token,    14.36 tokens per second)\n",
      "llama_print_timings:       total time =    2334.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.90 ms /    34 runs   (    0.23 ms per token,  4302.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     235.74 ms /    62 tokens (    3.80 ms per token,   263.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2143.49 ms /    33 runs   (   64.95 ms per token,    15.40 tokens per second)\n",
      "llama_print_timings:       total time =    2555.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.52 ms /    50 runs   (    0.23 ms per token,  4342.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.67 ms /    56 tokens (    3.69 ms per token,   270.97 tokens per second)\n",
      "llama_print_timings:        eval time =    2192.90 ms /    49 runs   (   44.75 ms per token,    22.34 tokens per second)\n",
      "llama_print_timings:       total time =    2584.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /    13 runs   (    0.21 ms per token,  4793.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.51 ms /    38 tokens (    5.70 ms per token,   175.51 tokens per second)\n",
      "llama_print_timings:        eval time =     604.61 ms /    12 runs   (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_print_timings:       total time =     912.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    51 runs   (    0.24 ms per token,  4200.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.83 ms /    55 tokens (    3.58 ms per token,   279.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2275.07 ms /    50 runs   (   45.50 ms per token,    21.98 tokens per second)\n",
      "llama_print_timings:       total time =    2659.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    25 runs   (    0.22 ms per token,  4641.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.09 ms /    43 tokens (    4.47 ms per token,   223.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.54 ms /    24 runs   (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_print_timings:       total time =    1509.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    20 runs   (    0.22 ms per token,  4500.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.39 ms /    47 tokens (    3.94 ms per token,   253.53 tokens per second)\n",
      "llama_print_timings:        eval time =     732.95 ms /    19 runs   (   38.58 ms per token,    25.92 tokens per second)\n",
      "llama_print_timings:       total time =    1021.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    26 runs   (    0.22 ms per token,  4445.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.97 ms /    41 tokens (    5.41 ms per token,   184.71 tokens per second)\n",
      "llama_print_timings:        eval time =     988.83 ms /    25 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
      "llama_print_timings:       total time =    1320.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.57 ms /    73 runs   (    0.23 ms per token,  4406.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.67 ms /    47 tokens (    3.95 ms per token,   253.13 tokens per second)\n",
      "llama_print_timings:        eval time =    3619.11 ms /    72 runs   (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_print_timings:       total time =    4028.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.38 ms /    62 runs   (    0.23 ms per token,  4311.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.49 ms /    66 tokens (    3.96 ms per token,   252.40 tokens per second)\n",
      "llama_print_timings:        eval time =    3001.02 ms /    61 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_print_timings:       total time =    3489.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    45 runs   (    0.23 ms per token,  4430.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.84 ms /    37 tokens (    5.51 ms per token,   181.51 tokens per second)\n",
      "llama_print_timings:        eval time =    2116.69 ms /    44 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_print_timings:       total time =    2474.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      20.98 ms /    90 runs   (    0.23 ms per token,  4290.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.09 ms /    62 tokens (    3.57 ms per token,   280.43 tokens per second)\n",
      "llama_print_timings:        eval time =    4108.29 ms /    89 runs   (   46.16 ms per token,    21.66 tokens per second)\n",
      "llama_print_timings:       total time =    4610.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    42 runs   (    0.22 ms per token,  4475.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.77 ms /    43 tokens (    4.55 ms per token,   219.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1578.65 ms /    41 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
      "llama_print_timings:       total time =    1931.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    32 runs   (    0.24 ms per token,  4104.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.51 ms /    56 tokens (    4.60 ms per token,   217.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1559.35 ms /    31 runs   (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:       total time =    1970.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    47 runs   (    0.23 ms per token,  4336.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.93 ms /    56 tokens (    3.59 ms per token,   278.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1960.93 ms /    46 runs   (   42.63 ms per token,    23.46 tokens per second)\n",
      "llama_print_timings:       total time =    2341.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    25 runs   (    0.21 ms per token,  4712.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.29 ms /    48 tokens (    3.99 ms per token,   250.93 tokens per second)\n",
      "llama_print_timings:        eval time =     880.31 ms /    24 runs   (   36.68 ms per token,    27.26 tokens per second)\n",
      "llama_print_timings:       total time =    1184.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.51 ms /    52 runs   (    0.22 ms per token,  4518.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.39 ms /    49 tokens (    3.87 ms per token,   258.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2086.23 ms /    51 runs   (   40.91 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time =    2461.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    41 runs   (    0.23 ms per token,  4353.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.51 ms /    51 tokens (    3.83 ms per token,   260.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1921.33 ms /    40 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_print_timings:       total time =    2274.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.72 ms /    37 runs   (    0.24 ms per token,  4244.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.25 ms /    49 tokens (    4.17 ms per token,   239.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1483.22 ms /    36 runs   (   41.20 ms per token,    24.27 tokens per second)\n",
      "llama_print_timings:       total time =    1837.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.79 ms /    48 runs   (    0.22 ms per token,  4448.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.62 ms /    40 tokens (    4.52 ms per token,   221.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1982.62 ms /    47 runs   (   42.18 ms per token,    23.71 tokens per second)\n",
      "llama_print_timings:       total time =    2316.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.66 ms /    55 runs   (    0.23 ms per token,  4344.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.56 ms /    39 tokens (    4.76 ms per token,   210.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2169.20 ms /    54 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
      "llama_print_timings:       total time =    2527.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.65 ms /    40 runs   (    0.22 ms per token,  4623.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.88 ms /    46 tokens (    4.06 ms per token,   246.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1515.08 ms /    39 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
      "llama_print_timings:       total time =    1842.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.76 ms /    62 runs   (    0.22 ms per token,  4505.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.20 ms /    39 tokens (    4.67 ms per token,   214.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2365.24 ms /    61 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
      "llama_print_timings:       total time =    2738.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    25 runs   (    0.22 ms per token,  4570.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.59 ms /    52 tokens (    3.63 ms per token,   275.73 tokens per second)\n",
      "llama_print_timings:        eval time =     891.02 ms /    24 runs   (   37.13 ms per token,    26.94 tokens per second)\n",
      "llama_print_timings:       total time =    1196.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    57 runs   (    0.23 ms per token,  4328.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.88 ms /    50 tokens (    3.78 ms per token,   264.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2322.28 ms /    56 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
      "llama_print_timings:       total time =    2698.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    49 runs   (    0.24 ms per token,  4232.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.66 ms /    57 tokens (    3.34 ms per token,   298.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1996.12 ms /    48 runs   (   41.59 ms per token,    24.05 tokens per second)\n",
      "llama_print_timings:       total time =    2372.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    46 runs   (    0.24 ms per token,  4244.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.34 ms /    52 tokens (    3.81 ms per token,   262.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2530.79 ms /    45 runs   (   56.24 ms per token,    17.78 tokens per second)\n",
      "llama_print_timings:       total time =    2917.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    29 runs   (    0.23 ms per token,  4340.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.90 ms /    46 tokens (    4.00 ms per token,   250.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1238.64 ms /    28 runs   (   44.24 ms per token,    22.61 tokens per second)\n",
      "llama_print_timings:       total time =    1547.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    56 runs   (    0.22 ms per token,  4451.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.69 ms /    68 tokens (    3.11 ms per token,   321.22 tokens per second)\n",
      "llama_print_timings:        eval time =    2174.87 ms /    55 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
      "llama_print_timings:       total time =    2605.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.84 ms /    74 runs   (    0.23 ms per token,  4395.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.50 ms /    62 tokens (    3.20 ms per token,   312.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2784.90 ms /    73 runs   (   38.15 ms per token,    26.21 tokens per second)\n",
      "llama_print_timings:       total time =    3213.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    44 runs   (    0.23 ms per token,  4362.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.76 ms /    45 tokens (    4.31 ms per token,   232.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1685.98 ms /    43 runs   (   39.21 ms per token,    25.50 tokens per second)\n",
      "llama_print_timings:       total time =    2031.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    40 runs   (    0.23 ms per token,  4324.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.61 ms /    57 tokens (    3.47 ms per token,   288.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1599.25 ms /    39 runs   (   41.01 ms per token,    24.39 tokens per second)\n",
      "llama_print_timings:       total time =    1951.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    30 runs   (    0.22 ms per token,  4480.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.25 ms /    41 tokens (    4.42 ms per token,   226.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.73 ms /    29 runs   (   37.89 ms per token,    26.39 tokens per second)\n",
      "llama_print_timings:       total time =    1396.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.84 ms /    49 runs   (    0.22 ms per token,  4518.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.91 ms /    53 tokens (    3.58 ms per token,   279.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1934.71 ms /    48 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
      "llama_print_timings:       total time =    2292.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    22 runs   (    0.21 ms per token,  4824.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.92 ms /    34 tokens (    5.23 ms per token,   191.10 tokens per second)\n",
      "llama_print_timings:        eval time =     922.60 ms /    21 runs   (   43.93 ms per token,    22.76 tokens per second)\n",
      "llama_print_timings:       total time =    1187.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.96 ms /    76 runs   (    0.24 ms per token,  4232.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.67 ms /    48 tokens (    3.97 ms per token,   251.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2840.80 ms /    75 runs   (   37.88 ms per token,    26.40 tokens per second)\n",
      "llama_print_timings:       total time =    3259.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    33 runs   (    0.23 ms per token,  4369.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     344.60 ms /    76 tokens (    4.53 ms per token,   220.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2320.96 ms /    32 runs   (   72.53 ms per token,    13.79 tokens per second)\n",
      "llama_print_timings:       total time =    2846.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4815.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.48 ms /    71 tokens (    3.12 ms per token,   320.57 tokens per second)\n",
      "llama_print_timings:        eval time =      69.20 ms /     2 runs   (   34.60 ms per token,    28.90 tokens per second)\n",
      "llama_print_timings:       total time =     398.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    25 runs   (    0.23 ms per token,  4291.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.05 ms /    46 tokens (    4.50 ms per token,   222.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1403.07 ms /    24 runs   (   58.46 ms per token,    17.11 tokens per second)\n",
      "llama_print_timings:       total time =    1740.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    37 runs   (    0.22 ms per token,  4471.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.47 ms /    48 tokens (    4.41 ms per token,   226.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1556.92 ms /    36 runs   (   43.25 ms per token,    23.12 tokens per second)\n",
      "llama_print_timings:       total time =    1911.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  5008.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.71 ms /    48 tokens (    3.93 ms per token,   254.36 tokens per second)\n",
      "llama_print_timings:        eval time =     200.68 ms /     2 runs   (  100.34 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =     473.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    21 runs   (    0.22 ms per token,  4527.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.83 ms /    56 tokens (    3.48 ms per token,   287.43 tokens per second)\n",
      "llama_print_timings:        eval time =     853.49 ms /    20 runs   (   42.67 ms per token,    23.43 tokens per second)\n",
      "llama_print_timings:       total time =    1169.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    31 runs   (    0.22 ms per token,  4481.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.07 ms /    52 tokens (    4.02 ms per token,   248.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.00 ms /    30 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
      "llama_print_timings:       total time =    1510.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    36 runs   (    0.23 ms per token,  4344.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.10 ms /    64 tokens (    3.11 ms per token,   321.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1455.91 ms /    35 runs   (   41.60 ms per token,    24.04 tokens per second)\n",
      "llama_print_timings:       total time =    1821.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    41 runs   (    0.22 ms per token,  4580.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.04 ms /    42 tokens (    4.79 ms per token,   208.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1753.40 ms /    40 runs   (   43.84 ms per token,    22.81 tokens per second)\n",
      "llama_print_timings:       total time =    2103.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    22 runs   (    0.22 ms per token,  4457.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.03 ms /    41 tokens (    4.59 ms per token,   218.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1316.55 ms /    21 runs   (   62.69 ms per token,    15.95 tokens per second)\n",
      "llama_print_timings:       total time =    1614.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    38 runs   (    0.22 ms per token,  4491.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.56 ms /    62 tokens (    3.65 ms per token,   273.66 tokens per second)\n",
      "llama_print_timings:        eval time =    2324.62 ms /    37 runs   (   62.83 ms per token,    15.92 tokens per second)\n",
      "llama_print_timings:       total time =    2728.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.91 ms /    66 runs   (    0.23 ms per token,  4428.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.54 ms /    46 tokens (    5.03 ms per token,   198.67 tokens per second)\n",
      "llama_print_timings:        eval time =    3285.38 ms /    65 runs   (   50.54 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:       total time =    3725.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.29 ms /    73 runs   (    0.24 ms per token,  4223.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.56 ms /    61 tokens (    3.34 ms per token,   299.67 tokens per second)\n",
      "llama_print_timings:        eval time =    3083.12 ms /    72 runs   (   42.82 ms per token,    23.35 tokens per second)\n",
      "llama_print_timings:       total time =    3534.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    33 runs   (    0.23 ms per token,  4364.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.98 ms /    57 tokens (    3.49 ms per token,   286.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1761.01 ms /    32 runs   (   55.03 ms per token,    18.17 tokens per second)\n",
      "llama_print_timings:       total time =    2108.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    32 runs   (    0.23 ms per token,  4334.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.11 ms /    55 tokens (    4.26 ms per token,   234.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1379.59 ms /    31 runs   (   44.50 ms per token,    22.47 tokens per second)\n",
      "llama_print_timings:       total time =    1768.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.74 ms /    47 runs   (    0.23 ms per token,  4375.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     227.60 ms /    47 tokens (    4.84 ms per token,   206.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1852.67 ms /    46 runs   (   40.28 ms per token,    24.83 tokens per second)\n",
      "llama_print_timings:       total time =    2250.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.92 ms /    66 runs   (    0.23 ms per token,  4422.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.26 ms /    68 tokens (    3.24 ms per token,   308.73 tokens per second)\n",
      "llama_print_timings:        eval time =    3082.68 ms /    65 runs   (   47.43 ms per token,    21.09 tokens per second)\n",
      "llama_print_timings:       total time =    3533.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    31 runs   (    0.23 ms per token,  4345.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.56 ms /    49 tokens (    4.01 ms per token,   249.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1220.43 ms /    30 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =    1557.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    27 runs   (    0.23 ms per token,  4419.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.76 ms /    58 tokens (    3.56 ms per token,   280.51 tokens per second)\n",
      "llama_print_timings:        eval time =     985.21 ms /    26 runs   (   37.89 ms per token,    26.39 tokens per second)\n",
      "llama_print_timings:       total time =    1329.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.00 ms /    56 runs   (    0.23 ms per token,  4309.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.49 ms /    66 tokens (    3.22 ms per token,   310.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2125.57 ms /    55 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
      "llama_print_timings:       total time =    2557.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    34 runs   (    0.23 ms per token,  4413.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.86 ms /    51 tokens (    3.70 ms per token,   270.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1296.40 ms /    33 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
      "llama_print_timings:       total time =    1624.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    19 runs   (    0.22 ms per token,  4555.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.94 ms /    47 tokens (    4.47 ms per token,   223.88 tokens per second)\n",
      "llama_print_timings:        eval time =     718.37 ms /    18 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:       total time =    1037.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    38 runs   (    0.23 ms per token,  4329.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     228.83 ms /    65 tokens (    3.52 ms per token,   284.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1590.12 ms /    37 runs   (   42.98 ms per token,    23.27 tokens per second)\n",
      "llama_print_timings:       total time =    1994.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    31 runs   (    0.22 ms per token,  4524.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.86 ms /    48 tokens (    3.87 ms per token,   258.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1334.26 ms /    30 runs   (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_print_timings:       total time =    1647.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    29 runs   (    0.22 ms per token,  4590.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.11 ms /    45 tokens (    4.11 ms per token,   243.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1035.26 ms /    28 runs   (   36.97 ms per token,    27.05 tokens per second)\n",
      "llama_print_timings:       total time =    1337.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    44 runs   (    0.22 ms per token,  4534.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.14 ms /    56 tokens (    3.41 ms per token,   292.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1944.35 ms /    43 runs   (   45.22 ms per token,    22.12 tokens per second)\n",
      "llama_print_timings:       total time =    2300.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.26 ms /    15 runs   (    0.22 ms per token,  4595.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.46 ms /    51 tokens (    3.79 ms per token,   263.62 tokens per second)\n",
      "llama_print_timings:        eval time =     558.44 ms /    14 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:       total time =     851.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.65 ms /    46 runs   (    0.23 ms per token,  4320.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.45 ms /    66 tokens (    3.31 ms per token,   302.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2116.21 ms /    45 runs   (   47.03 ms per token,    21.26 tokens per second)\n",
      "llama_print_timings:       total time =    2524.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    40 runs   (    0.23 ms per token,  4374.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.84 ms /    64 tokens (    3.28 ms per token,   305.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.95 ms /    39 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
      "llama_print_timings:       total time =    1881.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    36 runs   (    0.22 ms per token,  4646.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.46 ms /    52 tokens (    3.78 ms per token,   264.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1346.83 ms /    35 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
      "llama_print_timings:       total time =    1688.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    36 runs   (    0.23 ms per token,  4319.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     210.55 ms /    72 tokens (    2.92 ms per token,   341.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1352.46 ms /    35 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
      "llama_print_timings:       total time =    1744.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.60 ms /    73 runs   (    0.23 ms per token,  4398.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.24 ms /    59 tokens (    3.41 ms per token,   293.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2739.04 ms /    72 runs   (   38.04 ms per token,    26.29 tokens per second)\n",
      "llama_print_timings:       total time =    3168.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    30 runs   (    0.23 ms per token,  4369.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     232.85 ms /    73 tokens (    3.19 ms per token,   313.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1116.71 ms /    29 runs   (   38.51 ms per token,    25.97 tokens per second)\n",
      "llama_print_timings:       total time =    1522.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    40 runs   (    0.22 ms per token,  4455.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     241.06 ms /    55 tokens (    4.38 ms per token,   228.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1765.14 ms /    39 runs   (   45.26 ms per token,    22.09 tokens per second)\n",
      "llama_print_timings:       total time =    2169.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    30 runs   (    0.23 ms per token,  4339.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.80 ms /    49 tokens (    4.04 ms per token,   247.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1390.60 ms /    29 runs   (   47.95 ms per token,    20.85 tokens per second)\n",
      "llama_print_timings:       total time =    1732.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    53 runs   (    0.24 ms per token,  4246.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.77 ms /    61 tokens (    3.36 ms per token,   297.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2080.48 ms /    52 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:       total time =    2483.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.68 ms /    54 runs   (    0.23 ms per token,  4259.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.60 ms /    53 tokens (    3.92 ms per token,   255.30 tokens per second)\n",
      "llama_print_timings:        eval time =    2717.12 ms /    53 runs   (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:       total time =    3122.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.25 ms /    36 runs   (    0.23 ms per token,  4362.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.74 ms /    58 tokens (    3.72 ms per token,   268.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1787.17 ms /    35 runs   (   51.06 ms per token,    19.58 tokens per second)\n",
      "llama_print_timings:       total time =    2165.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     3 runs   (    0.23 ms per token,  4431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     228.04 ms /    70 tokens (    3.26 ms per token,   306.96 tokens per second)\n",
      "llama_print_timings:        eval time =     173.28 ms /     2 runs   (   86.64 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     503.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    52 runs   (    0.23 ms per token,  4436.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.52 ms /    48 tokens (    4.14 ms per token,   241.80 tokens per second)\n",
      "llama_print_timings:        eval time =    4292.14 ms /    51 runs   (   84.16 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    4672.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    37 runs   (    0.23 ms per token,  4371.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.94 ms /    47 tokens (    4.45 ms per token,   224.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1733.97 ms /    36 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_print_timings:       total time =    2085.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    29 runs   (    0.23 ms per token,  4262.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     227.73 ms /    45 tokens (    5.06 ms per token,   197.60 tokens per second)\n",
      "llama_print_timings:        eval time =    2155.28 ms /    28 runs   (   76.97 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =    2522.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    46 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.62 ms /    48 tokens (    4.20 ms per token,   238.07 tokens per second)\n",
      "llama_print_timings:        eval time =    3276.28 ms /    45 runs   (   72.81 ms per token,    13.74 tokens per second)\n",
      "llama_print_timings:       total time =    3658.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.91 ms /    62 runs   (    0.24 ms per token,  4158.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.05 ms /    71 tokens (    3.01 ms per token,   331.69 tokens per second)\n",
      "llama_print_timings:        eval time =    3836.91 ms /    61 runs   (   62.90 ms per token,    15.90 tokens per second)\n",
      "llama_print_timings:       total time =    4288.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    40 runs   (    0.23 ms per token,  4432.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.53 ms /    54 tokens (    3.68 ms per token,   272.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2225.75 ms /    39 runs   (   57.07 ms per token,    17.52 tokens per second)\n",
      "llama_print_timings:       total time =    2584.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    29 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     331.72 ms /    45 tokens (    7.37 ms per token,   135.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1187.27 ms /    28 runs   (   42.40 ms per token,    23.58 tokens per second)\n",
      "llama_print_timings:       total time =    1639.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    33 runs   (    0.23 ms per token,  4303.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     235.21 ms /    69 tokens (    3.41 ms per token,   293.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1849.11 ms /    32 runs   (   57.78 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:       total time =    2257.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.33 ms /    40 runs   (    0.23 ms per token,  4286.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.08 ms /    64 tokens (    3.20 ms per token,   312.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1665.87 ms /    39 runs   (   42.71 ms per token,    23.41 tokens per second)\n",
      "llama_print_timings:       total time =    2050.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.85 ms /    56 runs   (    0.23 ms per token,  4358.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.45 ms /    57 tokens (    3.46 ms per token,   288.68 tokens per second)\n",
      "llama_print_timings:        eval time =    2355.59 ms /    55 runs   (   42.83 ms per token,    23.35 tokens per second)\n",
      "llama_print_timings:       total time =    2750.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    44 runs   (    0.23 ms per token,  4342.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.95 ms /    59 tokens (    3.46 ms per token,   289.28 tokens per second)\n",
      "llama_print_timings:        eval time =    2593.52 ms /    43 runs   (   60.31 ms per token,    16.58 tokens per second)\n",
      "llama_print_timings:       total time =    2972.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    53 runs   (    0.23 ms per token,  4259.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     347.54 ms /    69 tokens (    5.04 ms per token,   198.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2393.53 ms /    52 runs   (   46.03 ms per token,    21.73 tokens per second)\n",
      "llama_print_timings:       total time =    2951.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.11 ms /    82 runs   (    0.23 ms per token,  4290.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.97 ms /    63 tokens (    3.98 ms per token,   251.03 tokens per second)\n",
      "llama_print_timings:        eval time =    4948.57 ms /    81 runs   (   61.09 ms per token,    16.37 tokens per second)\n",
      "llama_print_timings:       total time =    5484.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      23.86 ms /   102 runs   (    0.23 ms per token,  4274.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     246.60 ms /    45 tokens (    5.48 ms per token,   182.48 tokens per second)\n",
      "llama_print_timings:        eval time =    6729.82 ms /   101 runs   (   66.63 ms per token,    15.01 tokens per second)\n",
      "llama_print_timings:       total time =    7282.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.57 ms /    42 runs   (    0.25 ms per token,  3974.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     372.38 ms /    73 tokens (    5.10 ms per token,   196.04 tokens per second)\n",
      "llama_print_timings:        eval time =    3197.72 ms /    41 runs   (   77.99 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    3813.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.32 ms /    23 runs   (    0.23 ms per token,  4325.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.39 ms /    58 tokens (    3.46 ms per token,   289.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1955.32 ms /    22 runs   (   88.88 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    2294.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    30 runs   (    0.23 ms per token,  4299.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     224.01 ms /    80 tokens (    2.80 ms per token,   357.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1878.74 ms /    29 runs   (   64.78 ms per token,    15.44 tokens per second)\n",
      "llama_print_timings:       total time =    2280.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    32 runs   (    0.22 ms per token,  4520.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     237.96 ms /    56 tokens (    4.25 ms per token,   235.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1369.70 ms /    31 runs   (   44.18 ms per token,    22.63 tokens per second)\n",
      "llama_print_timings:       total time =    1757.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.23 ms /    49 runs   (    0.23 ms per token,  4362.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.68 ms /    52 tokens (    3.94 ms per token,   254.05 tokens per second)\n",
      "llama_print_timings:        eval time =    3065.50 ms /    48 runs   (   63.86 ms per token,    15.66 tokens per second)\n",
      "llama_print_timings:       total time =    3459.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    37 runs   (    0.23 ms per token,  4354.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.36 ms /    50 tokens (    3.91 ms per token,   255.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2098.01 ms /    36 runs   (   58.28 ms per token,    17.16 tokens per second)\n",
      "llama_print_timings:       total time =    2454.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    24 runs   (    0.24 ms per token,  4167.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.34 ms /    56 tokens (    3.49 ms per token,   286.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1746.45 ms /    23 runs   (   75.93 ms per token,    13.17 tokens per second)\n",
      "llama_print_timings:       total time =    2098.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    27 runs   (    0.23 ms per token,  4383.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.54 ms /    61 tokens (    3.29 ms per token,   304.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1967.51 ms /    26 runs   (   75.67 ms per token,    13.21 tokens per second)\n",
      "llama_print_timings:       total time =    2323.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    49 runs   (    0.22 ms per token,  4550.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.19 ms /    46 tokens (    4.48 ms per token,   223.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2370.05 ms /    48 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_print_timings:       total time =    2741.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    23 runs   (    0.23 ms per token,  4375.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.41 ms /    63 tokens (    3.21 ms per token,   311.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1003.22 ms /    22 runs   (   45.60 ms per token,    21.93 tokens per second)\n",
      "llama_print_timings:       total time =    1341.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.91 ms /    42 runs   (    0.24 ms per token,  4238.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.56 ms /    53 tokens (    3.88 ms per token,   257.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2132.19 ms /    41 runs   (   52.00 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:       total time =    2508.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.59 ms /    68 runs   (    0.23 ms per token,  4362.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.20 ms /    65 tokens (    3.19 ms per token,   313.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3624.98 ms /    67 runs   (   54.10 ms per token,    18.48 tokens per second)\n",
      "llama_print_timings:       total time =    4079.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    37 runs   (    0.22 ms per token,  4612.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.06 ms /    44 tokens (    5.77 ms per token,   173.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1668.60 ms /    36 runs   (   46.35 ms per token,    21.57 tokens per second)\n",
      "llama_print_timings:       total time =    2062.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    34 runs   (    0.22 ms per token,  4549.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.04 ms /    48 tokens (    3.94 ms per token,   253.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1618.38 ms /    33 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:       total time =    1940.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    25 runs   (    0.22 ms per token,  4502.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.74 ms /    55 tokens (    3.69 ms per token,   271.29 tokens per second)\n",
      "llama_print_timings:        eval time =     875.65 ms /    24 runs   (   36.49 ms per token,    27.41 tokens per second)\n",
      "llama_print_timings:       total time =    1199.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.18 ms /    66 tokens (    3.26 ms per token,   306.72 tokens per second)\n",
      "llama_print_timings:        eval time =      70.17 ms /     2 runs   (   35.09 ms per token,    28.50 tokens per second)\n",
      "llama_print_timings:       total time =     386.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /    17 runs   (    0.21 ms per token,  4783.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.35 ms /    51 tokens (    4.03 ms per token,   248.35 tokens per second)\n",
      "llama_print_timings:        eval time =     585.39 ms /    16 runs   (   36.59 ms per token,    27.33 tokens per second)\n",
      "llama_print_timings:       total time =     894.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.15 ms /    24 runs   (    0.21 ms per token,  4659.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.92 ms /    40 tokens (    4.75 ms per token,   210.62 tokens per second)\n",
      "llama_print_timings:        eval time =     905.38 ms /    23 runs   (   39.36 ms per token,    25.40 tokens per second)\n",
      "llama_print_timings:       total time =    1198.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.70 ms /    46 runs   (    0.23 ms per token,  4300.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.07 ms /    67 tokens (    3.20 ms per token,   312.99 tokens per second)\n",
      "llama_print_timings:        eval time =    2446.75 ms /    45 runs   (   54.37 ms per token,    18.39 tokens per second)\n",
      "llama_print_timings:       total time =    2859.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     3 runs   (    0.21 ms per token,  4777.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.96 ms /    60 tokens (    3.58 ms per token,   279.12 tokens per second)\n",
      "llama_print_timings:        eval time =      70.69 ms /     2 runs   (   35.35 ms per token,    28.29 tokens per second)\n",
      "llama_print_timings:       total time =     379.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     3 runs   (    0.21 ms per token,  4870.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.65 ms /    53 tokens (    3.90 ms per token,   256.47 tokens per second)\n",
      "llama_print_timings:        eval time =      67.54 ms /     2 runs   (   33.77 ms per token,    29.61 tokens per second)\n",
      "llama_print_timings:       total time =     353.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    40 runs   (    0.23 ms per token,  4427.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     245.99 ms /    58 tokens (    4.24 ms per token,   235.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1700.11 ms /    39 runs   (   43.59 ms per token,    22.94 tokens per second)\n",
      "llama_print_timings:       total time =    2110.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.81 ms /    25 runs   (    0.23 ms per token,  4299.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.51 ms /    51 tokens (    4.52 ms per token,   221.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.17 ms /    24 runs   (   47.34 ms per token,    21.12 tokens per second)\n",
      "llama_print_timings:       total time =    1486.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    22 runs   (    0.22 ms per token,  4645.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.51 ms /    44 tokens (    5.76 ms per token,   173.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1059.22 ms /    21 runs   (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_print_timings:       total time =    1414.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.12 ms /    46 runs   (    0.24 ms per token,  4138.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.91 ms /    58 tokens (    3.98 ms per token,   251.19 tokens per second)\n",
      "llama_print_timings:        eval time =    4035.00 ms /    45 runs   (   89.67 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    4463.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.41 ms /    41 runs   (    0.23 ms per token,  4356.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.88 ms /    52 tokens (    5.50 ms per token,   181.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1722.77 ms /    40 runs   (   43.07 ms per token,    23.22 tokens per second)\n",
      "llama_print_timings:       total time =    2172.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    22 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     237.21 ms /    61 tokens (    3.89 ms per token,   257.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1020.99 ms /    21 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_print_timings:       total time =    1384.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.36 ms /    44 runs   (    0.24 ms per token,  4246.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.75 ms /    50 tokens (    4.30 ms per token,   232.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2031.89 ms /    43 runs   (   47.25 ms per token,    21.16 tokens per second)\n",
      "llama_print_timings:       total time =    2420.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    38 runs   (    0.22 ms per token,  4462.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.90 ms /    64 tokens (    3.67 ms per token,   272.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2095.07 ms /    37 runs   (   56.62 ms per token,    17.66 tokens per second)\n",
      "llama_print_timings:       total time =    2514.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.16 ms /    45 runs   (    0.23 ms per token,  4428.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     239.72 ms /    54 tokens (    4.44 ms per token,   225.26 tokens per second)\n",
      "llama_print_timings:        eval time =    2571.76 ms /    44 runs   (   58.45 ms per token,    17.11 tokens per second)\n",
      "llama_print_timings:       total time =    3009.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.24 ms /    45 runs   (    0.23 ms per token,  4395.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     222.53 ms /    43 tokens (    5.18 ms per token,   193.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2425.22 ms /    44 runs   (   55.12 ms per token,    18.14 tokens per second)\n",
      "llama_print_timings:       total time =    2819.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.84 ms /    44 runs   (    0.22 ms per token,  4472.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.27 ms /    60 tokens (    3.49 ms per token,   286.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2106.19 ms /    43 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_print_timings:       total time =    2494.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    39 runs   (    0.22 ms per token,  4476.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.37 ms /    60 tokens (    4.16 ms per token,   240.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1719.83 ms /    38 runs   (   45.26 ms per token,    22.10 tokens per second)\n",
      "llama_print_timings:       total time =    2144.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /    16 runs   (    0.22 ms per token,  4478.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.27 ms /    43 tokens (    4.63 ms per token,   215.79 tokens per second)\n",
      "llama_print_timings:        eval time =     623.11 ms /    15 runs   (   41.54 ms per token,    24.07 tokens per second)\n",
      "llama_print_timings:       total time =     915.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    21 runs   (    0.22 ms per token,  4449.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.51 ms /    50 tokens (    4.01 ms per token,   249.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1074.25 ms /    20 runs   (   53.71 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:       total time =    1410.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.93 ms /    40 runs   (    0.22 ms per token,  4477.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.47 ms /    56 tokens (    3.60 ms per token,   277.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1811.64 ms /    39 runs   (   46.45 ms per token,    21.53 tokens per second)\n",
      "llama_print_timings:       total time =    2181.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.72 ms /    16 runs   (    0.23 ms per token,  4299.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     309.21 ms /    66 tokens (    4.68 ms per token,   213.45 tokens per second)\n",
      "llama_print_timings:        eval time =     712.25 ms /    15 runs   (   47.48 ms per token,    21.06 tokens per second)\n",
      "llama_print_timings:       total time =    1151.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.78 ms /    85 runs   (    0.23 ms per token,  4298.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.59 ms /    52 tokens (    5.74 ms per token,   174.15 tokens per second)\n",
      "llama_print_timings:        eval time =    3855.25 ms /    84 runs   (   45.90 ms per token,    21.79 tokens per second)\n",
      "llama_print_timings:       total time =    4415.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    38 runs   (    0.23 ms per token,  4438.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.36 ms /    62 tokens (    4.36 ms per token,   229.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1872.05 ms /    37 runs   (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_print_timings:       total time =    2308.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    20 runs   (    0.23 ms per token,  4375.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.67 ms /    60 tokens (    3.38 ms per token,   296.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.56 ms /    19 runs   (   57.03 ms per token,    17.53 tokens per second)\n",
      "llama_print_timings:       total time =    1411.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.47 ms /    45 runs   (    0.23 ms per token,  4295.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.73 ms /    66 tokens (    3.87 ms per token,   258.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2346.21 ms /    44 runs   (   53.32 ms per token,    18.75 tokens per second)\n",
      "llama_print_timings:       total time =    2800.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    47 runs   (    0.23 ms per token,  4317.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.07 ms /    49 tokens (    4.02 ms per token,   248.64 tokens per second)\n",
      "llama_print_timings:        eval time =    3096.44 ms /    46 runs   (   67.31 ms per token,    14.86 tokens per second)\n",
      "llama_print_timings:       total time =    3471.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    25 runs   (    0.22 ms per token,  4475.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.62 ms /    61 tokens (    3.85 ms per token,   260.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1378.95 ms /    24 runs   (   57.46 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:       total time =    1752.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    25 runs   (    0.23 ms per token,  4416.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.36 ms /    59 tokens (    4.46 ms per token,   224.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1457.99 ms /    24 runs   (   60.75 ms per token,    16.46 tokens per second)\n",
      "llama_print_timings:       total time =    1860.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    49 runs   (    0.25 ms per token,  4035.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     307.87 ms /    66 tokens (    4.66 ms per token,   214.38 tokens per second)\n",
      "llama_print_timings:        eval time =    4666.15 ms /    48 runs   (   97.21 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =    5218.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    26 runs   (    0.22 ms per token,  4627.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.99 ms /    47 tokens (    4.21 ms per token,   237.38 tokens per second)\n",
      "llama_print_timings:        eval time =     956.92 ms /    25 runs   (   38.28 ms per token,    26.13 tokens per second)\n",
      "llama_print_timings:       total time =    1268.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    28 runs   (    0.22 ms per token,  4572.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.42 ms /    43 tokens (    4.54 ms per token,   220.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.35 ms /    27 runs   (   42.12 ms per token,    23.74 tokens per second)\n",
      "llama_print_timings:       total time =    1450.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    30 runs   (    0.22 ms per token,  4478.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.84 ms /    58 tokens (    3.74 ms per token,   267.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.83 ms /    29 runs   (   39.10 ms per token,    25.58 tokens per second)\n",
      "llama_print_timings:       total time =    1490.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    32 runs   (    0.22 ms per token,  4461.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.44 ms /    53 tokens (    3.69 ms per token,   271.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1309.80 ms /    31 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
      "llama_print_timings:       total time =    1643.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    24 runs   (    0.23 ms per token,  4287.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.83 ms /    53 tokens (    4.05 ms per token,   246.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1318.78 ms /    23 runs   (   57.34 ms per token,    17.44 tokens per second)\n",
      "llama_print_timings:       total time =    1672.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.86 ms /    39 runs   (    0.23 ms per token,  4402.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.38 ms /    56 tokens (    4.65 ms per token,   215.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2155.03 ms /    38 runs   (   56.71 ms per token,    17.63 tokens per second)\n",
      "llama_print_timings:       total time =    2578.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.01 ms /    69 runs   (    0.23 ms per token,  4310.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     223.68 ms /    45 tokens (    4.97 ms per token,   201.18 tokens per second)\n",
      "llama_print_timings:        eval time =    3648.04 ms /    68 runs   (   53.65 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:       total time =    4093.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    28 runs   (    0.23 ms per token,  4367.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     296.06 ms /    53 tokens (    5.59 ms per token,   179.02 tokens per second)\n",
      "llama_print_timings:        eval time =    2395.92 ms /    27 runs   (   88.74 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =    2838.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.98 ms /    49 runs   (    0.24 ms per token,  4091.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.19 ms /    60 tokens (    4.82 ms per token,   207.48 tokens per second)\n",
      "llama_print_timings:        eval time =    4208.55 ms /    48 runs   (   87.68 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =    4734.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    35 runs   (    0.23 ms per token,  4348.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.30 ms /    66 tokens (    3.16 ms per token,   316.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1822.02 ms /    34 runs   (   53.59 ms per token,    18.66 tokens per second)\n",
      "llama_print_timings:       total time =    2208.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    46 runs   (    0.23 ms per token,  4279.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     322.58 ms /    48 tokens (    6.72 ms per token,   148.80 tokens per second)\n",
      "llama_print_timings:        eval time =    3617.78 ms /    45 runs   (   80.40 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    4139.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    38 runs   (    0.24 ms per token,  4208.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.25 ms /    59 tokens (    3.44 ms per token,   290.28 tokens per second)\n",
      "llama_print_timings:        eval time =    2090.25 ms /    37 runs   (   56.49 ms per token,    17.70 tokens per second)\n",
      "llama_print_timings:       total time =    2483.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    34 runs   (    0.22 ms per token,  4521.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.95 ms /    47 tokens (    4.02 ms per token,   248.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1845.87 ms /    33 runs   (   55.94 ms per token,    17.88 tokens per second)\n",
      "llama_print_timings:       total time =    2170.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    26 runs   (    0.21 ms per token,  4782.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.54 ms /    41 tokens (    4.60 ms per token,   217.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1033.68 ms /    25 runs   (   41.35 ms per token,    24.19 tokens per second)\n",
      "llama_print_timings:       total time =    1334.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.63 ms /    82 runs   (    0.23 ms per token,  4401.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.24 ms /    54 tokens (    4.10 ms per token,   244.08 tokens per second)\n",
      "llama_print_timings:        eval time =    4216.80 ms /    81 runs   (   52.06 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:       total time =    4712.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.39 ms /    49 runs   (    0.23 ms per token,  4300.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     247.34 ms /    63 tokens (    3.93 ms per token,   254.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2590.78 ms /    48 runs   (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_print_timings:       total time =    3043.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.16 ms /    40 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     286.76 ms /    47 tokens (    6.10 ms per token,   163.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1824.37 ms /    39 runs   (   46.78 ms per token,    21.38 tokens per second)\n",
      "llama_print_timings:       total time =    2271.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.72 ms /    41 runs   (    0.24 ms per token,  4216.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.52 ms /    67 tokens (    3.16 ms per token,   316.76 tokens per second)\n",
      "llama_print_timings:        eval time =    2241.80 ms /    40 runs   (   56.04 ms per token,    17.84 tokens per second)\n",
      "llama_print_timings:       total time =    2639.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.37 ms /    61 runs   (    0.24 ms per token,  4244.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     308.73 ms /    63 tokens (    4.90 ms per token,   204.06 tokens per second)\n",
      "llama_print_timings:        eval time =    5556.68 ms /    60 runs   (   92.61 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =    6117.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.58 ms /    59 runs   (    0.23 ms per token,  4344.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     247.89 ms /    69 tokens (    3.59 ms per token,   278.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2653.05 ms /    58 runs   (   45.74 ms per token,    21.86 tokens per second)\n",
      "llama_print_timings:       total time =    3137.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    27 runs   (    0.22 ms per token,  4559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     317.79 ms /    52 tokens (    6.11 ms per token,   163.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1359.98 ms /    26 runs   (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_print_timings:       total time =    1819.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    35 runs   (    0.22 ms per token,  4551.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.41 ms /    51 tokens (    3.83 ms per token,   260.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1963.25 ms /    34 runs   (   57.74 ms per token,    17.32 tokens per second)\n",
      "llama_print_timings:       total time =    2309.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    45 runs   (    0.23 ms per token,  4406.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.29 ms /    58 tokens (    3.80 ms per token,   263.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2128.00 ms /    44 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_print_timings:       total time =    2523.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.77 ms /    44 runs   (    0.22 ms per token,  4502.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     229.10 ms /    55 tokens (    4.17 ms per token,   240.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2200.08 ms /    43 runs   (   51.16 ms per token,    19.54 tokens per second)\n",
      "llama_print_timings:       total time =    2607.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    40 runs   (    0.23 ms per token,  4338.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.04 ms /    58 tokens (    3.48 ms per token,   287.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2057.69 ms /    39 runs   (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_print_timings:       total time =    2432.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.35 ms /    58 runs   (    0.23 ms per token,  4346.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     223.68 ms /    62 tokens (    3.61 ms per token,   277.19 tokens per second)\n",
      "llama_print_timings:        eval time =    3183.11 ms /    57 runs   (   55.84 ms per token,    17.91 tokens per second)\n",
      "llama_print_timings:       total time =    3624.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.76 ms /    48 runs   (    0.24 ms per token,  4081.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.56 ms /    78 tokens (    2.80 ms per token,   356.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2210.05 ms /    47 runs   (   47.02 ms per token,    21.27 tokens per second)\n",
      "llama_print_timings:       total time =    2654.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.69 ms /    77 runs   (    0.23 ms per token,  4353.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.15 ms /    91 tokens (    3.00 ms per token,   333.15 tokens per second)\n",
      "llama_print_timings:        eval time =    3403.32 ms /    76 runs   (   44.78 ms per token,    22.33 tokens per second)\n",
      "llama_print_timings:       total time =    3969.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.41 ms /    81 runs   (    0.24 ms per token,  4173.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.93 ms /    69 tokens (    4.06 ms per token,   246.49 tokens per second)\n",
      "llama_print_timings:        eval time =    3888.00 ms /    80 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_print_timings:       total time =    4443.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    32 runs   (    0.24 ms per token,  4160.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.32 ms /    63 tokens (    4.21 ms per token,   237.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1544.45 ms /    31 runs   (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_print_timings:       total time =    1980.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.76 ms /    42 runs   (    0.23 ms per token,  4302.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     246.18 ms /   101 tokens (    2.44 ms per token,   410.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2113.93 ms /    41 runs   (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_print_timings:       total time =    2602.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    38 runs   (    0.24 ms per token,  4170.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.11 ms /   106 tokens (    2.46 ms per token,   405.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2255.12 ms /    37 runs   (   60.95 ms per token,    16.41 tokens per second)\n",
      "llama_print_timings:       total time =    2771.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    51 runs   (    0.23 ms per token,  4292.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     247.86 ms /    68 tokens (    3.64 ms per token,   274.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2994.68 ms /    50 runs   (   59.89 ms per token,    16.70 tokens per second)\n",
      "llama_print_timings:       total time =    3456.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    53 runs   (    0.23 ms per token,  4288.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.06 ms /    84 tokens (    3.08 ms per token,   324.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2343.61 ms /    52 runs   (   45.07 ms per token,    22.19 tokens per second)\n",
      "llama_print_timings:       total time =    2834.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    47 runs   (    0.22 ms per token,  4471.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     245.83 ms /    74 tokens (    3.32 ms per token,   301.02 tokens per second)\n",
      "llama_print_timings:        eval time =    2352.45 ms /    46 runs   (   51.14 ms per token,    19.55 tokens per second)\n",
      "llama_print_timings:       total time =    2808.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.23 ms /    81 runs   (    0.24 ms per token,  4213.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.44 ms /    90 tokens (    2.79 ms per token,   357.93 tokens per second)\n",
      "llama_print_timings:        eval time =    3685.58 ms /    80 runs   (   46.07 ms per token,    21.71 tokens per second)\n",
      "llama_print_timings:       total time =    4244.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    26 runs   (    0.23 ms per token,  4341.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     243.19 ms /    59 tokens (    4.12 ms per token,   242.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1196.78 ms /    25 runs   (   47.87 ms per token,    20.89 tokens per second)\n",
      "llama_print_timings:       total time =    1577.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    27 runs   (    0.23 ms per token,  4410.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.79 ms /    77 tokens (    3.30 ms per token,   303.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1169.84 ms /    26 runs   (   44.99 ms per token,    22.23 tokens per second)\n",
      "llama_print_timings:       total time =    1586.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      21.39 ms /    91 runs   (    0.24 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     248.90 ms /   113 tokens (    2.20 ms per token,   453.99 tokens per second)\n",
      "llama_print_timings:        eval time =    4689.93 ms /    90 runs   (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:       total time =    5313.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    42 runs   (    0.23 ms per token,  4353.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     247.60 ms /    63 tokens (    3.93 ms per token,   254.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1852.80 ms /    41 runs   (   45.19 ms per token,    22.13 tokens per second)\n",
      "llama_print_timings:       total time =    2295.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.88 ms /    54 runs   (    0.24 ms per token,  4193.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.73 ms /    95 tokens (    2.79 ms per token,   358.85 tokens per second)\n",
      "llama_print_timings:        eval time =    2897.76 ms /    53 runs   (   54.67 ms per token,    18.29 tokens per second)\n",
      "llama_print_timings:       total time =    3453.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.22 ms /    44 runs   (    0.23 ms per token,  4304.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     228.92 ms /    85 tokens (    2.69 ms per token,   371.31 tokens per second)\n",
      "llama_print_timings:        eval time =    2203.44 ms /    43 runs   (   51.24 ms per token,    19.51 tokens per second)\n",
      "llama_print_timings:       total time =    2665.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    40 runs   (    0.23 ms per token,  4360.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.09 ms /    69 tokens (    3.67 ms per token,   272.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1656.98 ms /    39 runs   (   42.49 ms per token,    23.54 tokens per second)\n",
      "llama_print_timings:       total time =    2096.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    46 runs   (    0.24 ms per token,  4226.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.39 ms /    68 tokens (    3.33 ms per token,   300.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2478.95 ms /    45 runs   (   55.09 ms per token,    18.15 tokens per second)\n",
      "llama_print_timings:       total time =    2904.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.01 ms /    66 runs   (    0.23 ms per token,  4397.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.70 ms /    79 tokens (    2.74 ms per token,   364.56 tokens per second)\n",
      "llama_print_timings:        eval time =    3232.37 ms /    65 runs   (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:       total time =    3696.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.46 ms /    64 runs   (    0.24 ms per token,  4139.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     246.39 ms /    84 tokens (    2.93 ms per token,   340.93 tokens per second)\n",
      "llama_print_timings:        eval time =    3547.18 ms /    63 runs   (   56.30 ms per token,    17.76 tokens per second)\n",
      "llama_print_timings:       total time =    4078.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.17 ms /    73 runs   (    0.24 ms per token,  4250.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     333.99 ms /   132 tokens (    2.53 ms per token,   395.22 tokens per second)\n",
      "llama_print_timings:        eval time =    3572.73 ms /    72 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:       total time =    4262.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    35 runs   (    0.23 ms per token,  4261.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.06 ms /    95 tokens (    2.92 ms per token,   342.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1946.18 ms /    34 runs   (   57.24 ms per token,    17.47 tokens per second)\n",
      "llama_print_timings:       total time =    2435.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    35 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.05 ms /    59 tokens (    3.97 ms per token,   252.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1695.86 ms /    34 runs   (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_print_timings:       total time =    2092.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    36 runs   (    0.23 ms per token,  4317.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     280.71 ms /    89 tokens (    3.15 ms per token,   317.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1879.52 ms /    35 runs   (   53.70 ms per token,    18.62 tokens per second)\n",
      "llama_print_timings:       total time =    2366.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    30 runs   (    0.23 ms per token,  4369.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     267.96 ms /   100 tokens (    2.68 ms per token,   373.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1310.86 ms /    29 runs   (   45.20 ms per token,    22.12 tokens per second)\n",
      "llama_print_timings:       total time =    1790.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    28 runs   (    0.23 ms per token,  4360.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    72 tokens (    3.48 ms per token,   287.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1344.54 ms /    27 runs   (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_print_timings:       total time =    1757.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.86 ms /    45 runs   (    0.24 ms per token,  4145.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.56 ms /    77 tokens (    3.57 ms per token,   280.44 tokens per second)\n",
      "llama_print_timings:        eval time =    2114.87 ms /    44 runs   (   48.07 ms per token,    20.81 tokens per second)\n",
      "llama_print_timings:       total time =    2610.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    35 runs   (    0.24 ms per token,  4144.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     306.87 ms /    90 tokens (    3.41 ms per token,   293.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2203.88 ms /    34 runs   (   64.82 ms per token,    15.43 tokens per second)\n",
      "llama_print_timings:       total time =    2739.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    46 runs   (    0.25 ms per token,  3984.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.49 ms /   108 tokens (    2.49 ms per token,   402.26 tokens per second)\n",
      "llama_print_timings:        eval time =    2041.40 ms /    45 runs   (   45.36 ms per token,    22.04 tokens per second)\n",
      "llama_print_timings:       total time =    2555.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    52 runs   (    0.24 ms per token,  4154.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.97 ms /    63 tokens (    3.25 ms per token,   307.36 tokens per second)\n",
      "llama_print_timings:        eval time =    6132.05 ms /    51 runs   (  120.24 ms per token,     8.32 tokens per second)\n",
      "llama_print_timings:       total time =    6585.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.16 ms /    64 runs   (    0.24 ms per token,  4222.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.12 ms /   105 tokens (    2.55 ms per token,   391.61 tokens per second)\n",
      "llama_print_timings:        eval time =    3680.73 ms /    63 runs   (   58.42 ms per token,    17.12 tokens per second)\n",
      "llama_print_timings:       total time =    4254.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    29 runs   (    0.23 ms per token,  4296.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     415.36 ms /    65 tokens (    6.39 ms per token,   156.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1486.44 ms /    28 runs   (   53.09 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:       total time =    2081.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    18 runs   (    0.22 ms per token,  4502.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.74 ms /   119 tokens (    2.19 ms per token,   456.40 tokens per second)\n",
      "llama_print_timings:        eval time =     611.67 ms /    17 runs   (   35.98 ms per token,    27.79 tokens per second)\n",
      "llama_print_timings:       total time =    1068.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    41 runs   (    0.23 ms per token,  4263.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.41 ms /    68 tokens (    3.15 ms per token,   317.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1581.66 ms /    40 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
      "llama_print_timings:       total time =    1980.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.92 ms /    77 runs   (    0.25 ms per token,  4070.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.33 ms /    86 tokens (    2.68 ms per token,   373.38 tokens per second)\n",
      "llama_print_timings:        eval time =    3363.68 ms /    76 runs   (   44.26 ms per token,    22.59 tokens per second)\n",
      "llama_print_timings:       total time =    3893.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    34 runs   (    0.24 ms per token,  4081.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     282.30 ms /    86 tokens (    3.28 ms per token,   304.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1884.51 ms /    33 runs   (   57.11 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:       total time =    2385.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.66 ms /    64 runs   (    0.23 ms per token,  4364.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.55 ms /    89 tokens (    2.86 ms per token,   349.64 tokens per second)\n",
      "llama_print_timings:        eval time =    3861.33 ms /    63 runs   (   61.29 ms per token,    16.32 tokens per second)\n",
      "llama_print_timings:       total time =    4383.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.54 ms /    56 runs   (    0.24 ms per token,  4134.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     516.55 ms /    97 tokens (    5.33 ms per token,   187.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2528.62 ms /    55 runs   (   45.97 ms per token,    21.75 tokens per second)\n",
      "llama_print_timings:       total time =    3319.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.51 ms /    68 runs   (    0.24 ms per token,  4119.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.19 ms /   114 tokens (    2.43 ms per token,   411.27 tokens per second)\n",
      "llama_print_timings:        eval time =    5982.14 ms /    67 runs   (   89.29 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    6604.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    37 runs   (    0.23 ms per token,  4406.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.58 ms /    64 tokens (    4.21 ms per token,   237.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2019.32 ms /    36 runs   (   56.09 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:       total time =    2465.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.31 ms /    53 runs   (    0.23 ms per token,  4306.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     242.86 ms /   105 tokens (    2.31 ms per token,   432.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2706.74 ms /    52 runs   (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_print_timings:       total time =    3210.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.72 ms /    50 runs   (    0.23 ms per token,  4266.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.83 ms /    75 tokens (    2.86 ms per token,   349.12 tokens per second)\n",
      "llama_print_timings:        eval time =    2662.30 ms /    49 runs   (   54.33 ms per token,    18.41 tokens per second)\n",
      "llama_print_timings:       total time =    3094.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.09 ms /    69 runs   (    0.23 ms per token,  4287.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.20 ms /    66 tokens (    3.99 ms per token,   250.76 tokens per second)\n",
      "llama_print_timings:        eval time =    3917.24 ms /    68 runs   (   57.61 ms per token,    17.36 tokens per second)\n",
      "llama_print_timings:       total time =    4430.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.51 ms /    51 runs   (    0.25 ms per token,  4075.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.38 ms /    91 tokens (    3.51 ms per token,   284.93 tokens per second)\n",
      "llama_print_timings:        eval time =    2215.81 ms /    50 runs   (   44.32 ms per token,    22.57 tokens per second)\n",
      "llama_print_timings:       total time =    2788.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.48 ms /    65 runs   (    0.22 ms per token,  4487.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     286.88 ms /    61 tokens (    4.70 ms per token,   212.63 tokens per second)\n",
      "llama_print_timings:        eval time =    3138.06 ms /    64 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:       total time =    3670.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      20.83 ms /    89 runs   (    0.23 ms per token,  4272.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.56 ms /    91 tokens (    3.07 ms per token,   325.51 tokens per second)\n",
      "llama_print_timings:        eval time =    3695.42 ms /    88 runs   (   41.99 ms per token,    23.81 tokens per second)\n",
      "llama_print_timings:       total time =    4294.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.07 ms /    72 runs   (    0.24 ms per token,  4217.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     247.36 ms /    64 tokens (    3.86 ms per token,   258.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2805.29 ms /    71 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
      "llama_print_timings:       total time =    3305.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.88 ms /    72 runs   (    0.23 ms per token,  4265.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     243.02 ms /    61 tokens (    3.98 ms per token,   251.00 tokens per second)\n",
      "llama_print_timings:        eval time =    3924.69 ms /    71 runs   (   55.28 ms per token,    18.09 tokens per second)\n",
      "llama_print_timings:       total time =    4415.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    33 runs   (    0.23 ms per token,  4256.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     350.42 ms /    89 tokens (    3.94 ms per token,   253.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1592.02 ms /    32 runs   (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_print_timings:       total time =    2144.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.77 ms /    65 runs   (    0.24 ms per token,  4122.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     224.62 ms /    83 tokens (    2.71 ms per token,   369.51 tokens per second)\n",
      "llama_print_timings:        eval time =    3235.12 ms /    64 runs   (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_print_timings:       total time =    3741.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    44 runs   (    0.24 ms per token,  4085.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     282.99 ms /   120 tokens (    2.36 ms per token,   424.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2768.27 ms /    43 runs   (   64.38 ms per token,    15.53 tokens per second)\n",
      "llama_print_timings:       total time =    3322.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.28 ms /    45 runs   (    0.25 ms per token,  3990.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     339.91 ms /   120 tokens (    2.83 ms per token,   353.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2384.71 ms /    44 runs   (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_print_timings:       total time =    2996.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.54 ms /    58 runs   (    0.25 ms per token,  3988.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     243.74 ms /    73 tokens (    3.34 ms per token,   299.50 tokens per second)\n",
      "llama_print_timings:        eval time =    2241.11 ms /    57 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:       total time =    2711.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.78 ms /    56 runs   (    0.23 ms per token,  4381.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     223.04 ms /    66 tokens (    3.38 ms per token,   295.91 tokens per second)\n",
      "llama_print_timings:        eval time =    3685.58 ms /    55 runs   (   67.01 ms per token,    14.92 tokens per second)\n",
      "llama_print_timings:       total time =    4124.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.54 ms /    60 runs   (    0.24 ms per token,  4127.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     245.94 ms /    90 tokens (    2.73 ms per token,   365.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3408.71 ms /    59 runs   (   57.77 ms per token,    17.31 tokens per second)\n",
      "llama_print_timings:       total time =    3925.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.31 ms /    44 runs   (    0.23 ms per token,  4268.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.98 ms /    88 tokens (    3.25 ms per token,   307.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1736.57 ms /    43 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:       total time =    2239.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.08 ms /    65 runs   (    0.23 ms per token,  4309.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     325.08 ms /    66 tokens (    4.93 ms per token,   203.03 tokens per second)\n",
      "llama_print_timings:        eval time =    2477.17 ms /    64 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
      "llama_print_timings:       total time =    3029.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /    23 runs   (    0.23 ms per token,  4405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.30 ms /    84 tokens (    2.62 ms per token,   381.30 tokens per second)\n",
      "llama_print_timings:        eval time =     798.21 ms /    22 runs   (   36.28 ms per token,    27.56 tokens per second)\n",
      "llama_print_timings:       total time =    1175.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.97 ms /    47 runs   (    0.23 ms per token,  4283.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     242.64 ms /   104 tokens (    2.33 ms per token,   428.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1847.88 ms /    46 runs   (   40.17 ms per token,    24.89 tokens per second)\n",
      "llama_print_timings:       total time =    2327.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    47 runs   (    0.23 ms per token,  4386.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.13 ms /    76 tokens (    2.86 ms per token,   350.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1859.66 ms /    46 runs   (   40.43 ms per token,    24.74 tokens per second)\n",
      "llama_print_timings:       total time =    2273.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.68 ms /    77 runs   (    0.23 ms per token,  4354.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.05 ms /   102 tokens (    2.33 ms per token,   428.48 tokens per second)\n",
      "llama_print_timings:        eval time =    2954.15 ms /    76 runs   (   38.87 ms per token,    25.73 tokens per second)\n",
      "llama_print_timings:       total time =    3485.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.32 ms /    53 runs   (    0.23 ms per token,  4302.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.67 ms /    74 tokens (    3.51 ms per token,   284.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2126.97 ms /    52 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time =    2603.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.42 ms /    55 runs   (    0.23 ms per token,  4428.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     224.11 ms /    81 tokens (    2.77 ms per token,   361.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2095.87 ms /    54 runs   (   38.81 ms per token,    25.77 tokens per second)\n",
      "llama_print_timings:       total time =    2551.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.94 ms /    66 runs   (    0.24 ms per token,  4141.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.08 ms /    60 tokens (    3.40 ms per token,   294.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2466.58 ms /    65 runs   (   37.95 ms per token,    26.35 tokens per second)\n",
      "llama_print_timings:       total time =    2893.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.24 ms /    44 runs   (    0.23 ms per token,  4297.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.44 ms /    73 tokens (    3.02 ms per token,   331.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1714.79 ms /    43 runs   (   39.88 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:       total time =    2137.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.65 ms /    72 runs   (    0.23 ms per token,  4324.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     223.12 ms /    85 tokens (    2.62 ms per token,   380.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2684.71 ms /    71 runs   (   37.81 ms per token,    26.45 tokens per second)\n",
      "llama_print_timings:       total time =    3169.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.32 ms /    45 runs   (    0.23 ms per token,  4358.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     227.60 ms /    72 tokens (    3.16 ms per token,   316.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1722.50 ms /    44 runs   (   39.15 ms per token,    25.54 tokens per second)\n",
      "llama_print_timings:       total time =    2141.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      22.77 ms /   101 runs   (    0.23 ms per token,  4436.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     245.00 ms /   105 tokens (    2.33 ms per token,   428.57 tokens per second)\n",
      "llama_print_timings:        eval time =    3874.73 ms /   100 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =    4470.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    33 runs   (    0.23 ms per token,  4367.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     222.49 ms /    75 tokens (    2.97 ms per token,   337.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1293.41 ms /    32 runs   (   40.42 ms per token,    24.74 tokens per second)\n",
      "llama_print_timings:       total time =    1692.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    35 runs   (    0.24 ms per token,  4132.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.16 ms /    89 tokens (    2.54 ms per token,   393.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1362.34 ms /    34 runs   (   40.07 ms per token,    24.96 tokens per second)\n",
      "llama_print_timings:       total time =    1784.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    37 runs   (    0.23 ms per token,  4284.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     219.70 ms /    76 tokens (    2.89 ms per token,   345.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1479.24 ms /    36 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:       total time =    1881.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.43 ms /    69 runs   (    0.24 ms per token,  4200.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.33 ms /    81 tokens (    2.72 ms per token,   367.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2637.39 ms /    68 runs   (   38.79 ms per token,    25.78 tokens per second)\n",
      "llama_print_timings:       total time =    3124.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.34 ms /    47 runs   (    0.24 ms per token,  4143.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.37 ms /    70 tokens (    3.59 ms per token,   278.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1865.66 ms /    46 runs   (   40.56 ms per token,    24.66 tokens per second)\n",
      "llama_print_timings:       total time =    2339.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    32 runs   (    0.24 ms per token,  4187.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     242.25 ms /    90 tokens (    2.69 ms per token,   371.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1750.11 ms /    31 runs   (   56.46 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:       total time =    2192.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    34 runs   (    0.23 ms per token,  4360.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.38 ms /    59 tokens (    3.50 ms per token,   285.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1878.95 ms /    33 runs   (   56.94 ms per token,    17.56 tokens per second)\n",
      "llama_print_timings:       total time =    2244.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      21.81 ms /    95 runs   (    0.23 ms per token,  4356.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.79 ms /    71 tokens (    3.00 ms per token,   333.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4472.17 ms /    94 runs   (   47.58 ms per token,    21.02 tokens per second)\n",
      "llama_print_timings:       total time =    4999.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.40 ms /    53 runs   (    0.23 ms per token,  4273.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.12 ms /    57 tokens (    3.60 ms per token,   277.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2252.29 ms /    52 runs   (   43.31 ms per token,    23.09 tokens per second)\n",
      "llama_print_timings:       total time =    2662.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    30 runs   (    0.24 ms per token,  4183.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.30 ms /    78 tokens (    2.79 ms per token,   358.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1359.28 ms /    29 runs   (   46.87 ms per token,    21.33 tokens per second)\n",
      "llama_print_timings:       total time =    1759.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    75 runs   (    0.23 ms per token,  4303.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     233.11 ms /    65 tokens (    3.59 ms per token,   278.84 tokens per second)\n",
      "llama_print_timings:        eval time =    3669.03 ms /    74 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:       total time =    4168.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.91 ms /    74 runs   (    0.24 ms per token,  4131.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     369.74 ms /    93 tokens (    3.98 ms per token,   251.53 tokens per second)\n",
      "llama_print_timings:        eval time =    3329.74 ms /    73 runs   (   45.61 ms per token,    21.92 tokens per second)\n",
      "llama_print_timings:       total time =    3993.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    32 runs   (    0.22 ms per token,  4515.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     397.80 ms /    65 tokens (    6.12 ms per token,   163.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1556.49 ms /    31 runs   (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:       total time =    2112.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    34 runs   (    0.23 ms per token,  4348.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.91 ms /    67 tokens (    3.13 ms per token,   319.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.71 ms /    33 runs   (   45.48 ms per token,    21.99 tokens per second)\n",
      "llama_print_timings:       total time =    1887.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    31 runs   (    0.24 ms per token,  4222.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.30 ms /    86 tokens (    2.72 ms per token,   367.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1560.18 ms /    30 runs   (   52.01 ms per token,    19.23 tokens per second)\n",
      "llama_print_timings:       total time =    1994.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    38 runs   (    0.24 ms per token,  4198.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.25 ms /    64 tokens (    3.39 ms per token,   294.59 tokens per second)\n",
      "llama_print_timings:        eval time =    2037.42 ms /    37 runs   (   55.07 ms per token,    18.16 tokens per second)\n",
      "llama_print_timings:       total time =    2431.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.32 ms /    66 runs   (    0.23 ms per token,  4308.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     223.56 ms /    79 tokens (    2.83 ms per token,   353.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2622.94 ms /    65 runs   (   40.35 ms per token,    24.78 tokens per second)\n",
      "llama_print_timings:       total time =    3088.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.22 ms /    56 runs   (    0.24 ms per token,  4236.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.51 ms /    78 tokens (    3.20 ms per token,   312.61 tokens per second)\n",
      "llama_print_timings:        eval time =    3291.98 ms /    55 runs   (   59.85 ms per token,    16.71 tokens per second)\n",
      "llama_print_timings:       total time =    3796.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.02 ms /    43 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     486.98 ms /    85 tokens (    5.73 ms per token,   174.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1930.46 ms /    42 runs   (   45.96 ms per token,    21.76 tokens per second)\n",
      "llama_print_timings:       total time =    2622.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.95 ms /    80 runs   (    0.24 ms per token,  4220.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     230.39 ms /    68 tokens (    3.39 ms per token,   295.15 tokens per second)\n",
      "llama_print_timings:        eval time =    3617.37 ms /    79 runs   (   45.79 ms per token,    21.84 tokens per second)\n",
      "llama_print_timings:       total time =    4118.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    53 runs   (    0.23 ms per token,  4265.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     267.22 ms /    82 tokens (    3.26 ms per token,   306.87 tokens per second)\n",
      "llama_print_timings:        eval time =    2115.16 ms /    52 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =    2614.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.41 ms /    64 runs   (    0.24 ms per token,  4152.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.14 ms /    72 tokens (    2.90 ms per token,   344.26 tokens per second)\n",
      "llama_print_timings:        eval time =    5605.84 ms /    63 runs   (   88.98 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    6088.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.89 ms /    40 runs   (    0.25 ms per token,  4044.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     410.50 ms /    91 tokens (    4.51 ms per token,   221.68 tokens per second)\n",
      "llama_print_timings:        eval time =    2793.05 ms /    39 runs   (   71.62 ms per token,    13.96 tokens per second)\n",
      "llama_print_timings:       total time =    3445.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.43 ms /    60 runs   (    0.24 ms per token,  4158.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.21 ms /   101 tokens (    2.36 ms per token,   424.00 tokens per second)\n",
      "llama_print_timings:        eval time =    2688.94 ms /    59 runs   (   45.58 ms per token,    21.94 tokens per second)\n",
      "llama_print_timings:       total time =    3191.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    38 runs   (    0.23 ms per token,  4338.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.86 ms /   120 tokens (    2.11 ms per token,   474.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1586.50 ms /    37 runs   (   42.88 ms per token,    23.32 tokens per second)\n",
      "llama_print_timings:       total time =    2084.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    36 runs   (    0.23 ms per token,  4310.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.85 ms /    65 tokens (    3.67 ms per token,   272.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1635.40 ms /    35 runs   (   46.73 ms per token,    21.40 tokens per second)\n",
      "llama_print_timings:       total time =    2043.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    37 runs   (    0.24 ms per token,  4197.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.47 ms /    77 tokens (    2.80 ms per token,   357.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1747.36 ms /    36 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_print_timings:       total time =    2154.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.23 ms /    68 runs   (    0.24 ms per token,  4188.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.47 ms /    84 tokens (    2.79 ms per token,   358.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2689.22 ms /    67 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
      "llama_print_timings:       total time =    3185.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.58 ms /    65 runs   (    0.22 ms per token,  4458.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     232.01 ms /    68 tokens (    3.41 ms per token,   293.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2614.12 ms /    64 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =    3078.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.12 ms /    22 runs   (    0.23 ms per token,  4298.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     222.17 ms /    71 tokens (    3.13 ms per token,   319.57 tokens per second)\n",
      "llama_print_timings:        eval time =     853.25 ms /    21 runs   (   40.63 ms per token,    24.61 tokens per second)\n",
      "llama_print_timings:       total time =    1216.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    46 runs   (    0.23 ms per token,  4337.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.15 ms /    92 tokens (    2.46 ms per token,   406.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2316.63 ms /    45 runs   (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:       total time =    2766.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    32 runs   (    0.24 ms per token,  4220.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     228.82 ms /    87 tokens (    2.63 ms per token,   380.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1732.17 ms /    31 runs   (   55.88 ms per token,    17.90 tokens per second)\n",
      "llama_print_timings:       total time =    2158.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.45 ms /    52 runs   (    0.24 ms per token,  4178.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.71 ms /    78 tokens (    2.97 ms per token,   336.63 tokens per second)\n",
      "llama_print_timings:        eval time =    3212.66 ms /    51 runs   (   62.99 ms per token,    15.87 tokens per second)\n",
      "llama_print_timings:       total time =    3672.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.67 ms /    85 runs   (    0.23 ms per token,  4322.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.59 ms /    91 tokens (    2.62 ms per token,   381.40 tokens per second)\n",
      "llama_print_timings:        eval time =    4134.82 ms /    84 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_print_timings:       total time =    4686.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.20 ms /    43 runs   (    0.24 ms per token,  4215.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     393.16 ms /    61 tokens (    6.45 ms per token,   155.15 tokens per second)\n",
      "llama_print_timings:        eval time =    3106.09 ms /    42 runs   (   73.95 ms per token,    13.52 tokens per second)\n",
      "llama_print_timings:       total time =    3730.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.64 ms /    55 runs   (    0.23 ms per token,  4351.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     282.35 ms /    77 tokens (    3.67 ms per token,   272.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3459.74 ms /    54 runs   (   64.07 ms per token,    15.61 tokens per second)\n",
      "llama_print_timings:       total time =    3969.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.49 ms /    56 runs   (    0.24 ms per token,  4151.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     240.77 ms /    93 tokens (    2.59 ms per token,   386.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2663.00 ms /    55 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_print_timings:       total time =    3155.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.82 ms /    73 runs   (    0.24 ms per token,  4096.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.76 ms /    75 tokens (    3.02 ms per token,   330.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6591.30 ms /    72 runs   (   91.55 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =    7127.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.42 ms /    48 runs   (    0.24 ms per token,  4202.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     293.99 ms /    74 tokens (    3.97 ms per token,   251.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2916.76 ms /    47 runs   (   62.06 ms per token,    16.11 tokens per second)\n",
      "llama_print_timings:       total time =    3423.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    34 runs   (    0.24 ms per token,  4147.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     379.95 ms /   114 tokens (    3.33 ms per token,   300.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2013.13 ms /    33 runs   (   61.00 ms per token,    16.39 tokens per second)\n",
      "llama_print_timings:       total time =    2638.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.70 ms /    56 runs   (    0.24 ms per token,  4088.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.18 ms /    85 tokens (    2.66 ms per token,   375.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2210.95 ms /    55 runs   (   40.20 ms per token,    24.88 tokens per second)\n",
      "llama_print_timings:       total time =    2681.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    51 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.77 ms /    60 tokens (    3.35 ms per token,   298.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2959.79 ms /    50 runs   (   59.20 ms per token,    16.89 tokens per second)\n",
      "llama_print_timings:       total time =    3364.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.62 ms /    72 runs   (    0.22 ms per token,  4608.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.60 ms /    69 tokens (    3.17 ms per token,   315.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2885.90 ms /    71 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =    3355.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /     9 runs   (    0.22 ms per token,  4459.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     295.79 ms /    66 tokens (    4.48 ms per token,   223.13 tokens per second)\n",
      "llama_print_timings:        eval time =     427.18 ms /     8 runs   (   53.40 ms per token,    18.73 tokens per second)\n",
      "llama_print_timings:       total time =     845.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    52 runs   (    0.24 ms per token,  4104.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     246.93 ms /    85 tokens (    2.91 ms per token,   344.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2678.30 ms /    51 runs   (   52.52 ms per token,    19.04 tokens per second)\n",
      "llama_print_timings:       total time =    3156.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    58 runs   (    0.24 ms per token,  4161.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     225.25 ms /    73 tokens (    3.09 ms per token,   324.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2861.63 ms /    57 runs   (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_print_timings:       total time =    3336.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.93 ms /    46 runs   (    0.24 ms per token,  4208.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.02 ms /    77 tokens (    3.42 ms per token,   292.76 tokens per second)\n",
      "llama_print_timings:        eval time =    2100.57 ms /    45 runs   (   46.68 ms per token,    21.42 tokens per second)\n",
      "llama_print_timings:       total time =    2574.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    39 runs   (    0.24 ms per token,  4246.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.40 ms /   104 tokens (    2.54 ms per token,   393.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1501.84 ms /    38 runs   (   39.52 ms per token,    25.30 tokens per second)\n",
      "llama_print_timings:       total time =    1984.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    33 runs   (    0.23 ms per token,  4370.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     232.46 ms /    96 tokens (    2.42 ms per token,   412.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1255.53 ms /    32 runs   (   39.24 ms per token,    25.49 tokens per second)\n",
      "llama_print_timings:       total time =    1685.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.53 ms /    44 runs   (    0.24 ms per token,  4179.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     282.50 ms /   101 tokens (    2.80 ms per token,   357.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2314.05 ms /    43 runs   (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:       total time =    2833.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.93 ms /    49 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.72 ms /    55 tokens (    3.63 ms per token,   275.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1963.05 ms /    48 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time =    2337.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.53 ms /    49 runs   (    0.21 ms per token,  4652.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.47 ms /    63 tokens (    3.37 ms per token,   296.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1953.02 ms /    48 runs   (   40.69 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =    2358.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.84 ms /    70 runs   (    0.23 ms per token,  4418.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     227.21 ms /    84 tokens (    2.70 ms per token,   369.70 tokens per second)\n",
      "llama_print_timings:        eval time =    2842.49 ms /    69 runs   (   41.20 ms per token,    24.27 tokens per second)\n",
      "llama_print_timings:       total time =    3333.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    35 runs   (    0.22 ms per token,  4491.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     236.36 ms /    71 tokens (    3.33 ms per token,   300.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1428.91 ms /    34 runs   (   42.03 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time =    1837.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    32 runs   (    0.23 ms per token,  4348.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.12 ms /    62 tokens (    4.41 ms per token,   227.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2030.90 ms /    31 runs   (   65.51 ms per token,    15.26 tokens per second)\n",
      "llama_print_timings:       total time =    2471.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    34 runs   (    0.24 ms per token,  4189.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.42 ms /    88 tokens (    3.18 ms per token,   314.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1851.37 ms /    33 runs   (   56.10 ms per token,    17.82 tokens per second)\n",
      "llama_print_timings:       total time =    2331.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.96 ms /    90 runs   (    0.21 ms per token,  4746.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     292.52 ms /   118 tokens (    2.48 ms per token,   403.39 tokens per second)\n",
      "llama_print_timings:        eval time =    3415.48 ms /    89 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
      "llama_print_timings:       total time =    4052.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.19 ms /    59 runs   (    0.24 ms per token,  4159.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.62 ms /    80 tokens (    3.30 ms per token,   303.47 tokens per second)\n",
      "llama_print_timings:        eval time =    2266.76 ms /    58 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
      "llama_print_timings:       total time =    2769.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    21 runs   (    0.21 ms per token,  4686.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.10 ms /    60 tokens (    3.35 ms per token,   298.36 tokens per second)\n",
      "llama_print_timings:        eval time =     718.84 ms /    20 runs   (   35.94 ms per token,    27.82 tokens per second)\n",
      "llama_print_timings:       total time =    1051.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.87 ms /    41 runs   (    0.24 ms per token,  4155.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     243.02 ms /   102 tokens (    2.38 ms per token,   419.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1631.05 ms /    40 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:       total time =    2116.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    41 runs   (    0.23 ms per token,  4370.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     247.02 ms /   106 tokens (    2.33 ms per token,   429.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1589.47 ms /    40 runs   (   39.74 ms per token,    25.17 tokens per second)\n",
      "llama_print_timings:       total time =    2058.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    27 runs   (    0.21 ms per token,  4669.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.93 ms /    88 tokens (    2.52 ms per token,   396.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1005.77 ms /    26 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
      "llama_print_timings:       total time =    1400.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.95 ms /    63 runs   (    0.24 ms per token,  4212.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.64 ms /    73 tokens (    2.98 ms per token,   335.41 tokens per second)\n",
      "llama_print_timings:        eval time =    2409.00 ms /    62 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
      "llama_print_timings:       total time =    2867.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    35 runs   (    0.22 ms per token,  4584.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.95 ms /    84 tokens (    2.64 ms per token,   378.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1366.02 ms /    34 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
      "llama_print_timings:       total time =    1771.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    26 runs   (    0.23 ms per token,  4407.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.40 ms /    73 tokens (    2.90 ms per token,   345.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1051.70 ms /    25 runs   (   42.07 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time =    1416.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.47 ms /    63 runs   (    0.23 ms per token,  4354.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     245.31 ms /   114 tokens (    2.15 ms per token,   464.72 tokens per second)\n",
      "llama_print_timings:        eval time =    2456.49 ms /    62 runs   (   39.62 ms per token,    25.24 tokens per second)\n",
      "llama_print_timings:       total time =    2989.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    41 runs   (    0.23 ms per token,  4289.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     213.32 ms /    70 tokens (    3.05 ms per token,   328.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1598.68 ms /    40 runs   (   39.97 ms per token,    25.02 tokens per second)\n",
      "llama_print_timings:       total time =    1999.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    36 runs   (    0.24 ms per token,  4203.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     248.06 ms /   109 tokens (    2.28 ms per token,   439.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1413.18 ms /    35 runs   (   40.38 ms per token,    24.77 tokens per second)\n",
      "llama_print_timings:       total time =    1886.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    26 runs   (    0.22 ms per token,  4508.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.85 ms /    56 tokens (    3.46 ms per token,   288.88 tokens per second)\n",
      "llama_print_timings:        eval time =     935.18 ms /    25 runs   (   37.41 ms per token,    26.73 tokens per second)\n",
      "llama_print_timings:       total time =    1255.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.06 ms /    55 runs   (    0.24 ms per token,  4211.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.88 ms /    64 tokens (    3.17 ms per token,   315.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2097.51 ms /    54 runs   (   38.84 ms per token,    25.74 tokens per second)\n",
      "llama_print_timings:       total time =    2496.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.46 ms /    47 runs   (    0.22 ms per token,  4495.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     228.95 ms /    87 tokens (    2.63 ms per token,   380.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1797.15 ms /    46 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
      "llama_print_timings:       total time =    2239.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    27 runs   (    0.24 ms per token,  4228.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.30 ms /    66 tokens (    3.16 ms per token,   316.86 tokens per second)\n",
      "llama_print_timings:        eval time =     962.74 ms /    26 runs   (   37.03 ms per token,    27.01 tokens per second)\n",
      "llama_print_timings:       total time =    1324.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.11 ms /    63 runs   (    0.24 ms per token,  4168.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     236.08 ms /    99 tokens (    2.38 ms per token,   419.36 tokens per second)\n",
      "llama_print_timings:        eval time =    2403.66 ms /    62 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
      "llama_print_timings:       total time =    2902.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.34 ms /    78 runs   (    0.24 ms per token,  4253.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.47 ms /   127 tokens (    2.09 ms per token,   478.39 tokens per second)\n",
      "llama_print_timings:        eval time =    3405.76 ms /    77 runs   (   44.23 ms per token,    22.61 tokens per second)\n",
      "llama_print_timings:       total time =    4005.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      25.47 ms /   118 runs   (    0.22 ms per token,  4632.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.77 ms /    69 tokens (    3.72 ms per token,   268.72 tokens per second)\n",
      "llama_print_timings:        eval time =    4442.46 ms /   117 runs   (   37.97 ms per token,    26.34 tokens per second)\n",
      "llama_print_timings:       total time =    5039.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.69 ms /    67 runs   (    0.23 ms per token,  4270.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     236.41 ms /    92 tokens (    2.57 ms per token,   389.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2523.91 ms /    66 runs   (   38.24 ms per token,    26.15 tokens per second)\n",
      "llama_print_timings:       total time =    3021.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.08 ms /    54 tokens (    3.65 ms per token,   274.00 tokens per second)\n",
      "llama_print_timings:        eval time =     109.51 ms /     2 runs   (   54.75 ms per token,    18.26 tokens per second)\n",
      "llama_print_timings:       total time =     391.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      28.48 ms /   128 runs   (    0.22 ms per token,  4495.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     229.15 ms /    88 tokens (    2.60 ms per token,   384.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4778.09 ms /   127 runs   (   37.62 ms per token,    26.58 tokens per second)\n",
      "llama_print_timings:       total time =    5388.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    37 runs   (    0.24 ms per token,  4217.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     240.70 ms /    91 tokens (    2.65 ms per token,   378.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.82 ms /    36 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
      "llama_print_timings:       total time =    1907.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    32 runs   (    0.23 ms per token,  4287.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     222.78 ms /    87 tokens (    2.56 ms per token,   390.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1244.89 ms /    31 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:       total time =    1673.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.67 ms /    62 runs   (    0.24 ms per token,  4227.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     221.88 ms /    81 tokens (    2.74 ms per token,   365.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2372.22 ms /    61 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
      "llama_print_timings:       total time =    2847.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.32 ms /    44 runs   (    0.23 ms per token,  4262.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.88 ms /    77 tokens (    2.82 ms per token,   355.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1693.12 ms /    43 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
      "llama_print_timings:       total time =    2105.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.23 ms /    57 runs   (    0.23 ms per token,  4307.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.83 ms /    58 tokens (    3.43 ms per token,   291.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2273.99 ms /    56 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:       total time =    2673.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    19 runs   (    0.22 ms per token,  4514.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     219.36 ms /    85 tokens (    2.58 ms per token,   387.49 tokens per second)\n",
      "llama_print_timings:        eval time =     746.12 ms /    18 runs   (   41.45 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =    1123.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    50 runs   (    0.23 ms per token,  4280.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.90 ms /    83 tokens (    2.66 ms per token,   375.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2120.24 ms /    49 runs   (   43.27 ms per token,    23.11 tokens per second)\n",
      "llama_print_timings:       total time =    2573.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.94 ms /    61 runs   (    0.23 ms per token,  4375.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.94 ms /    70 tokens (    3.07 ms per token,   325.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2324.54 ms /    60 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =    2756.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    34 runs   (    0.23 ms per token,  4277.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     219.88 ms /    70 tokens (    3.14 ms per token,   318.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1354.27 ms /    33 runs   (   41.04 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time =    1748.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.31 ms /    74 runs   (    0.23 ms per token,  4274.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.93 ms /    67 tokens (    3.13 ms per token,   319.16 tokens per second)\n",
      "llama_print_timings:        eval time =    3234.34 ms /    73 runs   (   44.31 ms per token,    22.57 tokens per second)\n",
      "llama_print_timings:       total time =    3705.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    30 runs   (    0.23 ms per token,  4285.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.95 ms /    83 tokens (    3.13 ms per token,   319.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2088.10 ms /    29 runs   (   72.00 ms per token,    13.89 tokens per second)\n",
      "llama_print_timings:       total time =    2532.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    21 runs   (    0.23 ms per token,  4371.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     506.57 ms /    58 tokens (    8.73 ms per token,   114.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1205.26 ms /    20 runs   (   60.26 ms per token,    16.59 tokens per second)\n",
      "llama_print_timings:       total time =    1852.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.79 ms /    46 runs   (    0.23 ms per token,  4262.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.96 ms /   125 tokens (    2.10 ms per token,   475.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2566.33 ms /    45 runs   (   57.03 ms per token,    17.53 tokens per second)\n",
      "llama_print_timings:       total time =    3102.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.59 ms /    50 runs   (    0.23 ms per token,  4313.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     235.73 ms /    79 tokens (    2.98 ms per token,   335.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2816.61 ms /    49 runs   (   57.48 ms per token,    17.40 tokens per second)\n",
      "llama_print_timings:       total time =    3294.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    39 runs   (    0.23 ms per token,  4278.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.49 ms /    80 tokens (    2.93 ms per token,   341.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1797.94 ms /    38 runs   (   47.31 ms per token,    21.14 tokens per second)\n",
      "llama_print_timings:       total time =    2229.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.48 ms /    74 runs   (    0.24 ms per token,  4232.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     303.09 ms /    72 tokens (    4.21 ms per token,   237.55 tokens per second)\n",
      "llama_print_timings:        eval time =    3279.98 ms /    73 runs   (   44.93 ms per token,    22.26 tokens per second)\n",
      "llama_print_timings:       total time =    3857.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.67 ms /    60 runs   (    0.24 ms per token,  4090.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     494.13 ms /    92 tokens (    5.37 ms per token,   186.18 tokens per second)\n",
      "llama_print_timings:        eval time =    4357.68 ms /    59 runs   (   73.86 ms per token,    13.54 tokens per second)\n",
      "llama_print_timings:       total time =    5124.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.03 ms /    55 runs   (    0.24 ms per token,  4222.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     307.59 ms /   123 tokens (    2.50 ms per token,   399.88 tokens per second)\n",
      "llama_print_timings:        eval time =    3310.31 ms /    54 runs   (   61.30 ms per token,    16.31 tokens per second)\n",
      "llama_print_timings:       total time =    3906.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.54 ms /    50 runs   (    0.23 ms per token,  4332.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     245.96 ms /   108 tokens (    2.28 ms per token,   439.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1991.79 ms /    49 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =    2502.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    23 runs   (    0.24 ms per token,  4134.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     244.22 ms /   101 tokens (    2.42 ms per token,   413.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1617.03 ms /    22 runs   (   73.50 ms per token,    13.61 tokens per second)\n",
      "llama_print_timings:       total time =    2082.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /    58 runs   (    0.23 ms per token,  4335.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     235.91 ms /    71 tokens (    3.32 ms per token,   300.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2877.39 ms /    57 runs   (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:       total time =    3363.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.02 ms /    52 runs   (    0.23 ms per token,  4324.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.96 ms /    68 tokens (    3.09 ms per token,   323.87 tokens per second)\n",
      "llama_print_timings:        eval time =    2304.71 ms /    51 runs   (   45.19 ms per token,    22.13 tokens per second)\n",
      "llama_print_timings:       total time =    2718.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    37 runs   (    0.23 ms per token,  4316.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.41 ms /    79 tokens (    3.33 ms per token,   299.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1576.07 ms /    36 runs   (   43.78 ms per token,    22.84 tokens per second)\n",
      "llama_print_timings:       total time =    2025.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.25 ms /    44 runs   (    0.23 ms per token,  4292.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     321.52 ms /    59 tokens (    5.45 ms per token,   183.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1868.22 ms /    43 runs   (   43.45 ms per token,    23.02 tokens per second)\n",
      "llama_print_timings:       total time =    2366.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    42 runs   (    0.23 ms per token,  4315.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     433.34 ms /   109 tokens (    3.98 ms per token,   251.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2683.77 ms /    41 runs   (   65.46 ms per token,    15.28 tokens per second)\n",
      "llama_print_timings:       total time =    3380.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    53 runs   (    0.24 ms per token,  4222.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     397.15 ms /    89 tokens (    4.46 ms per token,   224.10 tokens per second)\n",
      "llama_print_timings:        eval time =    2458.19 ms /    52 runs   (   47.27 ms per token,    21.15 tokens per second)\n",
      "llama_print_timings:       total time =    3091.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.56 ms /    45 runs   (    0.23 ms per token,  4261.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.37 ms /    59 tokens (    3.48 ms per token,   287.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1719.00 ms /    44 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
      "llama_print_timings:       total time =    2113.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    38 runs   (    0.24 ms per token,  4106.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     241.59 ms /   100 tokens (    2.42 ms per token,   413.92 tokens per second)\n",
      "llama_print_timings:        eval time =    2416.38 ms /    37 runs   (   65.31 ms per token,    15.31 tokens per second)\n",
      "llama_print_timings:       total time =    2892.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    29 runs   (    0.24 ms per token,  4173.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.38 ms /    74 tokens (    4.05 ms per token,   247.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1235.03 ms /    28 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time =    1706.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.93 ms /    62 runs   (    0.24 ms per token,  4152.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.65 ms /    85 tokens (    2.81 ms per token,   356.17 tokens per second)\n",
      "llama_print_timings:        eval time =    3289.60 ms /    61 runs   (   53.93 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:       total time =    3811.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    37 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.88 ms /    67 tokens (    3.12 ms per token,   320.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1760.14 ms /    36 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:       total time =    2148.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    41 runs   (    0.22 ms per token,  4460.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.17 ms /    65 tokens (    3.31 ms per token,   302.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1569.13 ms /    40 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
      "llama_print_timings:       total time =    1960.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.94 ms /    67 runs   (    0.24 ms per token,  4203.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     229.50 ms /    90 tokens (    2.55 ms per token,   392.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2907.96 ms /    66 runs   (   44.06 ms per token,    22.70 tokens per second)\n",
      "llama_print_timings:       total time =    3401.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.46 ms /    68 runs   (    0.24 ms per token,  4131.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.30 ms /   110 tokens (    2.27 ms per token,   441.23 tokens per second)\n",
      "llama_print_timings:        eval time =    2664.54 ms /    67 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
      "llama_print_timings:       total time =    3205.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /    12 runs   (    0.22 ms per token,  4454.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.33 ms /    51 tokens (    3.71 ms per token,   269.37 tokens per second)\n",
      "llama_print_timings:        eval time =     558.20 ms /    11 runs   (   50.75 ms per token,    19.71 tokens per second)\n",
      "llama_print_timings:       total time =     856.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.97 ms /    85 runs   (    0.23 ms per token,  4257.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     232.41 ms /    92 tokens (    2.53 ms per token,   395.85 tokens per second)\n",
      "llama_print_timings:        eval time =    4507.09 ms /    84 runs   (   53.66 ms per token,    18.64 tokens per second)\n",
      "llama_print_timings:       total time =    5060.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.40 ms /    56 runs   (    0.24 ms per token,  4180.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     287.52 ms /    66 tokens (    4.36 ms per token,   229.55 tokens per second)\n",
      "llama_print_timings:        eval time =    4443.82 ms /    55 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    4963.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.05 ms /    60 runs   (    0.23 ms per token,  4270.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.33 ms /    74 tokens (    3.69 ms per token,   270.74 tokens per second)\n",
      "llama_print_timings:        eval time =    3588.14 ms /    59 runs   (   60.82 ms per token,    16.44 tokens per second)\n",
      "llama_print_timings:       total time =    4094.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.77 ms /    39 runs   (    0.25 ms per token,  3992.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     233.66 ms /    88 tokens (    2.66 ms per token,   376.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2830.35 ms /    38 runs   (   74.48 ms per token,    13.43 tokens per second)\n",
      "llama_print_timings:       total time =    3272.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.23 ms /    79 runs   (    0.24 ms per token,  4107.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     233.99 ms /   103 tokens (    2.27 ms per token,   440.18 tokens per second)\n",
      "llama_print_timings:        eval time =    3576.32 ms /    78 runs   (   45.85 ms per token,    21.81 tokens per second)\n",
      "llama_print_timings:       total time =    4138.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    63 runs   (    0.24 ms per token,  4199.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.46 ms /    75 tokens (    2.87 ms per token,   348.09 tokens per second)\n",
      "llama_print_timings:        eval time =    2740.68 ms /    62 runs   (   44.20 ms per token,    22.62 tokens per second)\n",
      "llama_print_timings:       total time =    3209.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    29 runs   (    0.23 ms per token,  4342.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     233.34 ms /    78 tokens (    2.99 ms per token,   334.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1507.09 ms /    28 runs   (   53.82 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:       total time =    1905.51 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# change paths appropriately\n",
    "# make sure the output filename is the same as the reference filename for the scoring program\n",
    "path_val_model_aware = \"path/to/reference/val.model-aware.json\"\n",
    "path_val_model_aware_output = \"path/to/output/val.model-aware.json\" \n",
    "\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tqdm.notebook as tqdm\n",
    "seed_val = 442\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# simple JSON loading\n",
    "with open(path_val_model_aware, 'r') as istr:\n",
    "    data_val_all = json.load(istr)\n",
    "num_sample = len(data_val_all)\n",
    "print(num_sample)\n",
    "\n",
    "output_json = []\n",
    "labels = [\"Not Hallucination\", \"Hallucination\"]\n",
    "\"\"\"\n",
    "SelfCheckGPT Usage: (LLM) Prompt\n",
    "https://github.com/potsawee/selfcheckgpt\n",
    "Context: {}\n",
    "Sentence: {}\n",
    "Is the sentence supported by the context above?\n",
    "Answer Yes or No:\n",
    "\"\"\"\n",
    "for i in tqdm.trange(num_sample):\n",
    "    task = str(data_val_all[i]['task'])\n",
    "    if run_on_test:\n",
    "        # test splits will contain ids to ensure correct alignment before scoring\n",
    "        id = int(data_val_all[i]['id'])\n",
    "    hyp = str(data_val_all[i]['hyp'])\n",
    "    src = str(data_val_all[i]['src'])\n",
    "    tgt = str(data_val_all[i]['tgt'])\n",
    "\n",
    "    if task == \"PG\":\n",
    "        context = f\"Context: {src}\"\n",
    "    else: #i.e. task == \"MT\" or task == \"DM\":\n",
    "        context = f\"Context: {tgt}\"\n",
    "\n",
    "    sentence = f\"Sentence: {hyp}\"\n",
    "    message = f\"{context}\\n{sentence}\\nIs the Sentence supported by the Context above? Answer using ONLY yes or no:\"\n",
    "    prompt = f\"<s>[INST] {message} [/INST]\"\n",
    "\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        temperature= 0.0,\n",
    "        logprobs=1,\n",
    "    )\n",
    "    answer = str(response[\"choices\"][0][\"text\"]).strip().lower()\n",
    "    if answer.startswith(\"yes\"):\n",
    "        output_label = \"Not Hallucination\"\n",
    "        prob = 1-float(np.exp(response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0]))\n",
    "    if answer.startswith(\"no\"):\n",
    "        output_label = \"Hallucination\"\n",
    "        prob = float(np.exp(response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0]))\n",
    "    if not answer.startswith(\"no\") and not answer.startswith(\"yes\"):\n",
    "        idx_random = random.randint(0,len(labels)-1)\n",
    "        output_label = labels[idx_random]\n",
    "        prob = float(0.5)\n",
    "\n",
    "    item_to_json = {\"label\":output_label, \"p(Hallucination)\":prob}\n",
    "    if run_on_test:\n",
    "        item_to_json['id'] = id\n",
    "    \n",
    "    output_json.append(item_to_json)\n",
    "\n",
    "\n",
    "f = open(path_val_model_aware_output, 'w', encoding='utf-8')\n",
    "json.dump(output_json, f)\n",
    "f.close()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on the model-agnostic track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "aff193ecfc2e4d5a8b3ddd4f63604e63",
      "48be64dd9497468f83d73bd119591271",
      "04b2b191f387469facbc7e0f63edd957",
      "e225b3758fa24df3a0d6f1a039d3220a",
      "aeaed97ed3f441e9aa2ce24c87e02d87",
      "cebd82bbc195424a908c9527ee1a21d3",
      "8665cfefbc984fc4873e73cd96d6c018",
      "1c18583fabf94cf88d89e9d0ad83cd46",
      "16ceb8ceabea4adeb2ed5d3c62a52e87",
      "6c4a2676871e492897d305d6d9a6fac9",
      "f432e32a03704652a5bcd21c7ce36abd",
      "86da540e05824f2c95b5c8bea9b4581d",
      "d1f94d67f08449439e3191bcdf87c6bf",
      "cb886b4dac084c0290e1fd1c229b092e",
      "8b8fd80c79c54e479b15f798bc545b96",
      "3e1566a3d2f64b5fbbaf7cc51b9c9902",
      "ac217ebd99d94729ac89ed81fc0a0ab5",
      "2b25549d8eac4efd99bf1beb4fb26b0c",
      "4facca9ecbd74aa5b4dc474634686064",
      "f52b2088b6724e6dad9ee18ba364c009",
      "08db236b9ee74ccb9ac456bf09e298e1",
      "977e8b1928ec42a285804dcc8fc13cb5",
      "a0f2fe09ab0a4a21acda513f96bb7faf",
      "4f891d2316604dd08cd5ffd22c8854d9",
      "0ea36c0ff6cd4559bf733fb73ff82693",
      "de38e0a8f5a24cbdbf755db3cfd399ec",
      "9f4e1bc76cfb4643877686a6f0271b52",
      "5c70248a7e6e45199ed626fa68037174",
      "07bb3c8d23084467b680d0f8be879bcd",
      "fca89659d3684477bb46613bbb96383d",
      "265b13864e334d2d8875d1de157c428a",
      "823cdbf0fa2c43559d01de4664258a86",
      "e5ae38c7214c4f05974de99e5d5c3485"
     ]
    },
    "id": "-2KYuv-H-LYU",
    "outputId": "55d8a874-ee9c-4833-f426-279caf6813ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    val: Dataset({\n",
      "        features: ['labels', 'src', 'model', 'hyp', 'task', 'ref', 'tgt', 'label', 'p(Hallucination)'],\n",
      "        num_rows: 499\n",
      "    })\n",
      "})\n",
      "499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75227940743046f6a311c44651947dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    36 runs   (    0.23 ms per token,  4276.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.38 ms /    50 tokens (    5.09 ms per token,   196.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1643.54 ms /    35 runs   (   46.96 ms per token,    21.30 tokens per second)\n",
      "llama_print_timings:       total time =    2057.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.09 ms /    22 runs   (    0.23 ms per token,  4320.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.36 ms /    36 tokens (    5.73 ms per token,   174.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1039.12 ms /    21 runs   (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_print_timings:       total time =    1339.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /    16 runs   (    0.23 ms per token,  4422.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.90 ms /    49 tokens (    4.28 ms per token,   233.44 tokens per second)\n",
      "llama_print_timings:        eval time =     566.89 ms /    15 runs   (   37.79 ms per token,    26.46 tokens per second)\n",
      "llama_print_timings:       total time =     878.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      20.14 ms /    84 runs   (    0.24 ms per token,  4171.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.55 ms /    61 tokens (    3.39 ms per token,   295.33 tokens per second)\n",
      "llama_print_timings:        eval time =    4024.98 ms /    83 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_print_timings:       total time =    4502.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    39 runs   (    0.23 ms per token,  4346.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.44 ms /    61 tokens (    3.40 ms per token,   294.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1899.58 ms /    38 runs   (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_print_timings:       total time =    2274.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.83 ms /    80 runs   (    0.24 ms per token,  4248.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.49 ms /    43 tokens (    5.06 ms per token,   197.71 tokens per second)\n",
      "llama_print_timings:        eval time =    3736.65 ms /    79 runs   (   47.30 ms per token,    21.14 tokens per second)\n",
      "llama_print_timings:       total time =    4184.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    23 runs   (    0.25 ms per token,  3951.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     324.99 ms /    73 tokens (    4.45 ms per token,   224.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1762.68 ms /    22 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    2268.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /    22 runs   (    0.24 ms per token,  4106.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.28 ms /    56 tokens (    4.59 ms per token,   217.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1292.18 ms /    21 runs   (   61.53 ms per token,    16.25 tokens per second)\n",
      "llama_print_timings:       total time =    1678.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    32 runs   (    0.24 ms per token,  4171.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.38 ms /    52 tokens (    3.80 ms per token,   263.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1826.51 ms /    31 runs   (   58.92 ms per token,    16.97 tokens per second)\n",
      "llama_print_timings:       total time =    2166.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    29 runs   (    0.24 ms per token,  4145.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.41 ms /    59 tokens (    4.45 ms per token,   224.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1386.46 ms /    28 runs   (   49.52 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:       total time =    1812.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /    15 runs   (    0.23 ms per token,  4354.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.98 ms /    56 tokens (    3.50 ms per token,   285.74 tokens per second)\n",
      "llama_print_timings:        eval time =     581.22 ms /    14 runs   (   41.52 ms per token,    24.09 tokens per second)\n",
      "llama_print_timings:       total time =     887.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    31 runs   (    0.24 ms per token,  4139.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.31 ms /    54 tokens (    3.75 ms per token,   266.92 tokens per second)\n",
      "llama_print_timings:        eval time =    2221.16 ms /    30 runs   (   74.04 ms per token,    13.51 tokens per second)\n",
      "llama_print_timings:       total time =    2580.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    31 runs   (    0.24 ms per token,  4149.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     378.28 ms /    72 tokens (    5.25 ms per token,   190.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1988.41 ms /    30 runs   (   66.28 ms per token,    15.09 tokens per second)\n",
      "llama_print_timings:       total time =    2568.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    36 runs   (    0.23 ms per token,  4304.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     319.83 ms /    39 tokens (    8.20 ms per token,   121.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2228.67 ms /    35 runs   (   63.68 ms per token,    15.70 tokens per second)\n",
      "llama_print_timings:       total time =    2681.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    31 runs   (    0.24 ms per token,  4146.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.16 ms /    53 tokens (    3.64 ms per token,   274.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.06 ms /    30 runs   (   40.47 ms per token,    24.71 tokens per second)\n",
      "llama_print_timings:       total time =    1545.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    43 runs   (    0.24 ms per token,  4251.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.81 ms /    56 tokens (    3.46 ms per token,   288.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1724.95 ms /    42 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
      "llama_print_timings:       total time =    2089.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.80 ms /    72 runs   (    0.23 ms per token,  4284.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.52 ms /    60 tokens (    3.38 ms per token,   296.27 tokens per second)\n",
      "llama_print_timings:        eval time =    2742.76 ms /    71 runs   (   38.63 ms per token,    25.89 tokens per second)\n",
      "llama_print_timings:       total time =    3175.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    32 runs   (    0.24 ms per token,  4242.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.77 ms /    50 tokens (    3.96 ms per token,   252.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1203.89 ms /    31 runs   (   38.84 ms per token,    25.75 tokens per second)\n",
      "llama_print_timings:       total time =    1546.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.35 ms /    62 runs   (    0.23 ms per token,  4321.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.98 ms /    53 tokens (    3.75 ms per token,   266.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2730.89 ms /    61 runs   (   44.77 ms per token,    22.34 tokens per second)\n",
      "llama_print_timings:       total time =    3145.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.51 ms /    55 runs   (    0.25 ms per token,  4071.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     238.08 ms /    63 tokens (    3.78 ms per token,   264.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2151.17 ms /    54 runs   (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:       total time =    2600.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    30 runs   (    0.23 ms per token,  4351.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.98 ms /    53 tokens (    3.77 ms per token,   265.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.33 ms /    29 runs   (   37.87 ms per token,    26.40 tokens per second)\n",
      "llama_print_timings:       total time =    1433.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    36 runs   (    0.23 ms per token,  4325.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.71 ms /    47 tokens (    4.02 ms per token,   249.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1596.11 ms /    35 runs   (   45.60 ms per token,    21.93 tokens per second)\n",
      "llama_print_timings:       total time =    1922.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.04 ms /    53 runs   (    0.25 ms per token,  4064.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     229.62 ms /    79 tokens (    2.91 ms per token,   344.05 tokens per second)\n",
      "llama_print_timings:        eval time =    3389.84 ms /    52 runs   (   65.19 ms per token,    15.34 tokens per second)\n",
      "llama_print_timings:       total time =    3863.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    25 runs   (    0.22 ms per token,  4631.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.00 ms /    36 tokens (    5.14 ms per token,   194.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1071.12 ms /    24 runs   (   44.63 ms per token,    22.41 tokens per second)\n",
      "llama_print_timings:       total time =    1363.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.95 ms /    39 runs   (    0.23 ms per token,  4355.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     210.40 ms /    47 tokens (    4.48 ms per token,   223.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1733.31 ms /    38 runs   (   45.61 ms per token,    21.92 tokens per second)\n",
      "llama_print_timings:       total time =    2098.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    31 runs   (    0.24 ms per token,  4157.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.06 ms /    55 tokens (    3.78 ms per token,   264.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1973.39 ms /    30 runs   (   65.78 ms per token,    15.20 tokens per second)\n",
      "llama_print_timings:       total time =    2337.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.54 ms /    64 runs   (    0.24 ms per token,  4117.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.95 ms /    64 tokens (    3.91 ms per token,   256.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2929.43 ms /    63 runs   (   46.50 ms per token,    21.51 tokens per second)\n",
      "llama_print_timings:       total time =    3413.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    27 runs   (    0.23 ms per token,  4438.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.61 ms /    48 tokens (    3.99 ms per token,   250.50 tokens per second)\n",
      "llama_print_timings:        eval time =     968.77 ms /    26 runs   (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:       total time =    1281.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.01 ms /    46 runs   (    0.24 ms per token,  4178.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.38 ms /    51 tokens (    3.73 ms per token,   267.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1742.44 ms /    45 runs   (   38.72 ms per token,    25.83 tokens per second)\n",
      "llama_print_timings:       total time =    2105.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    38 runs   (    0.24 ms per token,  4236.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.54 ms /    51 tokens (    3.78 ms per token,   264.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1567.63 ms /    37 runs   (   42.37 ms per token,    23.60 tokens per second)\n",
      "llama_print_timings:       total time =    1922.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.37 ms /    44 runs   (    0.24 ms per token,  4242.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.88 ms /    49 tokens (    5.53 ms per token,   180.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2079.54 ms /    43 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_print_timings:       total time =    2513.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    18 runs   (    0.24 ms per token,  4169.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.69 ms /    55 tokens (    3.98 ms per token,   251.49 tokens per second)\n",
      "llama_print_timings:        eval time =     818.13 ms /    17 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_print_timings:       total time =    1146.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.72 ms /    40 runs   (    0.24 ms per token,  4116.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.00 ms /    55 tokens (    3.42 ms per token,   292.55 tokens per second)\n",
      "llama_print_timings:        eval time =    2640.16 ms /    39 runs   (   67.70 ms per token,    14.77 tokens per second)\n",
      "llama_print_timings:       total time =    2990.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    25 runs   (    0.23 ms per token,  4289.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.77 ms /    54 tokens (    5.38 ms per token,   185.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1450.64 ms /    24 runs   (   60.44 ms per token,    16.54 tokens per second)\n",
      "llama_print_timings:       total time =    1865.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    33 runs   (    0.23 ms per token,  4281.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.73 ms /    53 tokens (    3.58 ms per token,   279.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1582.31 ms /    32 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_print_timings:       total time =    1914.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    21 runs   (    0.24 ms per token,  4243.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.01 ms /    51 tokens (    3.78 ms per token,   264.24 tokens per second)\n",
      "llama_print_timings:        eval time =     775.47 ms /    20 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
      "llama_print_timings:       total time =    1086.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.83 ms /    67 runs   (    0.24 ms per token,  4231.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.03 ms /    55 tokens (    3.56 ms per token,   280.57 tokens per second)\n",
      "llama_print_timings:        eval time =    2486.53 ms /    66 runs   (   37.67 ms per token,    26.54 tokens per second)\n",
      "llama_print_timings:       total time =    2900.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    62 runs   (    0.22 ms per token,  4477.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.62 ms /    46 tokens (    3.97 ms per token,   251.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2293.95 ms /    61 runs   (   37.61 ms per token,    26.59 tokens per second)\n",
      "llama_print_timings:       total time =    2664.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    33 runs   (    0.24 ms per token,  4221.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.30 ms /    65 tokens (    3.19 ms per token,   313.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.86 ms /    32 runs   (   37.90 ms per token,    26.38 tokens per second)\n",
      "llama_print_timings:       total time =    1577.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.36 ms /    89 runs   (    0.22 ms per token,  4597.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     248.58 ms /    64 tokens (    3.88 ms per token,   257.46 tokens per second)\n",
      "llama_print_timings:        eval time =    4235.76 ms /    88 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_print_timings:       total time =    4763.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    32 runs   (    0.23 ms per token,  4370.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.43 ms /    58 tokens (    3.35 ms per token,   298.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.13 ms /    31 runs   (   39.10 ms per token,    25.57 tokens per second)\n",
      "llama_print_timings:       total time =    1554.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    37 runs   (    0.24 ms per token,  4195.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.00 ms /    58 tokens (    4.71 ms per token,   212.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1824.05 ms /    36 runs   (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_print_timings:       total time =    2284.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.85 ms /    47 runs   (    0.25 ms per token,  3964.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.61 ms /    56 tokens (    4.46 ms per token,   224.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2446.52 ms /    46 runs   (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_print_timings:       total time =    2891.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.07 ms /    43 runs   (    0.23 ms per token,  4270.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.48 ms /    65 tokens (    3.13 ms per token,   319.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1658.67 ms /    42 runs   (   39.49 ms per token,    25.32 tokens per second)\n",
      "llama_print_timings:       total time =    2037.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    29 runs   (    0.23 ms per token,  4424.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.48 ms /    44 tokens (    4.26 ms per token,   234.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.49 ms /    28 runs   (   39.27 ms per token,    25.47 tokens per second)\n",
      "llama_print_timings:       total time =    1406.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.95 ms /    54 runs   (    0.24 ms per token,  4171.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.95 ms /    50 tokens (    3.84 ms per token,   260.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1987.64 ms /    53 runs   (   37.50 ms per token,    26.66 tokens per second)\n",
      "llama_print_timings:       total time =    2360.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    27 runs   (    0.23 ms per token,  4330.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.39 ms /    56 tokens (    3.42 ms per token,   292.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1008.08 ms /    26 runs   (   38.77 ms per token,    25.79 tokens per second)\n",
      "llama_print_timings:       total time =    1325.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      23.87 ms /   101 runs   (    0.24 ms per token,  4231.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     210.84 ms /    66 tokens (    3.19 ms per token,   313.03 tokens per second)\n",
      "llama_print_timings:        eval time =    3708.34 ms /   100 runs   (   37.08 ms per token,    26.97 tokens per second)\n",
      "llama_print_timings:       total time =    4213.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.47 ms /    48 runs   (    0.24 ms per token,  4185.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.90 ms /   115 tokens (    2.24 ms per token,   445.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1892.20 ms /    47 runs   (   40.26 ms per token,    24.84 tokens per second)\n",
      "llama_print_timings:       total time =    2404.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.18 ms /    48 runs   (    0.23 ms per token,  4293.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.80 ms /    58 tokens (    3.39 ms per token,   294.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1791.44 ms /    47 runs   (   38.12 ms per token,    26.24 tokens per second)\n",
      "llama_print_timings:       total time =    2164.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    36 runs   (    0.23 ms per token,  4400.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.21 ms /    51 tokens (    3.83 ms per token,   261.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1329.34 ms /    35 runs   (   37.98 ms per token,    26.33 tokens per second)\n",
      "llama_print_timings:       total time =    1667.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.08 ms /    60 runs   (    0.23 ms per token,  4261.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     242.81 ms /   108 tokens (    2.25 ms per token,   444.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2407.56 ms /    59 runs   (   40.81 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =    2910.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.27 ms /    27 runs   (    0.23 ms per token,  4303.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.66 ms /    40 tokens (    4.59 ms per token,   217.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.32 ms /    26 runs   (   41.78 ms per token,    23.93 tokens per second)\n",
      "llama_print_timings:       total time =    1388.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    33 runs   (    0.23 ms per token,  4276.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.46 ms /    53 tokens (    3.61 ms per token,   276.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1211.80 ms /    32 runs   (   37.87 ms per token,    26.41 tokens per second)\n",
      "llama_print_timings:       total time =    1542.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    29 runs   (    0.24 ms per token,  4214.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.87 ms /    59 tokens (    3.40 ms per token,   293.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1056.15 ms /    28 runs   (   37.72 ms per token,    26.51 tokens per second)\n",
      "llama_print_timings:       total time =    1395.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.80 ms /    47 runs   (    0.23 ms per token,  4352.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.66 ms /    54 tokens (    3.51 ms per token,   284.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1768.59 ms /    46 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
      "llama_print_timings:       total time =    2126.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /    20 runs   (    0.23 ms per token,  4302.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.00 ms /    47 tokens (    3.91 ms per token,   255.43 tokens per second)\n",
      "llama_print_timings:        eval time =     685.49 ms /    19 runs   (   36.08 ms per token,    27.72 tokens per second)\n",
      "llama_print_timings:       total time =     978.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.11 ms /    76 runs   (    0.24 ms per token,  4197.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.19 ms /    74 tokens (    2.87 ms per token,   348.75 tokens per second)\n",
      "llama_print_timings:        eval time =    2845.14 ms /    75 runs   (   37.94 ms per token,    26.36 tokens per second)\n",
      "llama_print_timings:       total time =    3321.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    38 runs   (    0.23 ms per token,  4440.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.35 ms /    45 tokens (    4.12 ms per token,   242.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1399.43 ms /    37 runs   (   37.82 ms per token,    26.44 tokens per second)\n",
      "llama_print_timings:       total time =    1722.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    56 runs   (    0.25 ms per token,  4057.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.51 ms /    56 tokens (    3.46 ms per token,   289.39 tokens per second)\n",
      "llama_print_timings:        eval time =    2092.00 ms /    55 runs   (   38.04 ms per token,    26.29 tokens per second)\n",
      "llama_print_timings:       total time =    2475.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    29 runs   (    0.24 ms per token,  4239.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.75 ms /    52 tokens (    3.73 ms per token,   268.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1032.43 ms /    28 runs   (   36.87 ms per token,    27.12 tokens per second)\n",
      "llama_print_timings:       total time =    1351.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    24 runs   (    0.23 ms per token,  4323.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.13 ms /    47 tokens (    3.94 ms per token,   253.88 tokens per second)\n",
      "llama_print_timings:        eval time =     926.65 ms /    23 runs   (   40.29 ms per token,    24.82 tokens per second)\n",
      "llama_print_timings:       total time =    1223.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    20 runs   (    0.22 ms per token,  4447.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.19 ms /    53 tokens (    3.51 ms per token,   284.66 tokens per second)\n",
      "llama_print_timings:        eval time =     699.39 ms /    19 runs   (   36.81 ms per token,    27.17 tokens per second)\n",
      "llama_print_timings:       total time =     995.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.40 ms /    50 runs   (    0.23 ms per token,  4385.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.21 ms /    50 tokens (    3.88 ms per token,   257.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1946.50 ms /    49 runs   (   39.72 ms per token,    25.17 tokens per second)\n",
      "llama_print_timings:       total time =    2309.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.29 ms /    64 runs   (    0.22 ms per token,  4477.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.69 ms /    45 tokens (    4.17 ms per token,   239.76 tokens per second)\n",
      "llama_print_timings:        eval time =    2318.97 ms /    63 runs   (   36.81 ms per token,    27.17 tokens per second)\n",
      "llama_print_timings:       total time =    2693.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    38 runs   (    0.24 ms per token,  4154.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.67 ms /    64 tokens (    3.21 ms per token,   311.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1388.28 ms /    37 runs   (   37.52 ms per token,    26.65 tokens per second)\n",
      "llama_print_timings:       total time =    1769.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.97 ms /    54 runs   (    0.24 ms per token,  4163.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.64 ms /    59 tokens (    3.30 ms per token,   303.12 tokens per second)\n",
      "llama_print_timings:        eval time =    2069.84 ms /    53 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
      "llama_print_timings:       total time =    2465.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.00 ms /    42 runs   (    0.24 ms per token,  4200.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.18 ms /    59 tokens (    3.34 ms per token,   299.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1551.08 ms /    41 runs   (   37.83 ms per token,    26.43 tokens per second)\n",
      "llama_print_timings:       total time =    1912.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    35 runs   (    0.24 ms per token,  4218.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.96 ms /    49 tokens (    3.88 ms per token,   257.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1307.77 ms /    34 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
      "llama_print_timings:       total time =    1637.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    35 runs   (    0.23 ms per token,  4288.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.02 ms /    75 tokens (    2.77 ms per token,   360.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1347.36 ms /    34 runs   (   39.63 ms per token,    25.23 tokens per second)\n",
      "llama_print_timings:       total time =    1724.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    27 runs   (    0.22 ms per token,  4577.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.90 ms /    39 tokens (    4.69 ms per token,   213.23 tokens per second)\n",
      "llama_print_timings:        eval time =     949.49 ms /    26 runs   (   36.52 ms per token,    27.38 tokens per second)\n",
      "llama_print_timings:       total time =    1235.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    29 runs   (    0.23 ms per token,  4294.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.02 ms /    52 tokens (    3.58 ms per token,   279.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1068.42 ms /    28 runs   (   38.16 ms per token,    26.21 tokens per second)\n",
      "llama_print_timings:       total time =    1379.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    25 runs   (    0.24 ms per token,  4215.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.79 ms /    56 tokens (    3.42 ms per token,   291.98 tokens per second)\n",
      "llama_print_timings:        eval time =     889.38 ms /    24 runs   (   37.06 ms per token,    26.98 tokens per second)\n",
      "llama_print_timings:       total time =    1203.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.75 ms /    75 runs   (    0.24 ms per token,  4225.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.06 ms /    47 tokens (    4.02 ms per token,   248.59 tokens per second)\n",
      "llama_print_timings:        eval time =    2749.99 ms /    74 runs   (   37.16 ms per token,    26.91 tokens per second)\n",
      "llama_print_timings:       total time =    3153.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    19 runs   (    0.22 ms per token,  4476.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.03 ms /    47 tokens (    4.13 ms per token,   242.23 tokens per second)\n",
      "llama_print_timings:        eval time =     657.19 ms /    18 runs   (   36.51 ms per token,    27.39 tokens per second)\n",
      "llama_print_timings:       total time =     957.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    20 runs   (    0.23 ms per token,  4391.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.21 ms /    46 tokens (    4.05 ms per token,   247.03 tokens per second)\n",
      "llama_print_timings:        eval time =     704.18 ms /    19 runs   (   37.06 ms per token,    26.98 tokens per second)\n",
      "llama_print_timings:       total time =     990.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    27 runs   (    0.23 ms per token,  4260.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.38 ms /    49 tokens (    3.78 ms per token,   264.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.11 ms /    26 runs   (   44.04 ms per token,    22.71 tokens per second)\n",
      "llama_print_timings:       total time =    1452.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    23 runs   (    0.23 ms per token,  4422.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.97 ms /    40 tokens (    4.62 ms per token,   216.26 tokens per second)\n",
      "llama_print_timings:        eval time =     833.28 ms /    22 runs   (   37.88 ms per token,    26.40 tokens per second)\n",
      "llama_print_timings:       total time =    1115.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    28 runs   (    0.22 ms per token,  4646.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.72 ms /    38 tokens (    4.78 ms per token,   209.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1187.11 ms /    27 runs   (   43.97 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time =    1474.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    36 runs   (    0.23 ms per token,  4308.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.99 ms /    45 tokens (    4.07 ms per token,   245.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1339.28 ms /    35 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
      "llama_print_timings:       total time =    1653.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.00 ms /    66 runs   (    0.23 ms per token,  4399.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.45 ms /    48 tokens (    3.91 ms per token,   256.07 tokens per second)\n",
      "llama_print_timings:        eval time =    2581.60 ms /    65 runs   (   39.72 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:       total time =    2962.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /    19 runs   (    0.21 ms per token,  4806.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.44 ms /    44 tokens (    4.24 ms per token,   236.00 tokens per second)\n",
      "llama_print_timings:        eval time =     686.03 ms /    18 runs   (   38.11 ms per token,    26.24 tokens per second)\n",
      "llama_print_timings:       total time =     977.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.39 ms /    42 runs   (    0.22 ms per token,  4472.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.31 ms /    50 tokens (    3.89 ms per token,   257.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1558.44 ms /    41 runs   (   38.01 ms per token,    26.31 tokens per second)\n",
      "llama_print_timings:       total time =    1910.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.48 ms /    54 runs   (    0.23 ms per token,  4326.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.69 ms /    48 tokens (    3.87 ms per token,   258.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1960.78 ms /    53 runs   (   37.00 ms per token,    27.03 tokens per second)\n",
      "llama_print_timings:       total time =    2320.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    34 runs   (    0.23 ms per token,  4379.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.52 ms /    44 tokens (    4.13 ms per token,   242.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1236.87 ms /    33 runs   (   37.48 ms per token,    26.68 tokens per second)\n",
      "llama_print_timings:       total time =    1553.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    22 runs   (    0.24 ms per token,  4197.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.98 ms /    55 tokens (    3.45 ms per token,   289.51 tokens per second)\n",
      "llama_print_timings:        eval time =     775.98 ms /    21 runs   (   36.95 ms per token,    27.06 tokens per second)\n",
      "llama_print_timings:       total time =    1086.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    48 runs   (    0.23 ms per token,  4281.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.03 ms /    62 tokens (    3.18 ms per token,   314.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1787.01 ms /    47 runs   (   38.02 ms per token,    26.30 tokens per second)\n",
      "llama_print_timings:       total time =    2165.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.18 ms /    49 runs   (    0.23 ms per token,  4384.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.73 ms /    38 tokens (    4.68 ms per token,   213.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1791.83 ms /    48 runs   (   37.33 ms per token,    26.79 tokens per second)\n",
      "llama_print_timings:       total time =    2116.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    38 runs   (    0.23 ms per token,  4283.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.23 ms /    45 tokens (    4.07 ms per token,   245.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1407.25 ms /    37 runs   (   38.03 ms per token,    26.29 tokens per second)\n",
      "llama_print_timings:       total time =    1725.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    31 runs   (    0.24 ms per token,  4250.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.51 ms /    51 tokens (    3.81 ms per token,   262.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1475.08 ms /    30 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:       total time =    1799.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    38 runs   (    0.24 ms per token,  4168.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.52 ms /    56 tokens (    3.42 ms per token,   292.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1496.65 ms /    37 runs   (   40.45 ms per token,    24.72 tokens per second)\n",
      "llama_print_timings:       total time =    1852.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    33 runs   (    0.23 ms per token,  4272.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.00 ms /    61 tokens (    3.25 ms per token,   308.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1274.48 ms /    32 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:       total time =    1619.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    25 runs   (    0.23 ms per token,  4358.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     202.98 ms /    66 tokens (    3.08 ms per token,   325.15 tokens per second)\n",
      "llama_print_timings:        eval time =     928.43 ms /    24 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
      "llama_print_timings:       total time =    1269.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    26 runs   (    0.22 ms per token,  4486.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.09 ms /    46 tokens (    4.02 ms per token,   248.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.20 ms /    25 runs   (   44.01 ms per token,    22.72 tokens per second)\n",
      "llama_print_timings:       total time =    1402.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    34 runs   (    0.22 ms per token,  4551.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.23 ms /    41 tokens (    4.52 ms per token,   221.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1221.85 ms /    33 runs   (   37.03 ms per token,    27.01 tokens per second)\n",
      "llama_print_timings:       total time =    1535.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.74 ms /    36 runs   (    0.24 ms per token,  4119.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.05 ms /    65 tokens (    3.15 ms per token,   317.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.08 ms /    35 runs   (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:       total time =    1677.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    47 runs   (    0.24 ms per token,  4247.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.78 ms /    61 tokens (    3.24 ms per token,   308.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1782.27 ms /    46 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =    2158.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    31 runs   (    0.22 ms per token,  4642.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.49 ms /    42 tokens (    4.32 ms per token,   231.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.08 ms /    30 runs   (   38.00 ms per token,    26.31 tokens per second)\n",
      "llama_print_timings:       total time =    1448.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.43 ms /    46 runs   (    0.23 ms per token,  4412.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.59 ms /    44 tokens (    4.22 ms per token,   237.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1697.71 ms /    45 runs   (   37.73 ms per token,    26.51 tokens per second)\n",
      "llama_print_timings:       total time =    2043.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    27 runs   (    0.24 ms per token,  4162.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.93 ms /    47 tokens (    3.96 ms per token,   252.79 tokens per second)\n",
      "llama_print_timings:        eval time =     950.32 ms /    26 runs   (   36.55 ms per token,    27.36 tokens per second)\n",
      "llama_print_timings:       total time =    1259.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      27.52 ms /   115 runs   (    0.24 ms per token,  4178.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.29 ms /    68 tokens (    2.99 ms per token,   334.50 tokens per second)\n",
      "llama_print_timings:        eval time =    4349.62 ms /   114 runs   (   38.15 ms per token,    26.21 tokens per second)\n",
      "llama_print_timings:       total time =    4881.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    26 runs   (    0.22 ms per token,  4539.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.72 ms /    42 tokens (    4.33 ms per token,   231.12 tokens per second)\n",
      "llama_print_timings:        eval time =     933.78 ms /    25 runs   (   37.35 ms per token,    26.77 tokens per second)\n",
      "llama_print_timings:       total time =    1231.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    53 runs   (    0.23 ms per token,  4368.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.21 ms /    45 tokens (    4.07 ms per token,   245.62 tokens per second)\n",
      "llama_print_timings:        eval time =    2295.38 ms /    52 runs   (   44.14 ms per token,    22.65 tokens per second)\n",
      "llama_print_timings:       total time =    2648.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.48 ms /    45 runs   (    0.23 ms per token,  4293.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.89 ms /    47 tokens (    4.04 ms per token,   247.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1816.84 ms /    44 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:       total time =    2158.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.73 ms /    50 runs   (    0.23 ms per token,  4264.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.61 ms /    54 tokens (    3.66 ms per token,   273.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1832.14 ms /    49 runs   (   37.39 ms per token,    26.74 tokens per second)\n",
      "llama_print_timings:       total time =    2208.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.34 ms /    69 runs   (    0.22 ms per token,  4498.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.16 ms /    68 tokens (    3.15 ms per token,   317.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2556.90 ms /    68 runs   (   37.60 ms per token,    26.59 tokens per second)\n",
      "llama_print_timings:       total time =    2998.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    43 runs   (    0.24 ms per token,  4224.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.50 ms /    69 tokens (    2.95 ms per token,   339.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1574.80 ms /    42 runs   (   37.50 ms per token,    26.67 tokens per second)\n",
      "llama_print_timings:       total time =    1958.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.31 ms /    61 runs   (    0.23 ms per token,  4263.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.30 ms /    47 tokens (    4.01 ms per token,   249.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2284.10 ms /    60 runs   (   38.07 ms per token,    26.27 tokens per second)\n",
      "llama_print_timings:       total time =    2662.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.62 ms /    52 runs   (    0.24 ms per token,  4120.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.18 ms /    44 tokens (    4.16 ms per token,   240.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1944.55 ms /    51 runs   (   38.13 ms per token,    26.23 tokens per second)\n",
      "llama_print_timings:       total time =    2306.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /    20 runs   (    0.22 ms per token,  4544.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.94 ms /    45 tokens (    4.15 ms per token,   240.72 tokens per second)\n",
      "llama_print_timings:        eval time =     692.90 ms /    19 runs   (   36.47 ms per token,    27.42 tokens per second)\n",
      "llama_print_timings:       total time =     976.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    21 runs   (    0.23 ms per token,  4406.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.08 ms /    49 tokens (    3.82 ms per token,   261.92 tokens per second)\n",
      "llama_print_timings:        eval time =     737.06 ms /    20 runs   (   36.85 ms per token,    27.13 tokens per second)\n",
      "llama_print_timings:       total time =    1029.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    21 runs   (    0.23 ms per token,  4394.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.47 ms /    49 tokens (    3.93 ms per token,   254.58 tokens per second)\n",
      "llama_print_timings:        eval time =     739.17 ms /    20 runs   (   36.96 ms per token,    27.06 tokens per second)\n",
      "llama_print_timings:       total time =    1040.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.79 ms /    60 runs   (    0.23 ms per token,  4351.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.50 ms /    60 tokens (    3.26 ms per token,   306.91 tokens per second)\n",
      "llama_print_timings:        eval time =    2407.82 ms /    59 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
      "llama_print_timings:       total time =    2810.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    43 runs   (    0.23 ms per token,  4284.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.13 ms /    59 tokens (    3.36 ms per token,   297.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1831.07 ms /    42 runs   (   43.60 ms per token,    22.94 tokens per second)\n",
      "llama_print_timings:       total time =    2194.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    27 runs   (    0.22 ms per token,  4509.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.90 ms /    47 tokens (    4.06 ms per token,   246.20 tokens per second)\n",
      "llama_print_timings:        eval time =     967.55 ms /    26 runs   (   37.21 ms per token,    26.87 tokens per second)\n",
      "llama_print_timings:       total time =    1275.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    53 runs   (    0.23 ms per token,  4288.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.16 ms /    59 tokens (    3.32 ms per token,   300.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2231.97 ms /    52 runs   (   42.92 ms per token,    23.30 tokens per second)\n",
      "llama_print_timings:       total time =    2617.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    22 runs   (    0.23 ms per token,  4429.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.50 ms /    48 tokens (    3.95 ms per token,   253.29 tokens per second)\n",
      "llama_print_timings:        eval time =     772.20 ms /    21 runs   (   36.77 ms per token,    27.20 tokens per second)\n",
      "llama_print_timings:       total time =    1067.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    52 runs   (    0.23 ms per token,  4321.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.13 ms /    55 tokens (    3.55 ms per token,   281.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1933.33 ms /    51 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
      "llama_print_timings:       total time =    2304.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    39 runs   (    0.24 ms per token,  4238.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.05 ms /    55 tokens (    3.49 ms per token,   286.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1666.45 ms /    38 runs   (   43.85 ms per token,    22.80 tokens per second)\n",
      "llama_print_timings:       total time =    2013.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    23 runs   (    0.24 ms per token,  4088.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.53 ms /    50 tokens (    3.75 ms per token,   266.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.07 ms /    22 runs   (   50.82 ms per token,    19.68 tokens per second)\n",
      "llama_print_timings:       total time =    1432.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    36 runs   (    0.24 ms per token,  4143.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.03 ms /    64 tokens (    3.23 ms per token,   309.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1374.12 ms /    35 runs   (   39.26 ms per token,    25.47 tokens per second)\n",
      "llama_print_timings:       total time =    1738.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    26 runs   (    0.21 ms per token,  4653.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.72 ms /    38 tokens (    4.68 ms per token,   213.82 tokens per second)\n",
      "llama_print_timings:        eval time =     962.60 ms /    25 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
      "llama_print_timings:       total time =    1241.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    27 runs   (    0.23 ms per token,  4429.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.13 ms /    38 tokens (    4.85 ms per token,   206.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1013.22 ms /    26 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
      "llama_print_timings:       total time =    1301.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    33 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.86 ms /    47 tokens (    4.10 ms per token,   243.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.71 ms /    32 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
      "llama_print_timings:       total time =    1615.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    33 runs   (    0.24 ms per token,  4231.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.16 ms /    47 tokens (    3.94 ms per token,   253.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1270.87 ms /    32 runs   (   39.71 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:       total time =    1585.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    41 runs   (    0.24 ms per token,  4156.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.73 ms /    60 tokens (    3.26 ms per token,   306.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1580.48 ms /    40 runs   (   39.51 ms per token,    25.31 tokens per second)\n",
      "llama_print_timings:       total time =    1941.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    44 runs   (    0.25 ms per token,  4034.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.33 ms /    61 tokens (    3.25 ms per token,   307.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1663.28 ms /    43 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
      "llama_print_timings:       total time =    2035.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.23 ms /    47 runs   (    0.24 ms per token,  4185.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.65 ms /    60 tokens (    3.29 ms per token,   303.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1805.54 ms /    46 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
      "llama_print_timings:       total time =    2195.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    33 runs   (    0.24 ms per token,  4153.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.95 ms /    55 tokens (    3.53 ms per token,   283.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1428.10 ms /    32 runs   (   44.63 ms per token,    22.41 tokens per second)\n",
      "llama_print_timings:       total time =    1768.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.26 ms /    52 runs   (    0.24 ms per token,  4241.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.98 ms /    55 tokens (    3.49 ms per token,   286.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1994.98 ms /    51 runs   (   39.12 ms per token,    25.56 tokens per second)\n",
      "llama_print_timings:       total time =    2376.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.72 ms /    46 runs   (    0.23 ms per token,  4292.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.86 ms /    50 tokens (    3.82 ms per token,   261.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1754.62 ms /    45 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
      "llama_print_timings:       total time =    2105.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    28 runs   (    0.23 ms per token,  4350.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.01 ms /    45 tokens (    4.07 ms per token,   245.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1013.93 ms /    27 runs   (   37.55 ms per token,    26.63 tokens per second)\n",
      "llama_print_timings:       total time =    1313.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    26 runs   (    0.24 ms per token,  4130.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.05 ms /    47 tokens (    4.02 ms per token,   248.62 tokens per second)\n",
      "llama_print_timings:        eval time =     966.30 ms /    25 runs   (   38.65 ms per token,    25.87 tokens per second)\n",
      "llama_print_timings:       total time =    1272.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    33 runs   (    0.24 ms per token,  4244.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.87 ms /    45 tokens (    4.06 ms per token,   246.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1382.22 ms /    32 runs   (   43.19 ms per token,    23.15 tokens per second)\n",
      "llama_print_timings:       total time =    1700.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.07 ms /    55 runs   (    0.26 ms per token,  3910.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     312.07 ms /    67 tokens (    4.66 ms per token,   214.69 tokens per second)\n",
      "llama_print_timings:        eval time =    3251.29 ms /    54 runs   (   60.21 ms per token,    16.61 tokens per second)\n",
      "llama_print_timings:       total time =    3804.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.50 ms /    43 runs   (    0.24 ms per token,  4095.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     226.76 ms /    72 tokens (    3.15 ms per token,   317.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1946.02 ms /    42 runs   (   46.33 ms per token,    21.58 tokens per second)\n",
      "llama_print_timings:       total time =    2362.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    35 runs   (    0.25 ms per token,  4024.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.45 ms /    54 tokens (    3.71 ms per token,   269.39 tokens per second)\n",
      "llama_print_timings:        eval time =    2271.02 ms /    34 runs   (   66.79 ms per token,    14.97 tokens per second)\n",
      "llama_print_timings:       total time =    2631.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.78 ms /    48 runs   (    0.25 ms per token,  4074.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.00 ms /    47 tokens (    4.38 ms per token,   228.15 tokens per second)\n",
      "llama_print_timings:        eval time =    3072.03 ms /    47 runs   (   65.36 ms per token,    15.30 tokens per second)\n",
      "llama_print_timings:       total time =    3452.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    33 runs   (    0.24 ms per token,  4152.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     210.27 ms /    58 tokens (    3.63 ms per token,   275.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1712.59 ms /    32 runs   (   53.52 ms per token,    18.69 tokens per second)\n",
      "llama_print_timings:       total time =    2081.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.47 ms /    42 runs   (    0.25 ms per token,  4010.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     223.67 ms /    75 tokens (    2.98 ms per token,   335.32 tokens per second)\n",
      "llama_print_timings:        eval time =    2281.22 ms /    41 runs   (   55.64 ms per token,    17.97 tokens per second)\n",
      "llama_print_timings:       total time =    2715.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    25 runs   (    0.24 ms per token,  4224.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     391.89 ms /    51 tokens (    7.68 ms per token,   130.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1319.70 ms /    24 runs   (   54.99 ms per token,    18.19 tokens per second)\n",
      "llama_print_timings:       total time =    1859.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    31 runs   (    0.24 ms per token,  4153.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.51 ms /    54 tokens (    3.51 ms per token,   284.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2198.96 ms /    30 runs   (   73.30 ms per token,    13.64 tokens per second)\n",
      "llama_print_timings:       total time =    2534.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      20.49 ms /    84 runs   (    0.24 ms per token,  4099.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.41 ms /    50 tokens (    4.03 ms per token,   248.24 tokens per second)\n",
      "llama_print_timings:        eval time =    4175.67 ms /    83 runs   (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_print_timings:       total time =    4632.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    44 runs   (    0.25 ms per token,  4039.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.21 ms /    62 tokens (    3.78 ms per token,   264.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1957.43 ms /    43 runs   (   45.52 ms per token,    21.97 tokens per second)\n",
      "llama_print_timings:       total time =    2380.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    22 runs   (    0.24 ms per token,  4126.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.08 ms /    65 tokens (    3.29 ms per token,   303.62 tokens per second)\n",
      "llama_print_timings:        eval time =     874.74 ms /    21 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =    1228.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.39 ms /    44 runs   (    0.24 ms per token,  4234.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.78 ms /    48 tokens (    3.89 ms per token,   256.99 tokens per second)\n",
      "llama_print_timings:        eval time =    2554.34 ms /    43 runs   (   59.40 ms per token,    16.83 tokens per second)\n",
      "llama_print_timings:       total time =    2921.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    27 runs   (    0.24 ms per token,  4107.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.69 ms /    55 tokens (    3.56 ms per token,   281.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1553.42 ms /    26 runs   (   59.75 ms per token,    16.74 tokens per second)\n",
      "llama_print_timings:       total time =    1909.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    38 runs   (    0.25 ms per token,  4049.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.71 ms /    52 tokens (    3.69 ms per token,   271.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2208.39 ms /    37 runs   (   59.69 ms per token,    16.75 tokens per second)\n",
      "llama_print_timings:       total time =    2566.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.33 ms /    39 runs   (    0.24 ms per token,  4180.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.60 ms /    54 tokens (    3.55 ms per token,   281.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2244.01 ms /    38 runs   (   59.05 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:       total time =    2593.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.02 ms /    21 runs   (    0.24 ms per token,  4181.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.47 ms /    56 tokens (    3.85 ms per token,   259.89 tokens per second)\n",
      "llama_print_timings:        eval time =     895.86 ms /    20 runs   (   44.79 ms per token,    22.32 tokens per second)\n",
      "llama_print_timings:       total time =    1232.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    36 runs   (    0.23 ms per token,  4385.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     394.28 ms /    45 tokens (    8.76 ms per token,   114.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1638.52 ms /    35 runs   (   46.81 ms per token,    21.36 tokens per second)\n",
      "llama_print_timings:       total time =    2169.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.60 ms /    50 runs   (    0.23 ms per token,  4311.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.75 ms /    55 tokens (    3.63 ms per token,   275.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2156.84 ms /    49 runs   (   44.02 ms per token,    22.72 tokens per second)\n",
      "llama_print_timings:       total time =    2549.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.73 ms /    46 runs   (    0.26 ms per token,  3919.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.78 ms /    75 tokens (    2.92 ms per token,   342.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2078.83 ms /    45 runs   (   46.20 ms per token,    21.65 tokens per second)\n",
      "llama_print_timings:       total time =    2507.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    45 runs   (    0.24 ms per token,  4085.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.69 ms /    51 tokens (    3.82 ms per token,   261.96 tokens per second)\n",
      "llama_print_timings:        eval time =    2265.24 ms /    44 runs   (   51.48 ms per token,    19.42 tokens per second)\n",
      "llama_print_timings:       total time =    2625.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.77 ms /    50 runs   (    0.26 ms per token,  3914.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     343.95 ms /    80 tokens (    4.30 ms per token,   232.59 tokens per second)\n",
      "llama_print_timings:        eval time =    2776.83 ms /    49 runs   (   56.67 ms per token,    17.65 tokens per second)\n",
      "llama_print_timings:       total time =    3370.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    42 runs   (    0.25 ms per token,  4029.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.65 ms /    66 tokens (    4.10 ms per token,   243.86 tokens per second)\n",
      "llama_print_timings:        eval time =    3374.83 ms /    41 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    3854.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    26 runs   (    0.23 ms per token,  4397.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.38 ms /    42 tokens (    6.06 ms per token,   165.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2216.93 ms /    25 runs   (   88.68 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =    2610.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    33 runs   (    0.25 ms per token,  3968.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     284.96 ms /    80 tokens (    3.56 ms per token,   280.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2133.58 ms /    32 runs   (   66.67 ms per token,    15.00 tokens per second)\n",
      "llama_print_timings:       total time =    2614.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      30.67 ms /   128 runs   (    0.24 ms per token,  4173.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.82 ms /    57 tokens (    3.38 ms per token,   295.61 tokens per second)\n",
      "llama_print_timings:        eval time =    6730.23 ms /   127 runs   (   52.99 ms per token,    18.87 tokens per second)\n",
      "llama_print_timings:       total time =    7295.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /    15 runs   (    0.23 ms per token,  4339.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.77 ms /    43 tokens (    4.37 ms per token,   229.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1288.89 ms /    14 runs   (   92.06 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =    1584.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    39 runs   (    0.24 ms per token,  4122.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.96 ms /    57 tokens (    3.40 ms per token,   293.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2233.16 ms /    38 runs   (   58.77 ms per token,    17.02 tokens per second)\n",
      "llama_print_timings:       total time =    2599.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /    16 runs   (    0.23 ms per token,  4284.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.44 ms /    47 tokens (    3.92 ms per token,   254.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1178.33 ms /    15 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1466.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.50 ms /    65 runs   (    0.24 ms per token,  4192.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.63 ms /    74 tokens (    2.93 ms per token,   341.60 tokens per second)\n",
      "llama_print_timings:        eval time =    3372.56 ms /    64 runs   (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_print_timings:       total time =    3837.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    37 runs   (    0.24 ms per token,  4208.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.99 ms /    52 tokens (    3.83 ms per token,   261.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1706.40 ms /    36 runs   (   47.40 ms per token,    21.10 tokens per second)\n",
      "llama_print_timings:       total time =    2062.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    26 runs   (    0.24 ms per token,  4114.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.63 ms /    48 tokens (    3.89 ms per token,   257.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1205.99 ms /    25 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_print_timings:       total time =    1522.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    38 runs   (    0.22 ms per token,  4455.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.93 ms /    46 tokens (    4.06 ms per token,   246.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1452.22 ms /    37 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
      "llama_print_timings:       total time =    1788.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      23.73 ms /    96 runs   (    0.25 ms per token,  4044.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.02 ms /    75 tokens (    2.83 ms per token,   353.74 tokens per second)\n",
      "llama_print_timings:        eval time =    3550.96 ms /    95 runs   (   37.38 ms per token,    26.75 tokens per second)\n",
      "llama_print_timings:       total time =    4062.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    26 runs   (    0.24 ms per token,  4159.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     232.60 ms /    44 tokens (    5.29 ms per token,   189.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1295.80 ms /    25 runs   (   51.83 ms per token,    19.29 tokens per second)\n",
      "llama_print_timings:       total time =    1659.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    33 runs   (    0.23 ms per token,  4285.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     286.06 ms /    49 tokens (    5.84 ms per token,   171.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1876.68 ms /    32 runs   (   58.65 ms per token,    17.05 tokens per second)\n",
      "llama_print_timings:       total time =    2320.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    30 runs   (    0.23 ms per token,  4294.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.42 ms /    54 tokens (    3.62 ms per token,   276.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.30 ms /    29 runs   (   37.46 ms per token,    26.70 tokens per second)\n",
      "llama_print_timings:       total time =    1411.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      24.90 ms /   102 runs   (    0.24 ms per token,  4095.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.87 ms /    44 tokens (    4.32 ms per token,   231.73 tokens per second)\n",
      "llama_print_timings:        eval time =    4879.30 ms /   101 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_print_timings:       total time =    5351.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    20 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.21 ms /    43 tokens (    4.26 ms per token,   234.70 tokens per second)\n",
      "llama_print_timings:        eval time =     713.22 ms /    19 runs   (   37.54 ms per token,    26.64 tokens per second)\n",
      "llama_print_timings:       total time =     991.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.26 ms /    39 runs   (    0.24 ms per token,  4213.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.44 ms /    48 tokens (    3.86 ms per token,   258.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1421.17 ms /    38 runs   (   37.40 ms per token,    26.74 tokens per second)\n",
      "llama_print_timings:       total time =    1749.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    35 runs   (    0.24 ms per token,  4173.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.95 ms /    67 tokens (    3.04 ms per token,   328.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1357.00 ms /    34 runs   (   39.91 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:       total time =    1721.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    21 runs   (    0.24 ms per token,  4157.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.25 ms /    58 tokens (    3.40 ms per token,   294.04 tokens per second)\n",
      "llama_print_timings:        eval time =     752.13 ms /    20 runs   (   37.61 ms per token,    26.59 tokens per second)\n",
      "llama_print_timings:       total time =    1087.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.21 ms /    68 runs   (    0.24 ms per token,  4194.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.63 ms /    45 tokens (    4.08 ms per token,   245.05 tokens per second)\n",
      "llama_print_timings:        eval time =    2560.22 ms /    67 runs   (   38.21 ms per token,    26.17 tokens per second)\n",
      "llama_print_timings:       total time =    2947.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      23.08 ms /    96 runs   (    0.24 ms per token,  4159.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.59 ms /    44 tokens (    4.15 ms per token,   240.97 tokens per second)\n",
      "llama_print_timings:        eval time =    3780.33 ms /    95 runs   (   39.79 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:       total time =    4235.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    22 runs   (    0.24 ms per token,  4240.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     218.39 ms /    70 tokens (    3.12 ms per token,   320.53 tokens per second)\n",
      "llama_print_timings:        eval time =     740.19 ms /    21 runs   (   35.25 ms per token,    28.37 tokens per second)\n",
      "llama_print_timings:       total time =    1098.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.09 ms /    42 runs   (    0.24 ms per token,  4164.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.50 ms /    47 tokens (    4.03 ms per token,   248.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1667.92 ms /    41 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =    2022.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    30 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.18 ms /    38 tokens (    4.77 ms per token,   209.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1067.75 ms /    29 runs   (   36.82 ms per token,    27.16 tokens per second)\n",
      "llama_print_timings:       total time =    1357.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.69 ms /    52 runs   (    0.24 ms per token,  4099.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.35 ms /    54 tokens (    3.56 ms per token,   280.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2000.25 ms /    51 runs   (   39.22 ms per token,    25.50 tokens per second)\n",
      "llama_print_timings:       total time =    2388.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.89 ms /    54 runs   (    0.24 ms per token,  4189.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.85 ms /    55 tokens (    3.49 ms per token,   286.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1991.19 ms /    53 runs   (   37.57 ms per token,    26.62 tokens per second)\n",
      "llama_print_timings:       total time =    2366.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    25 runs   (    0.26 ms per token,  3913.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.33 ms /    59 tokens (    3.41 ms per token,   293.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1020.82 ms /    24 runs   (   42.53 ms per token,    23.51 tokens per second)\n",
      "llama_print_timings:       total time =    1369.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      21.48 ms /    90 runs   (    0.24 ms per token,  4190.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.68 ms /    54 tokens (    3.70 ms per token,   270.43 tokens per second)\n",
      "llama_print_timings:        eval time =    3911.24 ms /    89 runs   (   43.95 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time =    4389.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    44 runs   (    0.25 ms per token,  4040.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.39 ms /    44 tokens (    4.58 ms per token,   218.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1929.89 ms /    43 runs   (   44.88 ms per token,    22.28 tokens per second)\n",
      "llama_print_timings:       total time =    2290.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /    15 runs   (    0.23 ms per token,  4356.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.77 ms /    48 tokens (    3.93 ms per token,   254.28 tokens per second)\n",
      "llama_print_timings:        eval time =     530.58 ms /    14 runs   (   37.90 ms per token,    26.39 tokens per second)\n",
      "llama_print_timings:       total time =     812.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.11 ms /    59 runs   (    0.24 ms per token,  4181.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.55 ms /    58 tokens (    3.48 ms per token,   287.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2214.75 ms /    58 runs   (   38.19 ms per token,    26.19 tokens per second)\n",
      "llama_print_timings:       total time =    2618.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    27 runs   (    0.22 ms per token,  4515.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.29 ms /    43 tokens (    4.33 ms per token,   230.82 tokens per second)\n",
      "llama_print_timings:        eval time =     945.68 ms /    26 runs   (   36.37 ms per token,    27.49 tokens per second)\n",
      "llama_print_timings:       total time =    1258.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    26 runs   (    0.23 ms per token,  4279.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.43 ms /    44 tokens (    4.28 ms per token,   233.51 tokens per second)\n",
      "llama_print_timings:        eval time =     909.29 ms /    25 runs   (   36.37 ms per token,    27.49 tokens per second)\n",
      "llama_print_timings:       total time =    1230.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    26 runs   (    0.22 ms per token,  4458.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.11 ms /    40 tokens (    4.73 ms per token,   211.52 tokens per second)\n",
      "llama_print_timings:        eval time =     948.96 ms /    25 runs   (   37.96 ms per token,    26.34 tokens per second)\n",
      "llama_print_timings:       total time =    1252.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      29.13 ms /   124 runs   (    0.23 ms per token,  4256.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.73 ms /    46 tokens (    4.23 ms per token,   236.22 tokens per second)\n",
      "llama_print_timings:        eval time =    5264.30 ms /   123 runs   (   42.80 ms per token,    23.36 tokens per second)\n",
      "llama_print_timings:       total time =    5793.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    28 runs   (    0.22 ms per token,  4445.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     332.20 ms /    42 tokens (    7.91 ms per token,   126.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1398.87 ms /    27 runs   (   51.81 ms per token,    19.30 tokens per second)\n",
      "llama_print_timings:       total time =    1845.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    50 runs   (    0.24 ms per token,  4120.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.38 ms /    46 tokens (    4.05 ms per token,   246.81 tokens per second)\n",
      "llama_print_timings:        eval time =    3034.76 ms /    49 runs   (   61.93 ms per token,    16.15 tokens per second)\n",
      "llama_print_timings:       total time =    3395.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    45 runs   (    0.24 ms per token,  4242.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     229.41 ms /    58 tokens (    3.96 ms per token,   252.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2117.54 ms /    44 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_print_timings:       total time =    2544.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    28 runs   (    0.24 ms per token,  4239.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.28 ms /    44 tokens (    4.23 ms per token,   236.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1731.87 ms /    27 runs   (   64.14 ms per token,    15.59 tokens per second)\n",
      "llama_print_timings:       total time =    2038.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    37 runs   (    0.23 ms per token,  4301.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     219.00 ms /    38 tokens (    5.76 ms per token,   173.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1714.15 ms /    36 runs   (   47.62 ms per token,    21.00 tokens per second)\n",
      "llama_print_timings:       total time =    2064.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.31 ms /    43 runs   (    0.24 ms per token,  4170.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     271.83 ms /    40 tokens (    6.80 ms per token,   147.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1683.83 ms /    42 runs   (   40.09 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:       total time =    2116.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    10 runs   (    0.22 ms per token,  4576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.70 ms /    47 tokens (    3.95 ms per token,   253.10 tokens per second)\n",
      "llama_print_timings:        eval time =     333.17 ms /     9 runs   (   37.02 ms per token,    27.01 tokens per second)\n",
      "llama_print_timings:       total time =     599.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    40 runs   (    0.22 ms per token,  4530.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.19 ms /    47 tokens (    4.22 ms per token,   237.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1434.10 ms /    39 runs   (   36.77 ms per token,    27.19 tokens per second)\n",
      "llama_print_timings:       total time =    1777.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /    16 runs   (    0.23 ms per token,  4344.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.80 ms /    50 tokens (    3.76 ms per token,   266.25 tokens per second)\n",
      "llama_print_timings:        eval time =     668.14 ms /    15 runs   (   44.54 ms per token,    22.45 tokens per second)\n",
      "llama_print_timings:       total time =     955.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    34 runs   (    0.23 ms per token,  4335.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.66 ms /    43 tokens (    4.32 ms per token,   231.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1595.58 ms /    33 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_print_timings:       total time =    1913.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.50 ms /    44 runs   (    0.24 ms per token,  4190.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.19 ms /    49 tokens (    4.31 ms per token,   232.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1995.17 ms /    43 runs   (   46.40 ms per token,    21.55 tokens per second)\n",
      "llama_print_timings:       total time =    2380.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    27 runs   (    0.22 ms per token,  4465.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.06 ms /    42 tokens (    4.29 ms per token,   233.26 tokens per second)\n",
      "llama_print_timings:        eval time =     953.02 ms /    26 runs   (   36.65 ms per token,    27.28 tokens per second)\n",
      "llama_print_timings:       total time =    1242.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    43 runs   (    0.24 ms per token,  4224.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.95 ms /    42 tokens (    4.31 ms per token,   232.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1639.38 ms /    42 runs   (   39.03 ms per token,    25.62 tokens per second)\n",
      "llama_print_timings:       total time =    1974.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    40 runs   (    0.23 ms per token,  4279.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.69 ms /    45 tokens (    4.08 ms per token,   244.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1488.38 ms /    39 runs   (   38.16 ms per token,    26.20 tokens per second)\n",
      "llama_print_timings:       total time =    1825.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    31 runs   (    0.23 ms per token,  4364.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.11 ms /    53 tokens (    3.68 ms per token,   271.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1276.27 ms /    30 runs   (   42.54 ms per token,    23.51 tokens per second)\n",
      "llama_print_timings:       total time =    1606.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    37 runs   (    0.22 ms per token,  4495.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.90 ms /    40 tokens (    4.52 ms per token,   221.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1341.47 ms /    36 runs   (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:       total time =    1649.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.99 ms /    64 runs   (    0.23 ms per token,  4268.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.11 ms /    49 tokens (    3.86 ms per token,   259.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2371.44 ms /    63 runs   (   37.64 ms per token,    26.57 tokens per second)\n",
      "llama_print_timings:       total time =    2757.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    34 runs   (    0.23 ms per token,  4390.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.70 ms /    46 tokens (    4.12 ms per token,   242.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1247.12 ms /    33 runs   (   37.79 ms per token,    26.46 tokens per second)\n",
      "llama_print_timings:       total time =    1566.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    35 runs   (    0.22 ms per token,  4604.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.53 ms /    44 tokens (    4.31 ms per token,   232.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1264.33 ms /    34 runs   (   37.19 ms per token,    26.89 tokens per second)\n",
      "llama_print_timings:       total time =    1579.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.86 ms /    79 runs   (    0.24 ms per token,  4188.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.43 ms /    43 tokens (    4.22 ms per token,   237.00 tokens per second)\n",
      "llama_print_timings:        eval time =    3514.98 ms /    78 runs   (   45.06 ms per token,    22.19 tokens per second)\n",
      "llama_print_timings:       total time =    3927.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.59 ms /    41 runs   (    0.23 ms per token,  4275.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.36 ms /    40 tokens (    4.88 ms per token,   204.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1864.09 ms /    40 runs   (   46.60 ms per token,    21.46 tokens per second)\n",
      "llama_print_timings:       total time =    2209.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    26 runs   (    0.23 ms per token,  4351.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     328.47 ms /    56 tokens (    5.87 ms per token,   170.49 tokens per second)\n",
      "llama_print_timings:        eval time =     975.98 ms /    25 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
      "llama_print_timings:       total time =    1432.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    37 runs   (    0.23 ms per token,  4299.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.60 ms /    45 tokens (    4.41 ms per token,   226.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1478.06 ms /    36 runs   (   41.06 ms per token,    24.36 tokens per second)\n",
      "llama_print_timings:       total time =    1816.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    38 runs   (    0.23 ms per token,  4382.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.49 ms /    41 tokens (    4.65 ms per token,   215.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1837.98 ms /    37 runs   (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_print_timings:       total time =    2164.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.11 ms /    83 runs   (    0.23 ms per token,  4343.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.85 ms /    43 tokens (    6.76 ms per token,   147.84 tokens per second)\n",
      "llama_print_timings:        eval time =    3576.92 ms /    82 runs   (   43.62 ms per token,    22.92 tokens per second)\n",
      "llama_print_timings:       total time =    4114.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.33 ms /    44 runs   (    0.23 ms per token,  4260.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.48 ms /    47 tokens (    4.39 ms per token,   227.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1649.64 ms /    43 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
      "llama_print_timings:       total time =    2015.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      25.67 ms /   111 runs   (    0.23 ms per token,  4324.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.32 ms /    49 tokens (    3.95 ms per token,   253.47 tokens per second)\n",
      "llama_print_timings:        eval time =    4640.95 ms /   110 runs   (   42.19 ms per token,    23.70 tokens per second)\n",
      "llama_print_timings:       total time =    5145.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.28 ms /    56 runs   (    0.24 ms per token,  4216.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.02 ms /    44 tokens (    4.32 ms per token,   231.55 tokens per second)\n",
      "llama_print_timings:        eval time =    3084.44 ms /    55 runs   (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_print_timings:       total time =    3460.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.48 ms /    46 runs   (    0.23 ms per token,  4390.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.25 ms /    40 tokens (    6.93 ms per token,   144.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1743.78 ms /    45 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =    2171.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.63 ms /    40 runs   (    0.24 ms per token,  4151.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.81 ms /    42 tokens (    4.30 ms per token,   232.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1608.12 ms /    39 runs   (   41.23 ms per token,    24.25 tokens per second)\n",
      "llama_print_timings:       total time =    1939.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    24 runs   (    0.23 ms per token,  4373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.37 ms /    42 tokens (    4.34 ms per token,   230.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1063.68 ms /    23 runs   (   46.25 ms per token,    21.62 tokens per second)\n",
      "llama_print_timings:       total time =    1347.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /    16 runs   (    0.22 ms per token,  4596.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.75 ms /    42 tokens (    4.40 ms per token,   227.34 tokens per second)\n",
      "llama_print_timings:        eval time =     639.51 ms /    15 runs   (   42.63 ms per token,    23.46 tokens per second)\n",
      "llama_print_timings:       total time =     915.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    26 runs   (    0.24 ms per token,  4246.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.40 ms /    44 tokens (    4.17 ms per token,   239.92 tokens per second)\n",
      "llama_print_timings:        eval time =     941.97 ms /    25 runs   (   37.68 ms per token,    26.54 tokens per second)\n",
      "llama_print_timings:       total time =    1236.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    29 runs   (    0.23 ms per token,  4314.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.19 ms /    50 tokens (    3.76 ms per token,   265.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1056.57 ms /    28 runs   (   37.73 ms per token,    26.50 tokens per second)\n",
      "llama_print_timings:       total time =    1366.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.67 ms /    46 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.75 ms /    44 tokens (    4.20 ms per token,   238.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1936.86 ms /    45 runs   (   43.04 ms per token,    23.23 tokens per second)\n",
      "llama_print_timings:       total time =    2279.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    22 runs   (    0.21 ms per token,  4690.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.55 ms /    39 tokens (    4.78 ms per token,   209.06 tokens per second)\n",
      "llama_print_timings:        eval time =     743.41 ms /    21 runs   (   35.40 ms per token,    28.25 tokens per second)\n",
      "llama_print_timings:       total time =    1023.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.61 ms /    74 runs   (    0.24 ms per token,  4202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     179.94 ms /    40 tokens (    4.50 ms per token,   222.29 tokens per second)\n",
      "llama_print_timings:        eval time =    2825.49 ms /    73 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
      "llama_print_timings:       total time =    3214.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    20 runs   (    0.23 ms per token,  4391.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.27 ms /    54 tokens (    3.56 ms per token,   280.85 tokens per second)\n",
      "llama_print_timings:        eval time =     706.70 ms /    19 runs   (   37.19 ms per token,    26.89 tokens per second)\n",
      "llama_print_timings:       total time =    1022.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    25 runs   (    0.23 ms per token,  4266.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.96 ms /    47 tokens (    3.96 ms per token,   252.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.55 ms /    24 runs   (   46.23 ms per token,    21.63 tokens per second)\n",
      "llama_print_timings:       total time =    1415.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    32 runs   (    0.23 ms per token,  4264.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     311.33 ms /    43 tokens (    7.24 ms per token,   138.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1262.54 ms /    31 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time =    1710.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    30 runs   (    0.22 ms per token,  4559.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.12 ms /    43 tokens (    4.26 ms per token,   234.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1272.15 ms /    29 runs   (   43.87 ms per token,    22.80 tokens per second)\n",
      "llama_print_timings:       total time =    1570.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    23 runs   (    0.22 ms per token,  4447.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.77 ms /    48 tokens (    3.83 ms per token,   261.20 tokens per second)\n",
      "llama_print_timings:        eval time =     972.62 ms /    22 runs   (   44.21 ms per token,    22.62 tokens per second)\n",
      "llama_print_timings:       total time =    1267.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.24 ms /    64 runs   (    0.24 ms per token,  4200.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.26 ms /    46 tokens (    4.51 ms per token,   221.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3071.14 ms /    63 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_print_timings:       total time =    3500.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    21 runs   (    0.23 ms per token,  4421.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.75 ms /    46 tokens (    4.47 ms per token,   223.57 tokens per second)\n",
      "llama_print_timings:        eval time =     744.03 ms /    20 runs   (   37.20 ms per token,    26.88 tokens per second)\n",
      "llama_print_timings:       total time =    1055.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    20 runs   (    0.25 ms per token,  3958.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.58 ms /    49 tokens (    4.18 ms per token,   239.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1611.46 ms /    19 runs   (   84.81 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =    1934.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.44 ms /    41 runs   (    0.23 ms per token,  4341.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.49 ms /    42 tokens (    5.04 ms per token,   198.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1681.66 ms /    40 runs   (   42.04 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time =    2041.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.98 ms /    43 runs   (    0.23 ms per token,  4309.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.66 ms /    43 tokens (    4.25 ms per token,   235.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2229.93 ms /    42 runs   (   53.09 ms per token,    18.83 tokens per second)\n",
      "llama_print_timings:       total time =    2565.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    53 runs   (    0.25 ms per token,  4035.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.72 ms /    45 tokens (    4.08 ms per token,   244.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2664.53 ms /    52 runs   (   51.24 ms per token,    19.52 tokens per second)\n",
      "llama_print_timings:       total time =    3026.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.13 ms /    23 runs   (    0.22 ms per token,  4484.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     206.61 ms /    46 tokens (    4.49 ms per token,   222.64 tokens per second)\n",
      "llama_print_timings:        eval time =     804.50 ms /    22 runs   (   36.57 ms per token,    27.35 tokens per second)\n",
      "llama_print_timings:       total time =    1118.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    32 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.67 ms /    42 tokens (    5.11 ms per token,   195.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1858.41 ms /    31 runs   (   59.95 ms per token,    16.68 tokens per second)\n",
      "llama_print_timings:       total time =    2203.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    26 runs   (    0.23 ms per token,  4296.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     215.91 ms /    41 tokens (    5.27 ms per token,   189.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1053.56 ms /    25 runs   (   42.14 ms per token,    23.73 tokens per second)\n",
      "llama_print_timings:       total time =    1386.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.47 ms /    45 runs   (    0.23 ms per token,  4297.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.12 ms /    39 tokens (    5.21 ms per token,   192.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1786.60 ms /    44 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:       total time =    2139.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    45 runs   (    0.23 ms per token,  4336.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.99 ms /    42 tokens (    4.88 ms per token,   204.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2041.78 ms /    44 runs   (   46.40 ms per token,    21.55 tokens per second)\n",
      "llama_print_timings:       total time =    2418.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.89 ms /    45 runs   (    0.24 ms per token,  4132.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.05 ms /    46 tokens (    4.07 ms per token,   245.92 tokens per second)\n",
      "llama_print_timings:        eval time =    2058.38 ms /    44 runs   (   46.78 ms per token,    21.38 tokens per second)\n",
      "llama_print_timings:       total time =    2418.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    38 runs   (    0.25 ms per token,  3974.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     208.61 ms /    57 tokens (    3.66 ms per token,   273.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1501.75 ms /    37 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
      "llama_print_timings:       total time =    1872.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    21 runs   (    0.21 ms per token,  4704.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.38 ms /    44 tokens (    4.17 ms per token,   239.94 tokens per second)\n",
      "llama_print_timings:        eval time =     734.37 ms /    20 runs   (   36.72 ms per token,    27.23 tokens per second)\n",
      "llama_print_timings:       total time =    1015.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.40 ms /    46 runs   (    0.23 ms per token,  4422.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.46 ms /    42 tokens (    4.51 ms per token,   221.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1814.58 ms /    45 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
      "llama_print_timings:       total time =    2152.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    41 runs   (    0.22 ms per token,  4492.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.79 ms /    50 tokens (    3.74 ms per token,   267.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.58 ms /    40 runs   (   37.51 ms per token,    26.66 tokens per second)\n",
      "llama_print_timings:       total time =    1837.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    35 runs   (    0.22 ms per token,  4455.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     179.91 ms /    40 tokens (    4.50 ms per token,   222.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1395.23 ms /    34 runs   (   41.04 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time =    1702.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    35 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.52 ms /    47 tokens (    4.03 ms per token,   247.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1245.63 ms /    34 runs   (   36.64 ms per token,    27.30 tokens per second)\n",
      "llama_print_timings:       total time =    1568.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /    15 runs   (    0.22 ms per token,  4455.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.87 ms /    48 tokens (    3.85 ms per token,   259.64 tokens per second)\n",
      "llama_print_timings:        eval time =     546.55 ms /    14 runs   (   39.04 ms per token,    25.62 tokens per second)\n",
      "llama_print_timings:       total time =     822.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    22 runs   (    0.22 ms per token,  4635.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.72 ms /    50 tokens (    3.75 ms per token,   266.35 tokens per second)\n",
      "llama_print_timings:        eval time =     783.88 ms /    21 runs   (   37.33 ms per token,    26.79 tokens per second)\n",
      "llama_print_timings:       total time =    1078.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    36 runs   (    0.23 ms per token,  4312.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.09 ms /    47 tokens (    3.98 ms per token,   251.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1326.91 ms /    35 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
      "llama_print_timings:       total time =    1652.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.14 ms /    52 runs   (    0.23 ms per token,  4283.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.66 ms /    52 tokens (    3.59 ms per token,   278.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1938.21 ms /    51 runs   (   38.00 ms per token,    26.31 tokens per second)\n",
      "llama_print_timings:       total time =    2297.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.64 ms /    72 runs   (    0.23 ms per token,  4327.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.60 ms /    44 tokens (    4.10 ms per token,   243.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2800.00 ms /    71 runs   (   39.44 ms per token,    25.36 tokens per second)\n",
      "llama_print_timings:       total time =    3182.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.79 ms /    51 runs   (    0.23 ms per token,  4325.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.65 ms /    56 tokens (    3.57 ms per token,   280.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1890.11 ms /    50 runs   (   37.80 ms per token,    26.45 tokens per second)\n",
      "llama_print_timings:       total time =    2268.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    31 runs   (    0.23 ms per token,  4349.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.02 ms /    49 tokens (    3.86 ms per token,   259.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.94 ms /    30 runs   (   37.66 ms per token,    26.55 tokens per second)\n",
      "llama_print_timings:       total time =    1446.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    18 runs   (    0.22 ms per token,  4588.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.44 ms /    59 tokens (    3.35 ms per token,   298.82 tokens per second)\n",
      "llama_print_timings:        eval time =     650.79 ms /    17 runs   (   38.28 ms per token,    26.12 tokens per second)\n",
      "llama_print_timings:       total time =     961.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.48 ms /    59 runs   (    0.23 ms per token,  4375.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.62 ms /    50 tokens (    3.87 ms per token,   258.24 tokens per second)\n",
      "llama_print_timings:        eval time =    2225.46 ms /    58 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
      "llama_print_timings:       total time =    2604.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.03 ms /    50 runs   (    0.22 ms per token,  4534.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.67 ms /    43 tokens (    4.27 ms per token,   234.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2088.61 ms /    49 runs   (   42.62 ms per token,    23.46 tokens per second)\n",
      "llama_print_timings:       total time =    2435.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    28 runs   (    0.22 ms per token,  4591.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.50 ms /    42 tokens (    4.35 ms per token,   230.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1019.16 ms /    27 runs   (   37.75 ms per token,    26.49 tokens per second)\n",
      "llama_print_timings:       total time =    1321.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    35 runs   (    0.22 ms per token,  4535.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.36 ms /    42 tokens (    4.56 ms per token,   219.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1286.53 ms /    34 runs   (   37.84 ms per token,    26.43 tokens per second)\n",
      "llama_print_timings:       total time =    1603.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    19 runs   (    0.22 ms per token,  4541.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.45 ms /    54 tokens (    3.53 ms per token,   283.53 tokens per second)\n",
      "llama_print_timings:        eval time =     731.59 ms /    18 runs   (   40.64 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =    1043.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.84 ms /    86 runs   (    0.23 ms per token,  4334.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.97 ms /    44 tokens (    4.16 ms per token,   240.47 tokens per second)\n",
      "llama_print_timings:        eval time =    3203.86 ms /    85 runs   (   37.69 ms per token,    26.53 tokens per second)\n",
      "llama_print_timings:       total time =    3638.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    35 runs   (    0.23 ms per token,  4371.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.20 ms /    38 tokens (    4.95 ms per token,   201.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1317.37 ms /    34 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =    1635.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    20 runs   (    0.23 ms per token,  4378.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.00 ms /    56 tokens (    3.45 ms per token,   290.15 tokens per second)\n",
      "llama_print_timings:        eval time =     732.52 ms /    19 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
      "llama_print_timings:       total time =    1052.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.81 ms /    60 runs   (    0.23 ms per token,  4343.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.00 ms /    57 tokens (    3.47 ms per token,   287.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2264.47 ms /    59 runs   (   38.38 ms per token,    26.05 tokens per second)\n",
      "llama_print_timings:       total time =    2657.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    25 runs   (    0.23 ms per token,  4295.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.05 ms /    62 tokens (    3.19 ms per token,   313.05 tokens per second)\n",
      "llama_print_timings:        eval time =     914.73 ms /    24 runs   (   38.11 ms per token,    26.24 tokens per second)\n",
      "llama_print_timings:       total time =    1242.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    24 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.48 ms /    45 tokens (    4.12 ms per token,   242.62 tokens per second)\n",
      "llama_print_timings:        eval time =     848.14 ms /    23 runs   (   36.88 ms per token,    27.12 tokens per second)\n",
      "llama_print_timings:       total time =    1144.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.44 ms /    58 runs   (    0.23 ms per token,  4315.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.20 ms /    44 tokens (    4.21 ms per token,   237.58 tokens per second)\n",
      "llama_print_timings:        eval time =    2150.12 ms /    57 runs   (   37.72 ms per token,    26.51 tokens per second)\n",
      "llama_print_timings:       total time =    2519.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    43 runs   (    0.22 ms per token,  4596.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.59 ms /    43 tokens (    4.27 ms per token,   234.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1637.75 ms /    42 runs   (   38.99 ms per token,    25.65 tokens per second)\n",
      "llama_print_timings:       total time =    1961.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    38 runs   (    0.23 ms per token,  4439.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.96 ms /    42 tokens (    4.31 ms per token,   232.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1423.73 ms /    37 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
      "llama_print_timings:       total time =    1734.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.80 ms /    47 runs   (    0.23 ms per token,  4352.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.35 ms /    47 tokens (    3.99 ms per token,   250.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1836.49 ms /    46 runs   (   39.92 ms per token,    25.05 tokens per second)\n",
      "llama_print_timings:       total time =    2179.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    23 runs   (    0.22 ms per token,  4637.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.20 ms /    50 tokens (    3.88 ms per token,   257.46 tokens per second)\n",
      "llama_print_timings:        eval time =     828.50 ms /    22 runs   (   37.66 ms per token,    26.55 tokens per second)\n",
      "llama_print_timings:       total time =    1137.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    22 runs   (    0.22 ms per token,  4474.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.81 ms /    48 tokens (    3.89 ms per token,   256.95 tokens per second)\n",
      "llama_print_timings:        eval time =     800.18 ms /    21 runs   (   38.10 ms per token,    26.24 tokens per second)\n",
      "llama_print_timings:       total time =    1091.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    23 runs   (    0.22 ms per token,  4447.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.38 ms /    51 tokens (    3.77 ms per token,   265.10 tokens per second)\n",
      "llama_print_timings:        eval time =     814.17 ms /    22 runs   (   37.01 ms per token,    27.02 tokens per second)\n",
      "llama_print_timings:       total time =    1116.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.28 ms /    37 runs   (    0.22 ms per token,  4469.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.89 ms /    43 tokens (    4.21 ms per token,   237.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1367.08 ms /    36 runs   (   37.97 ms per token,    26.33 tokens per second)\n",
      "llama_print_timings:       total time =    1676.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    21 runs   (    0.22 ms per token,  4497.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.04 ms /    45 tokens (    4.13 ms per token,   241.88 tokens per second)\n",
      "llama_print_timings:        eval time =     764.31 ms /    20 runs   (   38.22 ms per token,    26.17 tokens per second)\n",
      "llama_print_timings:       total time =    1049.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.32 ms /    24 runs   (    0.22 ms per token,  4512.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.74 ms /    43 tokens (    4.34 ms per token,   230.26 tokens per second)\n",
      "llama_print_timings:        eval time =     871.68 ms /    23 runs   (   37.90 ms per token,    26.39 tokens per second)\n",
      "llama_print_timings:       total time =    1160.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    28 runs   (    0.23 ms per token,  4379.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.98 ms /    43 tokens (    4.26 ms per token,   235.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1043.43 ms /    27 runs   (   38.65 ms per token,    25.88 tokens per second)\n",
      "llama_print_timings:       total time =    1339.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    23 runs   (    0.23 ms per token,  4430.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.15 ms /    58 tokens (    3.43 ms per token,   291.25 tokens per second)\n",
      "llama_print_timings:        eval time =     822.11 ms /    22 runs   (   37.37 ms per token,    26.76 tokens per second)\n",
      "llama_print_timings:       total time =    1141.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    33 runs   (    0.22 ms per token,  4544.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.17 ms /    44 tokens (    4.16 ms per token,   240.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1229.96 ms /    32 runs   (   38.44 ms per token,    26.02 tokens per second)\n",
      "llama_print_timings:       total time =    1545.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    30 runs   (    0.23 ms per token,  4435.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.96 ms /    48 tokens (    3.85 ms per token,   259.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.00 ms /    29 runs   (   37.62 ms per token,    26.58 tokens per second)\n",
      "llama_print_timings:       total time =    1395.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    29 runs   (    0.22 ms per token,  4558.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.39 ms /    46 tokens (    3.99 ms per token,   250.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1062.00 ms /    28 runs   (   37.93 ms per token,    26.37 tokens per second)\n",
      "llama_print_timings:       total time =    1360.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    31 runs   (    0.22 ms per token,  4562.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.85 ms /    42 tokens (    4.35 ms per token,   229.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1227.98 ms /    30 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
      "llama_print_timings:       total time =    1527.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.77 ms /    51 runs   (    0.23 ms per token,  4333.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.68 ms /    43 tokens (    4.34 ms per token,   230.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1900.36 ms /    50 runs   (   38.01 ms per token,    26.31 tokens per second)\n",
      "llama_print_timings:       total time =    2248.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    38 runs   (    0.23 ms per token,  4428.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.40 ms /    42 tokens (    4.32 ms per token,   231.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1408.77 ms /    37 runs   (   38.07 ms per token,    26.26 tokens per second)\n",
      "llama_print_timings:       total time =    1721.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.46 ms /    77 runs   (    0.23 ms per token,  4409.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.51 ms /    42 tokens (    4.37 ms per token,   228.87 tokens per second)\n",
      "llama_print_timings:        eval time =    2936.60 ms /    76 runs   (   38.64 ms per token,    25.88 tokens per second)\n",
      "llama_print_timings:       total time =    3328.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    31 runs   (    0.22 ms per token,  4459.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.94 ms /    52 tokens (    3.73 ms per token,   268.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.02 ms /    30 runs   (   37.90 ms per token,    26.38 tokens per second)\n",
      "llama_print_timings:       total time =    1463.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.46 ms /    64 runs   (    0.23 ms per token,  4424.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.10 ms /    54 tokens (    3.48 ms per token,   287.08 tokens per second)\n",
      "llama_print_timings:        eval time =    2431.85 ms /    63 runs   (   38.60 ms per token,    25.91 tokens per second)\n",
      "llama_print_timings:       total time =    2819.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    53 runs   (    0.22 ms per token,  4581.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.39 ms /    46 tokens (    4.03 ms per token,   248.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1984.43 ms /    52 runs   (   38.16 ms per token,    26.20 tokens per second)\n",
      "llama_print_timings:       total time =    2337.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.95 ms /    53 runs   (    0.23 ms per token,  4434.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.80 ms /    41 tokens (    4.56 ms per token,   219.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1969.57 ms /    52 runs   (   37.88 ms per token,    26.40 tokens per second)\n",
      "llama_print_timings:       total time =    2318.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.64 ms /    43 runs   (    0.22 ms per token,  4461.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.65 ms /    48 tokens (    3.95 ms per token,   253.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1620.80 ms /    42 runs   (   38.59 ms per token,    25.91 tokens per second)\n",
      "llama_print_timings:       total time =    1961.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      21.20 ms /    94 runs   (    0.23 ms per token,  4433.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.59 ms /    54 tokens (    3.60 ms per token,   277.51 tokens per second)\n",
      "llama_print_timings:        eval time =    3503.90 ms /    93 runs   (   37.68 ms per token,    26.54 tokens per second)\n",
      "llama_print_timings:       total time =    3962.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.77 ms /    60 runs   (    0.23 ms per token,  4358.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.81 ms /    39 tokens (    4.71 ms per token,   212.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2233.57 ms /    59 runs   (   37.86 ms per token,    26.42 tokens per second)\n",
      "llama_print_timings:       total time =    2598.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    40 runs   (    0.22 ms per token,  4509.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.10 ms /    41 tokens (    4.51 ms per token,   221.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1501.55 ms /    39 runs   (   38.50 ms per token,    25.97 tokens per second)\n",
      "llama_print_timings:       total time =    1818.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    30 runs   (    0.22 ms per token,  4544.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.38 ms /    43 tokens (    4.26 ms per token,   234.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1252.80 ms /    29 runs   (   43.20 ms per token,    23.15 tokens per second)\n",
      "llama_print_timings:       total time =    1553.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /    17 runs   (    0.21 ms per token,  4660.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.03 ms /    40 tokens (    4.53 ms per token,   220.96 tokens per second)\n",
      "llama_print_timings:        eval time =     623.46 ms /    16 runs   (   38.97 ms per token,    25.66 tokens per second)\n",
      "llama_print_timings:       total time =     892.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    22 runs   (    0.22 ms per token,  4604.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.60 ms /    41 tokens (    4.50 ms per token,   222.10 tokens per second)\n",
      "llama_print_timings:        eval time =     774.53 ms /    21 runs   (   36.88 ms per token,    27.11 tokens per second)\n",
      "llama_print_timings:       total time =    1059.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    48 runs   (    0.23 ms per token,  4332.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.84 ms /    44 tokens (    4.16 ms per token,   240.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1991.75 ms /    47 runs   (   42.38 ms per token,    23.60 tokens per second)\n",
      "llama_print_timings:       total time =    2330.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    32 runs   (    0.23 ms per token,  4365.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.64 ms /    44 tokens (    4.22 ms per token,   237.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.81 ms /    31 runs   (   40.28 ms per token,    24.82 tokens per second)\n",
      "llama_print_timings:       total time =    1555.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    38 runs   (    0.23 ms per token,  4374.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.47 ms /    41 tokens (    4.43 ms per token,   225.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1460.49 ms /    37 runs   (   39.47 ms per token,    25.33 tokens per second)\n",
      "llama_print_timings:       total time =    1774.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      22.25 ms /    94 runs   (    0.24 ms per token,  4223.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.24 ms /    46 tokens (    4.03 ms per token,   248.32 tokens per second)\n",
      "llama_print_timings:        eval time =    3496.25 ms /    93 runs   (   37.59 ms per token,    26.60 tokens per second)\n",
      "llama_print_timings:       total time =    3936.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      26.03 ms /   112 runs   (    0.23 ms per token,  4303.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.42 ms /    45 tokens (    4.21 ms per token,   237.57 tokens per second)\n",
      "llama_print_timings:        eval time =    4275.35 ms /   111 runs   (   38.52 ms per token,    25.96 tokens per second)\n",
      "llama_print_timings:       total time =    4756.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    18 runs   (    0.22 ms per token,  4630.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.02 ms /    40 tokens (    4.80 ms per token,   208.31 tokens per second)\n",
      "llama_print_timings:        eval time =     674.87 ms /    17 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
      "llama_print_timings:       total time =     953.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      23.30 ms /   100 runs   (    0.23 ms per token,  4291.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.96 ms /    50 tokens (    4.12 ms per token,   242.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5657.68 ms /    99 runs   (   57.15 ms per token,    17.50 tokens per second)\n",
      "llama_print_timings:       total time =    6150.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    35 runs   (    0.23 ms per token,  4341.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.75 ms /    51 tokens (    3.78 ms per token,   264.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1547.70 ms /    34 runs   (   45.52 ms per token,    21.97 tokens per second)\n",
      "llama_print_timings:       total time =    1878.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.37 ms /    73 runs   (    0.24 ms per token,  4203.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     234.22 ms /    46 tokens (    5.09 ms per token,   196.40 tokens per second)\n",
      "llama_print_timings:        eval time =    4854.61 ms /    72 runs   (   67.43 ms per token,    14.83 tokens per second)\n",
      "llama_print_timings:       total time =    5339.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.78 ms /    47 runs   (    0.23 ms per token,  4360.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     197.36 ms /    47 tokens (    4.20 ms per token,   238.14 tokens per second)\n",
      "llama_print_timings:        eval time =    2597.13 ms /    46 runs   (   56.46 ms per token,    17.71 tokens per second)\n",
      "llama_print_timings:       total time =    2966.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.88 ms /    52 runs   (    0.23 ms per token,  4375.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.60 ms /    44 tokens (    4.33 ms per token,   230.85 tokens per second)\n",
      "llama_print_timings:        eval time =    2998.74 ms /    51 runs   (   58.80 ms per token,    17.01 tokens per second)\n",
      "llama_print_timings:       total time =    3359.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.18 ms /    71 runs   (    0.23 ms per token,  4389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.14 ms /    41 tokens (    4.47 ms per token,   223.88 tokens per second)\n",
      "llama_print_timings:        eval time =    3593.39 ms /    70 runs   (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_print_timings:       total time =    3981.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    36 runs   (    0.22 ms per token,  4531.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.22 ms /    45 tokens (    4.25 ms per token,   235.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1748.25 ms /    35 runs   (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:       total time =    2077.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    26 runs   (    0.22 ms per token,  4451.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     203.41 ms /    52 tokens (    3.91 ms per token,   255.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1848.35 ms /    25 runs   (   73.93 ms per token,    13.53 tokens per second)\n",
      "llama_print_timings:       total time =    2193.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.50 ms /    44 runs   (    0.24 ms per token,  4190.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     317.82 ms /    49 tokens (    6.49 ms per token,   154.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2301.49 ms /    43 runs   (   53.52 ms per token,    18.68 tokens per second)\n",
      "llama_print_timings:       total time =    2788.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    33 runs   (    0.21 ms per token,  4651.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.42 ms /    39 tokens (    4.68 ms per token,   213.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1352.94 ms /    32 runs   (   42.28 ms per token,    23.65 tokens per second)\n",
      "llama_print_timings:       total time =    1656.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    32 runs   (    0.22 ms per token,  4539.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.15 ms /    43 tokens (    4.42 ms per token,   226.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1749.29 ms /    31 runs   (   56.43 ms per token,    17.72 tokens per second)\n",
      "llama_print_timings:       total time =    2065.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    59 runs   (    0.22 ms per token,  4479.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.91 ms /    45 tokens (    4.20 ms per token,   238.21 tokens per second)\n",
      "llama_print_timings:        eval time =    2778.52 ms /    58 runs   (   47.91 ms per token,    20.87 tokens per second)\n",
      "llama_print_timings:       total time =    3152.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.20 ms /    46 runs   (    0.22 ms per token,  4508.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.92 ms /    49 tokens (    3.79 ms per token,   263.56 tokens per second)\n",
      "llama_print_timings:        eval time =    2048.32 ms /    45 runs   (   45.52 ms per token,    21.97 tokens per second)\n",
      "llama_print_timings:       total time =    2390.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    17 runs   (    0.22 ms per token,  4523.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.33 ms /    50 tokens (    3.87 ms per token,   258.63 tokens per second)\n",
      "llama_print_timings:        eval time =     618.90 ms /    16 runs   (   38.68 ms per token,    25.85 tokens per second)\n",
      "llama_print_timings:       total time =     913.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /    21 runs   (    0.22 ms per token,  4558.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.10 ms /    43 tokens (    4.21 ms per token,   237.44 tokens per second)\n",
      "llama_print_timings:        eval time =     741.94 ms /    20 runs   (   37.10 ms per token,    26.96 tokens per second)\n",
      "llama_print_timings:       total time =    1022.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    53 runs   (    0.23 ms per token,  4299.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.54 ms /    50 tokens (    3.79 ms per token,   263.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2641.05 ms /    52 runs   (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_print_timings:       total time =    3013.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    47 runs   (    0.23 ms per token,  4431.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.91 ms /    46 tokens (    4.06 ms per token,   246.10 tokens per second)\n",
      "llama_print_timings:        eval time =    2879.28 ms /    46 runs   (   62.59 ms per token,    15.98 tokens per second)\n",
      "llama_print_timings:       total time =    3239.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    48 runs   (    0.22 ms per token,  4479.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.81 ms /    42 tokens (    4.40 ms per token,   227.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1952.05 ms /    47 runs   (   41.53 ms per token,    24.08 tokens per second)\n",
      "llama_print_timings:       total time =    2288.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.84 ms /    61 runs   (    0.24 ms per token,  4109.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     228.76 ms /    96 tokens (    2.38 ms per token,   419.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2418.36 ms /    60 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
      "llama_print_timings:       total time =    2909.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    18 runs   (    0.22 ms per token,  4451.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.90 ms /    53 tokens (    3.68 ms per token,   271.94 tokens per second)\n",
      "llama_print_timings:        eval time =     694.51 ms /    17 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =    1000.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    29 runs   (    0.23 ms per token,  4422.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.85 ms /    42 tokens (    4.54 ms per token,   220.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.12 ms /    28 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1486.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.07 ms /    49 runs   (    0.23 ms per token,  4427.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     220.43 ms /    60 tokens (    3.67 ms per token,   272.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1944.61 ms /    48 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
      "llama_print_timings:       total time =    2359.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    38 runs   (    0.22 ms per token,  4584.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.36 ms /    41 tokens (    4.45 ms per token,   224.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1538.24 ms /    37 runs   (   41.57 ms per token,    24.05 tokens per second)\n",
      "llama_print_timings:       total time =    1853.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    44 runs   (    0.22 ms per token,  4492.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.85 ms /    41 tokens (    4.51 ms per token,   221.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1769.66 ms /    43 runs   (   41.16 ms per token,    24.30 tokens per second)\n",
      "llama_print_timings:       total time =    2100.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    28 runs   (    0.23 ms per token,  4330.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.91 ms /    54 tokens (    3.68 ms per token,   271.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1533.90 ms /    27 runs   (   56.81 ms per token,    17.60 tokens per second)\n",
      "llama_print_timings:       total time =    1862.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    24 runs   (    0.22 ms per token,  4606.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.47 ms /    50 tokens (    3.73 ms per token,   268.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1044.77 ms /    23 runs   (   45.42 ms per token,    22.01 tokens per second)\n",
      "llama_print_timings:       total time =    1345.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    33 runs   (    0.23 ms per token,  4375.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.50 ms /    54 tokens (    3.62 ms per token,   276.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1412.41 ms /    32 runs   (   44.14 ms per token,    22.66 tokens per second)\n",
      "llama_print_timings:       total time =    1749.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    44 runs   (    0.23 ms per token,  4322.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     209.76 ms /    61 tokens (    3.44 ms per token,   290.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2868.52 ms /    43 runs   (   66.71 ms per token,    14.99 tokens per second)\n",
      "llama_print_timings:       total time =    3260.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.97 ms /    66 runs   (    0.23 ms per token,  4407.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.63 ms /    49 tokens (    3.93 ms per token,   254.37 tokens per second)\n",
      "llama_print_timings:        eval time =    3021.95 ms /    65 runs   (   46.49 ms per token,    21.51 tokens per second)\n",
      "llama_print_timings:       total time =    3415.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.11 ms /    57 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     217.43 ms /    52 tokens (    4.18 ms per token,   239.16 tokens per second)\n",
      "llama_print_timings:        eval time =    3932.72 ms /    56 runs   (   70.23 ms per token,    14.24 tokens per second)\n",
      "llama_print_timings:       total time =    4360.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.93 ms /    45 runs   (    0.22 ms per token,  4533.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.71 ms /    39 tokens (    7.45 ms per token,   134.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2296.98 ms /    44 runs   (   52.20 ms per token,    19.16 tokens per second)\n",
      "llama_print_timings:       total time =    2742.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    46 runs   (    0.23 ms per token,  4271.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.11 ms /    45 tokens (    4.25 ms per token,   235.47 tokens per second)\n",
      "llama_print_timings:        eval time =    3515.88 ms /    45 runs   (   78.13 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    3871.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    22 runs   (    0.21 ms per token,  4706.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.42 ms /    40 tokens (    4.56 ms per token,   219.28 tokens per second)\n",
      "llama_print_timings:        eval time =     932.29 ms /    21 runs   (   44.39 ms per token,    22.53 tokens per second)\n",
      "llama_print_timings:       total time =    1216.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    36 runs   (    0.22 ms per token,  4553.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.13 ms /    42 tokens (    4.53 ms per token,   220.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1856.80 ms /    35 runs   (   53.05 ms per token,    18.85 tokens per second)\n",
      "llama_print_timings:       total time =    2181.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    31 runs   (    0.23 ms per token,  4433.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.38 ms /    43 tokens (    4.36 ms per token,   229.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1878.95 ms /    30 runs   (   62.63 ms per token,    15.97 tokens per second)\n",
      "llama_print_timings:       total time =    2182.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    27 runs   (    0.22 ms per token,  4531.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.71 ms /    41 tokens (    6.68 ms per token,   149.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1369.50 ms /    26 runs   (   52.67 ms per token,    18.99 tokens per second)\n",
      "llama_print_timings:       total time =    1768.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.81 ms /    70 runs   (    0.24 ms per token,  4164.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.16 ms /    62 tokens (    3.29 ms per token,   303.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4657.93 ms /    69 runs   (   67.51 ms per token,    14.81 tokens per second)\n",
      "llama_print_timings:       total time =    5122.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.55 ms /    54 runs   (    0.23 ms per token,  4303.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.59 ms /    46 tokens (    4.71 ms per token,   212.38 tokens per second)\n",
      "llama_print_timings:        eval time =    4244.87 ms /    53 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    4672.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    12 runs   (    0.22 ms per token,  4523.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.51 ms /    49 tokens (    6.11 ms per token,   163.60 tokens per second)\n",
      "llama_print_timings:        eval time =     696.02 ms /    11 runs   (   63.27 ms per token,    15.80 tokens per second)\n",
      "llama_print_timings:       total time =    1085.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      22.23 ms /    93 runs   (    0.24 ms per token,  4183.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.48 ms /    40 tokens (    4.81 ms per token,   207.82 tokens per second)\n",
      "llama_print_timings:        eval time =    5626.43 ms /    92 runs   (   61.16 ms per token,    16.35 tokens per second)\n",
      "llama_print_timings:       total time =    6090.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.68 ms /    49 runs   (    0.24 ms per token,  4193.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.59 ms /    42 tokens (    4.94 ms per token,   202.32 tokens per second)\n",
      "llama_print_timings:        eval time =    3787.56 ms /    48 runs   (   78.91 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    4178.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.59 ms /    60 runs   (    0.24 ms per token,  4113.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     328.62 ms /    41 tokens (    8.02 ms per token,   124.76 tokens per second)\n",
      "llama_print_timings:        eval time =    3649.08 ms /    59 runs   (   61.85 ms per token,    16.17 tokens per second)\n",
      "llama_print_timings:       total time =    4178.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    38 runs   (    0.23 ms per token,  4335.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.03 ms /    40 tokens (    5.10 ms per token,   196.04 tokens per second)\n",
      "llama_print_timings:        eval time =    2480.21 ms /    37 runs   (   67.03 ms per token,    14.92 tokens per second)\n",
      "llama_print_timings:       total time =    2837.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    32 runs   (    0.23 ms per token,  4361.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.85 ms /    46 tokens (    4.32 ms per token,   231.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1797.52 ms /    31 runs   (   57.98 ms per token,    17.25 tokens per second)\n",
      "llama_print_timings:       total time =    2146.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    19 runs   (    0.23 ms per token,  4409.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     382.15 ms /    43 tokens (    8.89 ms per token,   112.52 tokens per second)\n",
      "llama_print_timings:        eval time =     934.01 ms /    18 runs   (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_print_timings:       total time =    1423.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.21 ms /    50 runs   (    0.24 ms per token,  4093.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.33 ms /    55 tokens (    3.46 ms per token,   288.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2159.41 ms /    49 runs   (   44.07 ms per token,    22.69 tokens per second)\n",
      "llama_print_timings:       total time =    2551.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.75 ms /    67 runs   (    0.24 ms per token,  4252.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     232.65 ms /    60 tokens (    3.88 ms per token,   257.89 tokens per second)\n",
      "llama_print_timings:        eval time =    2715.01 ms /    66 runs   (   41.14 ms per token,    24.31 tokens per second)\n",
      "llama_print_timings:       total time =    3177.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.74 ms /    59 runs   (    0.23 ms per token,  4293.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     272.49 ms /    42 tokens (    6.49 ms per token,   154.14 tokens per second)\n",
      "llama_print_timings:        eval time =    2884.24 ms /    58 runs   (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_print_timings:       total time =    3354.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    20 runs   (    0.22 ms per token,  4473.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.15 ms /    41 tokens (    4.69 ms per token,   213.38 tokens per second)\n",
      "llama_print_timings:        eval time =     814.26 ms /    19 runs   (   42.86 ms per token,    23.33 tokens per second)\n",
      "llama_print_timings:       total time =    1106.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.33 ms /    53 runs   (    0.23 ms per token,  4300.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.90 ms /    46 tokens (    4.19 ms per token,   238.47 tokens per second)\n",
      "llama_print_timings:        eval time =    2561.59 ms /    52 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_print_timings:       total time =    2932.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.67 ms /    57 runs   (    0.24 ms per token,  4171.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.06 ms /    46 tokens (    5.57 ms per token,   179.65 tokens per second)\n",
      "llama_print_timings:        eval time =    5108.80 ms /    56 runs   (   91.23 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =    5571.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.68 ms /    44 runs   (    0.24 ms per token,  4121.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     231.35 ms /    51 tokens (    4.54 ms per token,   220.45 tokens per second)\n",
      "llama_print_timings:        eval time =    2015.65 ms /    43 runs   (   46.88 ms per token,    21.33 tokens per second)\n",
      "llama_print_timings:       total time =    2421.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.91 ms /    42 runs   (    0.24 ms per token,  4239.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.32 ms /    39 tokens (    5.44 ms per token,   183.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2950.37 ms /    41 runs   (   71.96 ms per token,    13.90 tokens per second)\n",
      "llama_print_timings:       total time =    3322.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    23 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     211.06 ms /    38 tokens (    5.55 ms per token,   180.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1186.61 ms /    22 runs   (   53.94 ms per token,    18.54 tokens per second)\n",
      "llama_print_timings:       total time =    1513.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    22 runs   (    0.22 ms per token,  4487.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.98 ms /    38 tokens (    4.92 ms per token,   203.23 tokens per second)\n",
      "llama_print_timings:        eval time =     805.08 ms /    21 runs   (   38.34 ms per token,    26.08 tokens per second)\n",
      "llama_print_timings:       total time =    1088.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.65 ms /    47 runs   (    0.23 ms per token,  4411.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.14 ms /    42 tokens (    4.34 ms per token,   230.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1851.26 ms /    46 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
      "llama_print_timings:       total time =    2183.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    15 runs   (    0.21 ms per token,  4727.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     204.15 ms /    40 tokens (    5.10 ms per token,   195.94 tokens per second)\n",
      "llama_print_timings:        eval time =     497.48 ms /    14 runs   (   35.53 ms per token,    28.14 tokens per second)\n",
      "llama_print_timings:       total time =     782.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.09 ms /    74 runs   (    0.23 ms per token,  4330.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.76 ms /    51 tokens (    3.84 ms per token,   260.52 tokens per second)\n",
      "llama_print_timings:        eval time =    3296.04 ms /    73 runs   (   45.15 ms per token,    22.15 tokens per second)\n",
      "llama_print_timings:       total time =    3714.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      19.77 ms /    87 runs   (    0.23 ms per token,  4399.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.07 ms /    39 tokens (    4.95 ms per token,   202.00 tokens per second)\n",
      "llama_print_timings:        eval time =    3574.36 ms /    86 runs   (   41.56 ms per token,    24.06 tokens per second)\n",
      "llama_print_timings:       total time =    4002.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    26 runs   (    0.22 ms per token,  4541.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.59 ms /    42 tokens (    4.40 ms per token,   227.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.10 ms /    25 runs   (   44.72 ms per token,    22.36 tokens per second)\n",
      "llama_print_timings:       total time =    1418.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    25 runs   (    0.21 ms per token,  4745.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.32 ms /    41 tokens (    4.67 ms per token,   214.30 tokens per second)\n",
      "llama_print_timings:        eval time =     933.38 ms /    24 runs   (   38.89 ms per token,    25.71 tokens per second)\n",
      "llama_print_timings:       total time =    1231.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.41 ms /    63 runs   (    0.23 ms per token,  4371.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.52 ms /    41 tokens (    4.45 ms per token,   224.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2520.58 ms /    62 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =    2890.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.91 ms /    67 runs   (    0.22 ms per token,  4493.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.64 ms /    41 tokens (    4.55 ms per token,   219.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2673.22 ms /    66 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:       total time =    3054.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /    15 runs   (    0.21 ms per token,  4716.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.93 ms /    40 tokens (    4.62 ms per token,   216.30 tokens per second)\n",
      "llama_print_timings:        eval time =     558.45 ms /    14 runs   (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:       total time =     836.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /    15 runs   (    0.22 ms per token,  4564.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.90 ms /    46 tokens (    4.17 ms per token,   239.71 tokens per second)\n",
      "llama_print_timings:        eval time =     617.34 ms /    14 runs   (   44.10 ms per token,    22.68 tokens per second)\n",
      "llama_print_timings:       total time =     906.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    38 runs   (    0.22 ms per token,  4572.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.80 ms /    37 tokens (    4.89 ms per token,   204.64 tokens per second)\n",
      "llama_print_timings:        eval time =    4798.13 ms /    37 runs   (  129.68 ms per token,     7.71 tokens per second)\n",
      "llama_print_timings:       total time =    5111.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    31 runs   (    0.21 ms per token,  4741.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.58 ms /    47 tokens (    3.97 ms per token,   251.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.59 ms /    30 runs   (   38.59 ms per token,    25.92 tokens per second)\n",
      "llama_print_timings:       total time =    1469.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    31 runs   (    0.22 ms per token,  4585.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.16 ms /    50 tokens (    3.96 ms per token,   252.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1199.74 ms /    30 runs   (   39.99 ms per token,    25.01 tokens per second)\n",
      "llama_print_timings:       total time =    1531.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    31 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.65 ms /    37 tokens (    5.40 ms per token,   185.32 tokens per second)\n",
      "llama_print_timings:        eval time =    3805.24 ms /    30 runs   (  126.84 ms per token,     7.88 tokens per second)\n",
      "llama_print_timings:       total time =    4117.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    20 runs   (    0.20 ms per token,  4898.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.80 ms /    38 tokens (    4.78 ms per token,   209.02 tokens per second)\n",
      "llama_print_timings:        eval time =     698.28 ms /    19 runs   (   36.75 ms per token,    27.21 tokens per second)\n",
      "llama_print_timings:       total time =     971.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    43 runs   (    0.21 ms per token,  4700.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.52 ms /    39 tokens (    4.63 ms per token,   216.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1713.86 ms /    42 runs   (   40.81 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =    2033.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    22 runs   (    0.21 ms per token,  4750.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.54 ms /    39 tokens (    4.68 ms per token,   213.65 tokens per second)\n",
      "llama_print_timings:        eval time =     792.98 ms /    21 runs   (   37.76 ms per token,    26.48 tokens per second)\n",
      "llama_print_timings:       total time =    1073.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    34 runs   (    0.23 ms per token,  4384.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.97 ms /    42 tokens (    4.76 ms per token,   210.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1493.96 ms /    33 runs   (   45.27 ms per token,    22.09 tokens per second)\n",
      "llama_print_timings:       total time =    1822.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    23 runs   (    0.23 ms per token,  4373.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.85 ms /    45 tokens (    4.20 ms per token,   238.28 tokens per second)\n",
      "llama_print_timings:        eval time =     898.65 ms /    22 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =    1201.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    36 runs   (    0.23 ms per token,  4439.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.12 ms /    49 tokens (    4.04 ms per token,   247.32 tokens per second)\n",
      "llama_print_timings:        eval time =    4476.36 ms /    35 runs   (  127.90 ms per token,     7.82 tokens per second)\n",
      "llama_print_timings:       total time =    4835.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.59 ms /    42 runs   (    0.23 ms per token,  4379.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     225.23 ms /    43 tokens (    5.24 ms per token,   190.92 tokens per second)\n",
      "llama_print_timings:        eval time =    2283.85 ms /    41 runs   (   55.70 ms per token,    17.95 tokens per second)\n",
      "llama_print_timings:       total time =    2674.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    32 runs   (    0.25 ms per token,  4072.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     244.85 ms /    68 tokens (    3.60 ms per token,   277.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1878.81 ms /    31 runs   (   60.61 ms per token,    16.50 tokens per second)\n",
      "llama_print_timings:       total time =    2295.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    29 runs   (    0.22 ms per token,  4549.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.14 ms /    45 tokens (    4.80 ms per token,   208.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1281.91 ms /    28 runs   (   45.78 ms per token,    21.84 tokens per second)\n",
      "llama_print_timings:       total time =    1623.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.16 ms /    47 runs   (    0.24 ms per token,  4210.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.64 ms /    48 tokens (    4.10 ms per token,   244.11 tokens per second)\n",
      "llama_print_timings:        eval time =    2441.51 ms /    46 runs   (   53.08 ms per token,    18.84 tokens per second)\n",
      "llama_print_timings:       total time =    2820.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    44 runs   (    0.23 ms per token,  4323.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     216.30 ms /    43 tokens (    5.03 ms per token,   198.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2441.41 ms /    43 runs   (   56.78 ms per token,    17.61 tokens per second)\n",
      "llama_print_timings:       total time =    2827.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    43 runs   (    0.24 ms per token,  4218.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     415.41 ms /    46 tokens (    9.03 ms per token,   110.74 tokens per second)\n",
      "llama_print_timings:        eval time =    8739.64 ms /    42 runs   (  208.09 ms per token,     4.81 tokens per second)\n",
      "llama_print_timings:       total time =    9333.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.01 ms /    39 runs   (    0.23 ms per token,  4329.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.04 ms /    45 tokens (    4.71 ms per token,   212.23 tokens per second)\n",
      "llama_print_timings:        eval time =    6471.50 ms /    38 runs   (  170.30 ms per token,     5.87 tokens per second)\n",
      "llama_print_timings:       total time =    6841.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    28 runs   (    0.23 ms per token,  4432.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.69 ms /    44 tokens (    4.15 ms per token,   240.84 tokens per second)\n",
      "llama_print_timings:        eval time =    2805.63 ms /    27 runs   (  103.91 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    3110.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /    18 runs   (    0.20 ms per token,  4904.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.47 ms /    36 tokens (    5.01 ms per token,   199.47 tokens per second)\n",
      "llama_print_timings:        eval time =     625.91 ms /    17 runs   (   36.82 ms per token,    27.16 tokens per second)\n",
      "llama_print_timings:       total time =     889.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    37 runs   (    0.21 ms per token,  4772.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     178.15 ms /    38 tokens (    4.69 ms per token,   213.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1463.02 ms /    36 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
      "llama_print_timings:       total time =    1766.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    38 runs   (    0.23 ms per token,  4413.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     214.92 ms /    50 tokens (    4.30 ms per token,   232.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1615.10 ms /    37 runs   (   43.65 ms per token,    22.91 tokens per second)\n",
      "llama_print_timings:       total time =    1984.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.43 ms /    55 runs   (    0.23 ms per token,  4425.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.68 ms /    48 tokens (    3.91 ms per token,   255.75 tokens per second)\n",
      "llama_print_timings:        eval time =    4135.78 ms /    54 runs   (   76.59 ms per token,    13.06 tokens per second)\n",
      "llama_print_timings:       total time =    4503.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.72 ms /    42 runs   (    0.23 ms per token,  4321.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     213.22 ms /    44 tokens (    4.85 ms per token,   206.36 tokens per second)\n",
      "llama_print_timings:        eval time =    5808.02 ms /    41 runs   (  141.66 ms per token,     7.06 tokens per second)\n",
      "llama_print_timings:       total time =    6190.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.89 ms /    61 runs   (    0.23 ms per token,  4390.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.36 ms /    60 tokens (    3.46 ms per token,   289.35 tokens per second)\n",
      "llama_print_timings:        eval time =    2488.26 ms /    60 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
      "llama_print_timings:       total time =    2914.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    36 runs   (    0.22 ms per token,  4457.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.53 ms /    55 tokens (    3.54 ms per token,   282.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1320.60 ms /    35 runs   (   37.73 ms per token,    26.50 tokens per second)\n",
      "llama_print_timings:       total time =    1659.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      17.43 ms /    79 runs   (    0.22 ms per token,  4531.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     242.86 ms /    42 tokens (    5.78 ms per token,   172.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3871.27 ms /    78 runs   (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_print_timings:       total time =    4350.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.12 ms /    57 runs   (    0.25 ms per token,  4037.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.77 ms /    98 tokens (    2.92 ms per token,   342.94 tokens per second)\n",
      "llama_print_timings:        eval time =    6153.04 ms /    56 runs   (  109.88 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =    6707.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    48 runs   (    0.23 ms per token,  4266.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.03 ms /    42 tokens (    4.67 ms per token,   214.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2216.39 ms /    47 runs   (   47.16 ms per token,    21.21 tokens per second)\n",
      "llama_print_timings:       total time =    2577.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.92 ms /    59 runs   (    0.24 ms per token,  4237.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     395.51 ms /   193 tokens (    2.05 ms per token,   487.98 tokens per second)\n",
      "llama_print_timings:        eval time =    2629.91 ms /    58 runs   (   45.34 ms per token,    22.05 tokens per second)\n",
      "llama_print_timings:       total time =    3448.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.37 ms /    50 runs   (    0.23 ms per token,  4397.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.45 ms /    44 tokens (    6.31 ms per token,   158.59 tokens per second)\n",
      "llama_print_timings:        eval time =    2408.71 ms /    49 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_print_timings:       total time =    2854.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    33 runs   (    0.23 ms per token,  4435.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.49 ms /    44 tokens (    6.06 ms per token,   165.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1547.38 ms /    32 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_print_timings:       total time =    1950.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    23 runs   (    0.21 ms per token,  4735.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.92 ms /    34 tokens (    7.62 ms per token,   131.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1256.62 ms /    22 runs   (   57.12 ms per token,    17.51 tokens per second)\n",
      "llama_print_timings:       total time =    1623.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      16.43 ms /    71 runs   (    0.23 ms per token,  4320.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     199.87 ms /    43 tokens (    4.65 ms per token,   215.14 tokens per second)\n",
      "llama_print_timings:        eval time =    3303.06 ms /    70 runs   (   47.19 ms per token,    21.19 tokens per second)\n",
      "llama_print_timings:       total time =    3711.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    47 runs   (    0.23 ms per token,  4263.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.67 ms /    43 tokens (    4.53 ms per token,   220.89 tokens per second)\n",
      "llama_print_timings:        eval time =    3462.54 ms /    46 runs   (   75.27 ms per token,    13.29 tokens per second)\n",
      "llama_print_timings:       total time =    3868.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.95 ms /    52 runs   (    0.23 ms per token,  4350.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     179.65 ms /    40 tokens (    4.49 ms per token,   222.65 tokens per second)\n",
      "llama_print_timings:        eval time =    2421.74 ms /    51 runs   (   47.49 ms per token,    21.06 tokens per second)\n",
      "llama_print_timings:       total time =    2767.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.11 ms /    49 runs   (    0.23 ms per token,  4410.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.97 ms /    48 tokens (    3.94 ms per token,   254.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2834.65 ms /    48 runs   (   59.06 ms per token,    16.93 tokens per second)\n",
      "llama_print_timings:       total time =    3200.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    34 runs   (    0.22 ms per token,  4500.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     201.77 ms /    44 tokens (    4.59 ms per token,   218.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1633.91 ms /    33 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_print_timings:       total time =    1985.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    32 runs   (    0.22 ms per token,  4457.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.32 ms /    45 tokens (    4.23 ms per token,   236.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1421.38 ms /    31 runs   (   45.85 ms per token,    21.81 tokens per second)\n",
      "llama_print_timings:       total time =    1746.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.99 ms /    48 runs   (    0.23 ms per token,  4368.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     307.30 ms /    46 tokens (    6.68 ms per token,   149.69 tokens per second)\n",
      "llama_print_timings:        eval time =    2616.33 ms /    47 runs   (   55.67 ms per token,    17.96 tokens per second)\n",
      "llama_print_timings:       total time =    3094.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    36 runs   (    0.23 ms per token,  4384.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.22 ms /    46 tokens (    6.07 ms per token,   164.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1553.84 ms /    35 runs   (   44.40 ms per token,    22.52 tokens per second)\n",
      "llama_print_timings:       total time =    1972.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.81 ms /    27 runs   (    0.22 ms per token,  4645.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.26 ms /    41 tokens (    4.42 ms per token,   226.19 tokens per second)\n",
      "llama_print_timings:        eval time =     961.87 ms /    26 runs   (   36.99 ms per token,    27.03 tokens per second)\n",
      "llama_print_timings:       total time =    1249.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.45 ms /    51 runs   (    0.22 ms per token,  4455.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.31 ms /    49 tokens (    3.78 ms per token,   264.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1863.22 ms /    50 runs   (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:       total time =    2232.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    29 runs   (    0.22 ms per token,  4596.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.54 ms /    43 tokens (    4.78 ms per token,   209.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1180.69 ms /    28 runs   (   42.17 ms per token,    23.71 tokens per second)\n",
      "llama_print_timings:       total time =    1518.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    41 runs   (    0.22 ms per token,  4576.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.04 ms /    44 tokens (    4.32 ms per token,   231.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1547.63 ms /    40 runs   (   38.69 ms per token,    25.85 tokens per second)\n",
      "llama_print_timings:       total time =    1881.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /    18 runs   (    0.21 ms per token,  4811.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.60 ms /    42 tokens (    4.37 ms per token,   228.76 tokens per second)\n",
      "llama_print_timings:        eval time =     655.54 ms /    17 runs   (   38.56 ms per token,    25.93 tokens per second)\n",
      "llama_print_timings:       total time =     932.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    42 runs   (    0.23 ms per token,  4428.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.77 ms /    43 tokens (    4.39 ms per token,   227.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1612.17 ms /    41 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:       total time =    1946.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    15 runs   (    0.21 ms per token,  4730.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.75 ms /    42 tokens (    4.45 ms per token,   224.90 tokens per second)\n",
      "llama_print_timings:        eval time =     532.97 ms /    14 runs   (   38.07 ms per token,    26.27 tokens per second)\n",
      "llama_print_timings:       total time =     812.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    34 runs   (    0.22 ms per token,  4603.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.43 ms /    48 tokens (    4.05 ms per token,   246.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1277.53 ms /    33 runs   (   38.71 ms per token,    25.83 tokens per second)\n",
      "llama_print_timings:       total time =    1606.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    35 runs   (    0.22 ms per token,  4533.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.31 ms /    47 tokens (    3.92 ms per token,   255.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1305.59 ms /    34 runs   (   38.40 ms per token,    26.04 tokens per second)\n",
      "llama_print_timings:       total time =    1620.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    47 runs   (    0.21 ms per token,  4654.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.24 ms /    50 tokens (    3.78 ms per token,   264.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1755.38 ms /    46 runs   (   38.16 ms per token,    26.21 tokens per second)\n",
      "llama_print_timings:       total time =    2099.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.17 ms /    40 runs   (    0.23 ms per token,  4361.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.15 ms /    38 tokens (    4.82 ms per token,   207.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1925.02 ms /    39 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:       total time =    2245.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    38 runs   (    0.25 ms per token,  4014.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     378.30 ms /    54 tokens (    7.01 ms per token,   142.75 tokens per second)\n",
      "llama_print_timings:        eval time =    6400.98 ms /    37 runs   (  173.00 ms per token,     5.78 tokens per second)\n",
      "llama_print_timings:       total time =    6955.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      18.39 ms /    79 runs   (    0.23 ms per token,  4296.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.54 ms /    49 tokens (    3.91 ms per token,   255.82 tokens per second)\n",
      "llama_print_timings:        eval time =    4498.26 ms /    78 runs   (   57.67 ms per token,    17.34 tokens per second)\n",
      "llama_print_timings:       total time =    4923.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    29 runs   (    0.23 ms per token,  4295.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     314.83 ms /    46 tokens (    6.84 ms per token,   146.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1630.28 ms /    28 runs   (   58.22 ms per token,    17.17 tokens per second)\n",
      "llama_print_timings:       total time =    2072.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.23 ms /    40 runs   (    0.23 ms per token,  4335.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.79 ms /    45 tokens (    4.22 ms per token,   237.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1618.15 ms /    39 runs   (   41.49 ms per token,    24.10 tokens per second)\n",
      "llama_print_timings:       total time =    1956.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    24 runs   (    0.24 ms per token,  4245.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.80 ms /    55 tokens (    3.52 ms per token,   283.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1029.93 ms /    23 runs   (   44.78 ms per token,    22.33 tokens per second)\n",
      "llama_print_timings:       total time =    1349.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    34 runs   (    0.22 ms per token,  4465.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     207.09 ms /    50 tokens (    4.14 ms per token,   241.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1261.30 ms /    33 runs   (   38.22 ms per token,    26.16 tokens per second)\n",
      "llama_print_timings:       total time =    1605.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.61 ms /    43 runs   (    0.25 ms per token,  4054.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     232.02 ms /    90 tokens (    2.58 ms per token,   387.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2442.88 ms /    42 runs   (   58.16 ms per token,    17.19 tokens per second)\n",
      "llama_print_timings:       total time =    2903.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.82 ms /    55 runs   (    0.23 ms per token,  4289.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     244.15 ms /    56 tokens (    4.36 ms per token,   229.37 tokens per second)\n",
      "llama_print_timings:        eval time =   10693.50 ms /    54 runs   (  198.03 ms per token,     5.05 tokens per second)\n",
      "llama_print_timings:       total time =   11157.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.69 ms /    60 runs   (    0.24 ms per token,  4085.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.62 ms /    45 tokens (    4.12 ms per token,   242.43 tokens per second)\n",
      "llama_print_timings:        eval time =    4070.07 ms /    59 runs   (   68.98 ms per token,    14.50 tokens per second)\n",
      "llama_print_timings:       total time =    4466.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    27 runs   (    0.21 ms per token,  4687.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.46 ms /    41 tokens (    4.43 ms per token,   225.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1297.24 ms /    26 runs   (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_print_timings:       total time =    1595.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    43 runs   (    0.21 ms per token,  4686.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.41 ms /    44 tokens (    4.26 ms per token,   234.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1587.15 ms /    42 runs   (   37.79 ms per token,    26.46 tokens per second)\n",
      "llama_print_timings:       total time =    1918.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    49 runs   (    0.22 ms per token,  4476.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     178.16 ms /    39 tokens (    4.57 ms per token,   218.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1817.94 ms /    48 runs   (   37.87 ms per token,    26.40 tokens per second)\n",
      "llama_print_timings:       total time =    2141.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    35 runs   (    0.23 ms per token,  4394.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.48 ms /    44 tokens (    4.24 ms per token,   235.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1656.01 ms /    34 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_print_timings:       total time =    1976.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    50 runs   (    0.22 ms per token,  4445.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.78 ms /    51 tokens (    3.70 ms per token,   270.15 tokens per second)\n",
      "llama_print_timings:        eval time =    2035.38 ms /    49 runs   (   41.54 ms per token,    24.07 tokens per second)\n",
      "llama_print_timings:       total time =    2400.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    27 runs   (    0.22 ms per token,  4470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.62 ms /    41 tokens (    4.41 ms per token,   227.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1187.10 ms /    26 runs   (   45.66 ms per token,    21.90 tokens per second)\n",
      "llama_print_timings:       total time =    1478.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    19 runs   (    0.21 ms per token,  4712.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.29 ms /    45 tokens (    4.10 ms per token,   244.18 tokens per second)\n",
      "llama_print_timings:        eval time =     715.77 ms /    18 runs   (   39.77 ms per token,    25.15 tokens per second)\n",
      "llama_print_timings:       total time =     999.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    37 runs   (    0.22 ms per token,  4640.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     306.20 ms /    39 tokens (    7.85 ms per token,   127.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1923.65 ms /    36 runs   (   53.43 ms per token,    18.71 tokens per second)\n",
      "llama_print_timings:       total time =    2368.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.78 ms /    65 runs   (    0.23 ms per token,  4396.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.93 ms /    39 tokens (    4.66 ms per token,   214.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2907.41 ms /    64 runs   (   45.43 ms per token,    22.01 tokens per second)\n",
      "llama_print_timings:       total time =    3271.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    39 runs   (    0.23 ms per token,  4353.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     306.38 ms /    43 tokens (    7.13 ms per token,   140.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1984.33 ms /    38 runs   (   52.22 ms per token,    19.15 tokens per second)\n",
      "llama_print_timings:       total time =    2435.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    23 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.73 ms /    58 tokens (    4.82 ms per token,   207.34 tokens per second)\n",
      "llama_print_timings:        eval time =     834.18 ms /    22 runs   (   37.92 ms per token,    26.37 tokens per second)\n",
      "llama_print_timings:       total time =    1240.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    22 runs   (    0.22 ms per token,  4571.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     198.95 ms /    57 tokens (    3.49 ms per token,   286.50 tokens per second)\n",
      "llama_print_timings:        eval time =     875.26 ms /    21 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =    1208.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.01 ms /    27 runs   (    0.22 ms per token,  4494.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     176.44 ms /    36 tokens (    4.90 ms per token,   204.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.41 ms /    26 runs   (   43.63 ms per token,    22.92 tokens per second)\n",
      "llama_print_timings:       total time =    1417.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.85 ms /    60 runs   (    0.23 ms per token,  4332.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.48 ms /    40 tokens (    4.51 ms per token,   221.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2495.63 ms /    59 runs   (   42.30 ms per token,    23.64 tokens per second)\n",
      "llama_print_timings:       total time =    2857.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      28.63 ms /   122 runs   (    0.23 ms per token,  4261.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     205.04 ms /    55 tokens (    3.73 ms per token,   268.24 tokens per second)\n",
      "llama_print_timings:        eval time =    5365.05 ms /   121 runs   (   44.34 ms per token,    22.55 tokens per second)\n",
      "llama_print_timings:       total time =    5916.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    37 runs   (    0.23 ms per token,  4312.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     212.34 ms /    42 tokens (    5.06 ms per token,   197.80 tokens per second)\n",
      "llama_print_timings:        eval time =    3789.00 ms /    36 runs   (  105.25 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    4166.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    31 runs   (    0.23 ms per token,  4399.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.30 ms /    45 tokens (    4.30 ms per token,   232.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1810.95 ms /    30 runs   (   60.36 ms per token,    16.57 tokens per second)\n",
      "llama_print_timings:       total time =    2142.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /    16 runs   (    0.22 ms per token,  4461.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     193.64 ms /    58 tokens (    3.34 ms per token,   299.52 tokens per second)\n",
      "llama_print_timings:        eval time =     684.86 ms /    15 runs   (   45.66 ms per token,    21.90 tokens per second)\n",
      "llama_print_timings:       total time =     996.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      12.29 ms /    55 runs   (    0.22 ms per token,  4476.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.41 ms /    46 tokens (    4.07 ms per token,   245.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2643.74 ms /    54 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_print_timings:       total time =    3011.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    30 runs   (    0.22 ms per token,  4595.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.81 ms /    51 tokens (    3.68 ms per token,   271.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1228.10 ms /    29 runs   (   42.35 ms per token,    23.61 tokens per second)\n",
      "llama_print_timings:       total time =    1545.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    33 runs   (    0.22 ms per token,  4544.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     196.12 ms /    47 tokens (    4.17 ms per token,   239.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1269.22 ms /    32 runs   (   39.66 ms per token,    25.21 tokens per second)\n",
      "llama_print_timings:       total time =    1595.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    34 runs   (    0.22 ms per token,  4599.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.71 ms /    48 tokens (    3.85 ms per token,   259.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1326.20 ms /    33 runs   (   40.19 ms per token,    24.88 tokens per second)\n",
      "llama_print_timings:       total time =    1645.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.94 ms /    46 runs   (    0.22 ms per token,  4626.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.65 ms /    46 tokens (    4.06 ms per token,   246.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1828.72 ms /    45 runs   (   40.64 ms per token,    24.61 tokens per second)\n",
      "llama_print_timings:       total time =    2174.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    32 runs   (    0.22 ms per token,  4614.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     178.28 ms /    39 tokens (    4.57 ms per token,   218.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1184.88 ms /    31 runs   (   38.22 ms per token,    26.16 tokens per second)\n",
      "llama_print_timings:       total time =    1478.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    40 runs   (    0.21 ms per token,  4758.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.63 ms /    38 tokens (    4.75 ms per token,   210.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1535.67 ms /    39 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
      "llama_print_timings:       total time =    1846.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    27 runs   (    0.22 ms per token,  4615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.67 ms /    48 tokens (    3.85 ms per token,   259.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1028.38 ms /    26 runs   (   39.55 ms per token,    25.28 tokens per second)\n",
      "llama_print_timings:       total time =    1334.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    42 runs   (    0.22 ms per token,  4621.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.23 ms /    44 tokens (    4.28 ms per token,   233.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1535.99 ms /    41 runs   (   37.46 ms per token,    26.69 tokens per second)\n",
      "llama_print_timings:       total time =    1870.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    52 runs   (    0.23 ms per token,  4343.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.26 ms /    53 tokens (    3.61 ms per token,   277.12 tokens per second)\n",
      "llama_print_timings:        eval time =    2192.37 ms /    51 runs   (   42.99 ms per token,    23.26 tokens per second)\n",
      "llama_print_timings:       total time =    2556.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    38 runs   (    0.22 ms per token,  4574.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     179.94 ms /    39 tokens (    4.61 ms per token,   216.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1453.35 ms /    37 runs   (   39.28 ms per token,    25.46 tokens per second)\n",
      "llama_print_timings:       total time =    1764.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.04 ms /    46 runs   (    0.22 ms per token,  4580.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.78 ms /    48 tokens (    3.89 ms per token,   256.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1803.92 ms /    45 runs   (   40.09 ms per token,    24.95 tokens per second)\n",
      "llama_print_timings:       total time =    2140.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.29 ms /    46 runs   (    0.22 ms per token,  4469.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     195.82 ms /    60 tokens (    3.26 ms per token,   306.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1691.23 ms /    45 runs   (   37.58 ms per token,    26.61 tokens per second)\n",
      "llama_print_timings:       total time =    2063.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.76 ms /    50 runs   (    0.22 ms per token,  4648.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.24 ms /    39 tokens (    4.62 ms per token,   216.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1838.88 ms /    49 runs   (   37.53 ms per token,    26.65 tokens per second)\n",
      "llama_print_timings:       total time =    2163.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    18 runs   (    0.22 ms per token,  4627.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.60 ms /    43 tokens (    4.25 ms per token,   235.49 tokens per second)\n",
      "llama_print_timings:        eval time =     650.62 ms /    17 runs   (   38.27 ms per token,    26.13 tokens per second)\n",
      "llama_print_timings:       total time =     929.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      10.98 ms /    49 runs   (    0.22 ms per token,  4463.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.12 ms /    43 tokens (    4.24 ms per token,   236.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1843.69 ms /    48 runs   (   38.41 ms per token,    26.03 tokens per second)\n",
      "llama_print_timings:       total time =    2181.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.50 ms /    25 runs   (    0.22 ms per token,  4545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     186.82 ms /    52 tokens (    3.59 ms per token,   278.35 tokens per second)\n",
      "llama_print_timings:        eval time =     926.55 ms /    24 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
      "llama_print_timings:       total time =    1232.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    23 runs   (    0.21 ms per token,  4690.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.54 ms /    43 tokens (    4.45 ms per token,   224.50 tokens per second)\n",
      "llama_print_timings:        eval time =     855.43 ms /    22 runs   (   38.88 ms per token,    25.72 tokens per second)\n",
      "llama_print_timings:       total time =    1148.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    41 runs   (    0.23 ms per token,  4386.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.35 ms /    46 tokens (    4.09 ms per token,   244.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1583.17 ms /    40 runs   (   39.58 ms per token,    25.27 tokens per second)\n",
      "llama_print_timings:       total time =    1918.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    27 runs   (    0.21 ms per token,  4779.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     179.56 ms /    39 tokens (    4.60 ms per token,   217.20 tokens per second)\n",
      "llama_print_timings:        eval time =     973.51 ms /    26 runs   (   37.44 ms per token,    26.71 tokens per second)\n",
      "llama_print_timings:       total time =    1258.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    38 runs   (    0.22 ms per token,  4508.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     177.09 ms /    36 tokens (    4.92 ms per token,   203.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1417.34 ms /    37 runs   (   38.31 ms per token,    26.11 tokens per second)\n",
      "llama_print_timings:       total time =    1719.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    16 runs   (    0.21 ms per token,  4823.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     179.43 ms /    42 tokens (    4.27 ms per token,   234.08 tokens per second)\n",
      "llama_print_timings:        eval time =     589.76 ms /    15 runs   (   39.32 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:       total time =     861.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    38 runs   (    0.23 ms per token,  4322.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     190.32 ms /    54 tokens (    3.52 ms per token,   283.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1553.67 ms /    37 runs   (   41.99 ms per token,    23.81 tokens per second)\n",
      "llama_print_timings:       total time =    1900.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    20 runs   (    0.21 ms per token,  4663.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     178.12 ms /    38 tokens (    4.69 ms per token,   213.34 tokens per second)\n",
      "llama_print_timings:        eval time =     774.84 ms /    19 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:       total time =    1040.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    15 runs   (    0.21 ms per token,  4655.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.66 ms /    40 tokens (    4.57 ms per token,   218.99 tokens per second)\n",
      "llama_print_timings:        eval time =     565.43 ms /    14 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:       total time =     833.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    25 runs   (    0.22 ms per token,  4490.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.17 ms /    44 tokens (    4.21 ms per token,   237.62 tokens per second)\n",
      "llama_print_timings:        eval time =     920.56 ms /    24 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
      "llama_print_timings:       total time =    1212.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.41 ms /    28 runs   (    0.23 ms per token,  4368.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     191.11 ms /    47 tokens (    4.07 ms per token,   245.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1061.91 ms /    27 runs   (   39.33 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:       total time =    1372.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    21 runs   (    0.22 ms per token,  4491.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.36 ms /    49 tokens (    3.93 ms per token,   254.74 tokens per second)\n",
      "llama_print_timings:        eval time =     732.93 ms /    20 runs   (   36.65 ms per token,    27.29 tokens per second)\n",
      "llama_print_timings:       total time =    1050.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    25 runs   (    0.22 ms per token,  4580.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.20 ms /    40 tokens (    4.58 ms per token,   218.34 tokens per second)\n",
      "llama_print_timings:        eval time =     923.75 ms /    24 runs   (   38.49 ms per token,    25.98 tokens per second)\n",
      "llama_print_timings:       total time =    1210.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    31 runs   (    0.23 ms per token,  4298.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.55 ms /    42 tokens (    4.30 ms per token,   232.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.84 ms /    30 runs   (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time =    1548.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    23 runs   (    0.21 ms per token,  4710.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.53 ms /    38 tokens (    4.75 ms per token,   210.49 tokens per second)\n",
      "llama_print_timings:        eval time =     893.34 ms /    22 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:       total time =    1172.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      13.82 ms /    60 runs   (    0.23 ms per token,  4342.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.40 ms /    42 tokens (    4.30 ms per token,   232.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2310.94 ms /    59 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
      "llama_print_timings:       total time =    2667.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      14.23 ms /    62 runs   (    0.23 ms per token,  4357.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.42 ms /    42 tokens (    4.39 ms per token,   227.74 tokens per second)\n",
      "llama_print_timings:        eval time =    2329.58 ms /    61 runs   (   38.19 ms per token,    26.18 tokens per second)\n",
      "llama_print_timings:       total time =    2696.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    13 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     194.05 ms /    45 tokens (    4.31 ms per token,   231.90 tokens per second)\n",
      "llama_print_timings:        eval time =     509.17 ms /    12 runs   (   42.43 ms per token,    23.57 tokens per second)\n",
      "llama_print_timings:       total time =     792.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    27 runs   (    0.22 ms per token,  4635.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     188.41 ms /    41 tokens (    4.60 ms per token,   217.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1031.98 ms /    26 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
      "llama_print_timings:       total time =    1326.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /    30 runs   (    0.23 ms per token,  4396.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     183.92 ms /    47 tokens (    3.91 ms per token,   255.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1255.18 ms /    29 runs   (   43.28 ms per token,    23.10 tokens per second)\n",
      "llama_print_timings:       total time =    1562.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    41 runs   (    0.22 ms per token,  4464.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     182.43 ms /    41 tokens (    4.45 ms per token,   224.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1562.36 ms /    40 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
      "llama_print_timings:       total time =    1885.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      11.30 ms /    50 runs   (    0.23 ms per token,  4425.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.22 ms /    40 tokens (    4.53 ms per token,   220.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2006.32 ms /    49 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
      "llama_print_timings:       total time =    2338.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    35 runs   (    0.22 ms per token,  4495.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.37 ms /    47 tokens (    3.92 ms per token,   254.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1449.10 ms /    34 runs   (   42.62 ms per token,    23.46 tokens per second)\n",
      "llama_print_timings:       total time =    1770.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    18 runs   (    0.21 ms per token,  4676.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     181.10 ms /    40 tokens (    4.53 ms per token,   220.87 tokens per second)\n",
      "llama_print_timings:        eval time =     649.38 ms /    17 runs   (   38.20 ms per token,    26.18 tokens per second)\n",
      "llama_print_timings:       total time =     926.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    29 runs   (    0.22 ms per token,  4571.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     185.68 ms /    45 tokens (    4.13 ms per token,   242.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1089.76 ms /    28 runs   (   38.92 ms per token,    25.69 tokens per second)\n",
      "llama_print_timings:       total time =    1392.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =      15.74 ms /    69 runs   (    0.23 ms per token,  4384.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.57 ms /    46 tokens (    4.08 ms per token,   245.25 tokens per second)\n",
      "llama_print_timings:        eval time =    2632.00 ms /    68 runs   (   38.71 ms per token,    25.84 tokens per second)\n",
      "llama_print_timings:       total time =    3022.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    29 runs   (    0.23 ms per token,  4364.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     192.58 ms /    50 tokens (    3.85 ms per token,   259.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1089.23 ms /    28 runs   (   38.90 ms per token,    25.71 tokens per second)\n",
      "llama_print_timings:       total time =    1411.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    26 runs   (    0.22 ms per token,  4649.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.50 ms /    46 tokens (    4.08 ms per token,   245.34 tokens per second)\n",
      "llama_print_timings:        eval time =     961.27 ms /    25 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
      "llama_print_timings:       total time =    1261.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    24 runs   (    0.21 ms per token,  4652.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     178.31 ms /    36 tokens (    4.95 ms per token,   201.89 tokens per second)\n",
      "llama_print_timings:        eval time =     884.63 ms /    23 runs   (   38.46 ms per token,    26.00 tokens per second)\n",
      "llama_print_timings:       total time =    1159.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    22 runs   (    0.22 ms per token,  4465.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     187.38 ms /    46 tokens (    4.07 ms per token,   245.49 tokens per second)\n",
      "llama_print_timings:        eval time =     817.65 ms /    21 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
      "llama_print_timings:       total time =    1117.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    40 runs   (    0.23 ms per token,  4429.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     189.68 ms /    56 tokens (    3.39 ms per token,   295.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1468.33 ms /    39 runs   (   37.65 ms per token,    26.56 tokens per second)\n",
      "llama_print_timings:       total time =    1830.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /    15 runs   (    0.22 ms per token,  4582.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     184.65 ms /    46 tokens (    4.01 ms per token,   249.13 tokens per second)\n",
      "llama_print_timings:        eval time =     551.29 ms /    14 runs   (   39.38 ms per token,    25.40 tokens per second)\n",
      "llama_print_timings:       total time =     829.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    23 runs   (    0.22 ms per token,  4554.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     180.47 ms /    39 tokens (    4.63 ms per token,   216.10 tokens per second)\n",
      "llama_print_timings:        eval time =     891.74 ms /    22 runs   (   40.53 ms per token,    24.67 tokens per second)\n",
      "llama_print_timings:       total time =    1172.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =     205.56 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    26 runs   (    0.23 ms per token,  4314.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     200.75 ms /    50 tokens (    4.02 ms per token,   249.06 tokens per second)\n",
      "llama_print_timings:        eval time =     970.73 ms /    25 runs   (   38.83 ms per token,    25.75 tokens per second)\n",
      "llama_print_timings:       total time =    1313.58 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# change paths appropriately\n",
    "# make sure the output filename is the same as the reference filename for the scoring program\n",
    "path_val_model_agnostic = \"path/to/reference/val.model-agnostic.json\"\n",
    "path_val_model_agnostic_output = \"path/to/output/val.model-agnostic.json\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import tqdm.notebook as tqdm\n",
    "seed_val = 442\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "\n",
    "# alternatively, one can use HuggingFace's library to load the data\n",
    "dataset = load_dataset('json', data_files={'val':path_val_model_agnostic})\n",
    "data_val_all = dataset['val']\n",
    "num_sample = len(data_val_all)\n",
    "print(dataset)\n",
    "print(num_sample)\n",
    "\n",
    "output_json = []\n",
    "labels = [\"Not Hallucination\", \"Hallucination\"]\n",
    "\"\"\"\n",
    "SelfCheckGPT Usage: (LLM) Prompt\n",
    "https://github.com/potsawee/selfcheckgpt\n",
    "Context: {}\n",
    "Sentence: {}\n",
    "Is the sentence supported by the context above?\n",
    "Answer Yes or No:\n",
    "\"\"\"\n",
    "for i in tqdm.trange(num_sample):\n",
    "    # label = str(data_val_all[i]['label'])\n",
    "    task = str(data_val_all[i]['task'])\n",
    "    if run_on_test:\n",
    "        # test splits will contain ids to ensure correct alignment before scoring\n",
    "        id = int(data_val_all[i]['id'])\n",
    "    hyp = str(data_val_all[i]['hyp'])\n",
    "    src = str(data_val_all[i]['src'])\n",
    "    tgt = str(data_val_all[i]['tgt'])\n",
    "\n",
    "    if task == \"PG\":\n",
    "        context = f\"Context: {src}\"\n",
    "    else: #i.e. task == \"MT\" or task == \"DM\":\n",
    "        context = f\"Context: {tgt}\"\n",
    "\n",
    "    sentence = f\"Sentence: {hyp}\"\n",
    "    message = f\"{context}\\n{sentence}\\nIs the Sentence supported by the Context above? Answer using ONLY yes or no:\"\n",
    "    prompt = f\"<s>[INST] {message} [/INST]\"\n",
    "\n",
    "    response = lcpp_llm(\n",
    "        prompt=prompt,\n",
    "        temperature= 0.0,\n",
    "        logprobs=1,\n",
    "    )\n",
    "    answer = str(response[\"choices\"][0][\"text\"]).strip().lower()\n",
    "    if answer.startswith(\"yes\"):\n",
    "        output_label = \"Not Hallucination\"\n",
    "        prob = 1-float(np.exp(response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0]))\n",
    "    if answer.startswith(\"no\"):\n",
    "        output_label = \"Hallucination\"\n",
    "        prob = float(np.exp(response[\"choices\"][0][\"logprobs\"][\"token_logprobs\"][0]))\n",
    "    if not answer.startswith(\"no\") and not answer.startswith(\"yes\"):\n",
    "        idx_random = random.randint(0,len(labels)-1)\n",
    "        output_label = labels[idx_random]\n",
    "        prob = float(0.5)\n",
    "\n",
    "    item_to_json = {\"label\":output_label, \"p(Hallucination)\":prob}\n",
    "    if run_on_test:\n",
    "        item_to_json['id'] = id\n",
    "    output_json.append(item_to_json)\n",
    "\n",
    "\n",
    "f = open(path_val_model_agnostic_output, 'w', encoding='utf-8')\n",
    "json.dump(output_json, f)\n",
    "f.close()\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04b2b191f387469facbc7e0f63edd957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c18583fabf94cf88d89e9d0ad83cd46",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16ceb8ceabea4adeb2ed5d3c62a52e87",
      "value": 1
     }
    },
    "07bb3c8d23084467b680d0f8be879bcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "08db236b9ee74ccb9ac456bf09e298e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ea36c0ff6cd4559bf733fb73ff82693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fca89659d3684477bb46613bbb96383d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_265b13864e334d2d8875d1de157c428a",
      "value": 1
     }
    },
    "16ceb8ceabea4adeb2ed5d3c62a52e87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c18583fabf94cf88d89e9d0ad83cd46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "265b13864e334d2d8875d1de157c428a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2abefc6082af406ab1c955a880a2b419": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ae89d1a8a074a249b750d138587e44d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eb30e73c1e824fa8942f0c58104d696f",
       "IPY_MODEL_df0a135d8a5b43d5ab94bef15b2db5aa",
       "IPY_MODEL_a5e99c0d3739407799fde2f29a301d05"
      ],
      "layout": "IPY_MODEL_fa5555299e2e47ae9d2cc7a7e58415f4"
     }
    },
    "2b25549d8eac4efd99bf1beb4fb26b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e1566a3d2f64b5fbbaf7cc51b9c9902": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48be64dd9497468f83d73bd119591271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cebd82bbc195424a908c9527ee1a21d3",
      "placeholder": "​",
      "style": "IPY_MODEL_8665cfefbc984fc4873e73cd96d6c018",
      "value": "Downloading data files: 100%"
     }
    },
    "4f891d2316604dd08cd5ffd22c8854d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c70248a7e6e45199ed626fa68037174",
      "placeholder": "​",
      "style": "IPY_MODEL_07bb3c8d23084467b680d0f8be879bcd",
      "value": "Generating val split: "
     }
    },
    "4facca9ecbd74aa5b4dc474634686064": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c70248a7e6e45199ed626fa68037174": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c4a2676871e492897d305d6d9a6fac9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "823cdbf0fa2c43559d01de4664258a86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8665cfefbc984fc4873e73cd96d6c018": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86da540e05824f2c95b5c8bea9b4581d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1f94d67f08449439e3191bcdf87c6bf",
       "IPY_MODEL_cb886b4dac084c0290e1fd1c229b092e",
       "IPY_MODEL_8b8fd80c79c54e479b15f798bc545b96"
      ],
      "layout": "IPY_MODEL_3e1566a3d2f64b5fbbaf7cc51b9c9902"
     }
    },
    "8b8fd80c79c54e479b15f798bc545b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08db236b9ee74ccb9ac456bf09e298e1",
      "placeholder": "​",
      "style": "IPY_MODEL_977e8b1928ec42a285804dcc8fc13cb5",
      "value": " 1/1 [00:00&lt;00:00,  1.86it/s]"
     }
    },
    "977e8b1928ec42a285804dcc8fc13cb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f4e1bc76cfb4643877686a6f0271b52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0ceffacff7f492d87084da291061006": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0f2fe09ab0a4a21acda513f96bb7faf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f891d2316604dd08cd5ffd22c8854d9",
       "IPY_MODEL_0ea36c0ff6cd4559bf733fb73ff82693",
       "IPY_MODEL_de38e0a8f5a24cbdbf755db3cfd399ec"
      ],
      "layout": "IPY_MODEL_9f4e1bc76cfb4643877686a6f0271b52"
     }
    },
    "a5e99c0d3739407799fde2f29a301d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e35a5293e19748679095d1222f1a31e5",
      "placeholder": "​",
      "style": "IPY_MODEL_2abefc6082af406ab1c955a880a2b419",
      "value": " 5.94G/5.94G [00:45&lt;00:00, 157MB/s]"
     }
    },
    "ac217ebd99d94729ac89ed81fc0a0ab5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeaed97ed3f441e9aa2ce24c87e02d87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af87959da48a436e842f58ac691717df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aff193ecfc2e4d5a8b3ddd4f63604e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48be64dd9497468f83d73bd119591271",
       "IPY_MODEL_04b2b191f387469facbc7e0f63edd957",
       "IPY_MODEL_e225b3758fa24df3a0d6f1a039d3220a"
      ],
      "layout": "IPY_MODEL_aeaed97ed3f441e9aa2ce24c87e02d87"
     }
    },
    "c96a1b051a7b4fbfbd873be07cf44cf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb886b4dac084c0290e1fd1c229b092e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4facca9ecbd74aa5b4dc474634686064",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f52b2088b6724e6dad9ee18ba364c009",
      "value": 1
     }
    },
    "cebd82bbc195424a908c9527ee1a21d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1f94d67f08449439e3191bcdf87c6bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac217ebd99d94729ac89ed81fc0a0ab5",
      "placeholder": "​",
      "style": "IPY_MODEL_2b25549d8eac4efd99bf1beb4fb26b0c",
      "value": "Extracting data files: 100%"
     }
    },
    "de38e0a8f5a24cbdbf755db3cfd399ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_823cdbf0fa2c43559d01de4664258a86",
      "placeholder": "​",
      "style": "IPY_MODEL_e5ae38c7214c4f05974de99e5d5c3485",
      "value": " 499/0 [00:00&lt;00:00, 2393.49 examples/s]"
     }
    },
    "df0a135d8a5b43d5ab94bef15b2db5aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0ceffacff7f492d87084da291061006",
      "max": 5942065440,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af87959da48a436e842f58ac691717df",
      "value": 5942065440
     }
    },
    "e225b3758fa24df3a0d6f1a039d3220a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c4a2676871e492897d305d6d9a6fac9",
      "placeholder": "​",
      "style": "IPY_MODEL_f432e32a03704652a5bcd21c7ce36abd",
      "value": " 1/1 [00:00&lt;00:00, 29.62it/s]"
     }
    },
    "e35a5293e19748679095d1222f1a31e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ae38c7214c4f05974de99e5d5c3485": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb30e73c1e824fa8942f0c58104d696f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c96a1b051a7b4fbfbd873be07cf44cf0",
      "placeholder": "​",
      "style": "IPY_MODEL_fa37a3f2205749468f31309b6061ffef",
      "value": "mistral-7b-instruct-v0.2.Q6_K.gguf: 100%"
     }
    },
    "f432e32a03704652a5bcd21c7ce36abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f52b2088b6724e6dad9ee18ba364c009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa37a3f2205749468f31309b6061ffef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa5555299e2e47ae9d2cc7a7e58415f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fca89659d3684477bb46613bbb96383d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
